@autoHeader: 2.1.1.1.1.1

<p align="right">update time : {docsify-updated}</p>

## 分布式理论

### 说一下CAP原则？

CAP理论指的是，一个分布式系统最多只能同时满足一致性、可用性和分区容错性，这三项中的两项。

一致性指指数据在多个副本之间能够保持一致的特性。

可用性指系统提供的服务必须一直处于可用的状态，每次请求都能获取到非错的响应。

分区容忍性指能容忍网络分区，在网络断开的情况下，被分隔的节点仍能正常对外提供服务。

一般来说使用网络通信的分布式系统，必须考虑网络中断的情况，一般无法舍弃分区容忍性，那么就只能在一致性和可用性上做一个艰难的选择。

CP系统保障一致性，AP系统保障高可用。

### 说一下BASE理论？

BASE 是 Basically Available（基本可用） 、Soft-state（软状态） 和 Eventually Consistent（最终一致性）三个短语的缩写。

基本可用是指分布式系统在出现不可预知故障的时候，允许损失部分可用性，并不等价于系统不可用，只是部分功能或者性能的丧失。

软状态指允许系统中的数据存在中间状态，并认为该中间状态的存在不会影响系统的整体可用性，即允许系统在不同节点的数据副本之间进行数据同步的过程存在延时。

最终一致性强调的是系统中所有的数据副本，在经过一段时间的同步后，最终能够达到一个一致的状态。

BASE理论是对CAP中一致性和可用性权衡的结果，BASE理论的思想是通过业务，牺牲强一致性而获得可用性，并允许数据在一段时间内是不一致的，但是最终达到一致性状态。

### 说一下分布式锁？

分布式锁的目的是保证在分布式部署的应用集群中，多个服务在请求同一个方法或者同一个业务操作的情况下，对应业务逻辑只能被一台机器上的一个线程执行，避免出现并发问题。

- **分布式锁需要满足以下特性**

1. 互斥性：在相同时刻，只有一个客户端能持有相同资源的锁
2. 安全性：对同一把锁，只能由同一个客户端进行加锁和解锁
3. 可用性：避免死锁，相同资源的锁不能无限期被某个客户端持有，导致后续客户端不能加锁。

- **目前常用的方案有以下三类:**

1. 基于数据库事务实现的锁服务：

   创建一张锁表，获取锁的时候在表中增加一条记录，释放锁的时候删除这条记录，利用数据库 的唯一索引来保障互斥性。

   有以下几个点需要注意:

   1. 锁释放失败:需要定时清理或监控运营
   2. 锁是非阻塞的，如果需要阻塞则可以使用循环语句直至 INSERT 成功
   3. 大规模并发下，数据库并发可能成为瓶颈，适用于并发不是特别高的场景

2. 基于分布式缓存实现的锁服务，典型代表有 Redis

   有两大类，一类是基于 Redis 主从模式的单机SET原子命令实现，另一类是基于 Redis 集群RedLock实现。

   单机模式下，优点是性能比较好，有成熟开源方案。

   缺点:

   1. 锁是非阻塞的，无论成功还是失败都会直接返回:可以通过循环重复执行并设置重试次数，直到获取锁为止。
   2. 删除锁失败守护线程一直执行，可能导致后续逻辑获取不到锁:自行设定一下续期逻辑，例如设置多长续期时间
   3.  主从切换时有一定时间差，可能出现同时获取到锁的情况:一般需要监控此类场景以 及运营处理。场景如:机器 A 申请到一把锁之后，如果 Redis 主宕机，这时候从机并没有同步到这一把锁，那么机器 B 再次申请的时候就会再申请到这把锁。

   集群模式下，相比于单机实现，Redlock 提供了更高的可用性。缺点:1.需要多台 Redis 实例，维护成本高，并且实现复杂 2. 如果出现服务器挂掉的情况，可能出现脑裂等情况

3. 分布式一致性算法实现的锁服务，典型代表有 ZooKeeper。

   优点:

   1. ZooKeeper 具备良好的故障恢复能力和数据一致性保障，leader 宕机后会根据一致性 算法选出新的 Leader
   2. ZooKeeper 有序临时节点在客户端宕机或断开后能自动删除，不会因为节点不删除而 引发后续流程阻塞问题

   缺点:

   1. 高并发场景性能上不如 Redis 分布式锁
   2. 运营成本高

- **选择哪种方案**

小型系统中，可以使用 mysql 等数据库分布式锁；

注重 CP，可以用基于分布式一致性算法实现的锁服务;

注重 AP，可以使用基于分布式缓存实现的锁服务

### 分布式一致性算法有哪些？//todo



### 说一下分布式事务？



### 缓存的分类？

根据缓存与应用的耦合度，分为local cache（本地缓存）和remote cache（分布式缓存）。

- 本地缓存

在应用中的缓存组件，其最大的优点是应用和cache是在同一个进程内部，请求缓存非常快速，没有过多的网络开销等，在单应用不需要集群支持或者集群情况下各节点无需互相通知的场景下使用本地缓存较合适；

它的缺点也是因为缓存跟应用程序耦合，多个应用程序无法直接的共享缓存，各应用或集群的各节点都需要维护自己的单独缓存，对内存是一种浪费。

可通过局部变量、静态变量、Ehcache等方式实现。

- 分布式缓存

与应用分离的缓存组件或服务，其最大的优点是自身就是一个独立的应用，与本地应用隔离，多个应用可直接的共享缓存。

常用的例如Redis缓存。



## 应用技术类

### 负载均衡

#### 负载均衡分类？

**【一】从软硬件上分类**，可分为DNS负载均衡，硬件负载、软件负载。

根据实现技术不同，可分为DNS负载均衡，硬件负载、软件负载。

1、DNS负载均衡。最早的负载均衡技术，利用域名解析实现负载均衡，在DNS服务器，配置多个A记录，这些A记录对应的服务器构成集群。

DNS负载均衡的优点是简单，而且就近访问可以减少响应时间，提升访问速度。缺点：

- DNS有缓存而且缓存时间较长，所以当机房迁移等需要修改DNS配置的时候，用户可能还会访问之前的IP，导致访问失败。
- 扩展能力差，因为运营商管理控制的，由不得开发人员定制或者扩展。
- 比较“笨”，不能区分服务器之间的差异，也不能反映服务器的当前运行状态

2、硬件负载均衡解决方案是直接在服务器和外部网络间安装负载均衡设备，常见的硬件有F5、A10。优点：

- 功能强大，支持全局负载均衡提供全面的复杂均衡算法。
- 高性能，支持百万以上的并发。
- 提供安全功能，例如防火墙、防DDos攻击等。

缺点是贵，而且扩展能力差，当访问量突增的时候，超过限度就不能动态扩容。

3、软件负载。软件负载均衡又分2/3/4/7层负载均衡，对应网络层的七层模型。软件负载均衡的优点在于便宜、简单灵活，配置也很简单。对于小型企业或者并发量不高的企业来说就够用了，在高峰期也容易扩容。缺点在于，它和硬件负载均衡相比，性能一般。支撑不起来大流量的企业，也没有防火墙或防DDos攻击等安全性功能

**【二】从网络七层模型上分类，**负载均衡有 2/3/4/7层多种，对应于网络的七层模型。

二层负载就是数据链路负载。在通信协议的数据链路层修改mac地址，进行负载均衡。数据分发时，指修改目标mac地址，配置真实物理服务器集群所有机器虚拟ip和负载均衡服务器ip地址一致，达到不修改数据包的源地址和目标地址，进行数据分发的目的。比如DR直接路由模式。

三层就是网络层负载。在网络层通过修改请求目标地址进行负载均衡。负载均衡服务器将请求目的地址修改为真实ip地址，不需要经过用户进程处理。真实服务器处理完成后，响应数据包回到负载均衡服务器，负载均衡服务器，再将数据包源地址修改为自身的ip地址，发送给用户浏览器。

四层就是传输层负载。是IP+PORT负载，提供虚拟的IP和端口接收数据后转发到真正服务器上。

七层就是应用层负载。提供虚拟URL或主机名接收数据后转发到真正的地址。

#### 常见的负载均衡服务器有哪些？

平时我们常用的有四层负载均衡和七层负载均衡：四层的负载均衡是基于IP和端口实现的，七层的负载均衡是在四层的基础上，基于URL等信息实现。

- **四层负载均衡**

LVS：重量级软件，本身不支持正则表达式，部署起来比较麻烦，但是性能高，应用范围广，一般的大型互联网公司都有用到。

HAProxy：轻量级软件，支持的负载均衡策略非常多，较灵活。

Nginx：轻量级软件，支持的协议少（HTTP、HTTPS和Email协议），对于Session支持不友好。

- **七层负载均衡**

HAProxy：全面支持七层代理，灵活性高，支持Session会话保持。

Nginx：可以针对HTTP应用进行分流，正则规则灵活，支持高并发，部署简单。

#### 常见负载均衡算法？

**第一类，轮询法**

- 轮询法(Round Robin) 。将请求按顺序轮流地分配到后端服务器上，它均衡地对待后端的每一台服务器，而不关心服务器实际的连接数和当前的系统负载。
- 加权轮询法(Weight Round Robin) 。不同的后端服务器可能机器的配置和当前系统的负载并不相同，因此它们的抗压能力也不相同。给配置高、负载低的机器配置更高的权重，让其处理更多的请；而配置低、负载高的机器，给其分配较低的权重，降低其系统负载，加权轮询能很好地处理这一问题，并将请求顺序且按照权重分配到后端。
- 平滑加权轮询法(Smooth Weight Round Robin)

**第二类，随机法**

- 随机法(Random) 。通过系统的随机算法，根据后端服务器的列表大小值来随机选取其中的一台服务器进行访问。由概率统计理论可以得知，随着客户端调用服务端的次数增多， 其实际效果越来越接近于平均分配调用量到后端的每一台服务器，也就是轮询的结果。
- 加权随机法(Weight Random) 。与加权轮询法一样，加权随机法也根据后端机器的配置，系统的负载分配不同的权重。不同的是，它是按照权重随机请求后端服务器，而非顺序。

**第三类，哈希**

- 源地址哈希法(Hash) 。源地址哈希的思想是根据获取客户端的IP地址，通过哈希函数计算得到的一个数值，用该数值对服务器列表的大小进行取模运算，得到的结果便是客服端要访问服务器的序号。采用源地址哈希法进行负载均衡，同一IP地址的客户端，当后端服务器列表不变时，它每次都会映射到同一台后端服务器进行访问。

**第四类，连接数法**

- 最小连接数法(Least Connections) 。最小连接数算法比较灵活和智能，由于后端服务器的配置不尽相同，对于请求的处理有快有慢，它是根据后端服务器当前的连接情况，动态地选取其中当前积压连接数最少的一台服务器来处理当前的请求，尽可能地提高后端服务的利用效率，将负责合理地分流到每一台服务器。

------

著作权归@pdai所有 原文链接：https://pdai.tech/md/interview/x-interview-2.html

------

著作权归@pdai所有 原文链接：https://pdai.tech/md/interview/x-interview-2.html

------

著作权归@pdai所有 原文链接：https://pdai.tech/md/interview/x-interview-2.html

### 熔断降级

#### 服务间调用的容错方式？

服务之间的依赖关系，如果有被依赖的服务挂了以后，造成其它服务也会出现请求堆积、资源占用，慢慢扩散到所有服务，引发雪崩效应，常见的容错方式有：

- **主动超时**：Http请求主动设置一个超时时间，超时就直接返回，不会造成服务堆积
- **限流**：限制最大并发数
- **熔断**：当错误数超过阈值时快速失败，不调用后端服务，同时隔一定时间放几个请求去重试后端服务是否能正常调用，如果成功则关闭熔断状态，失败则继续快速失败，直接返回。（此处有个重试，重试就是弹性恢复的能力）
- **隔离**：把每个依赖或调用的服务都隔离开来，防止级联失败引起整体服务不可用
- **降级**：服务失败或异常后，返回指定的默认信息

#### 说一下降级？

降级主要是针对非正常情况下的应急服务措施：当此时一些业务服务无法执行时，给出一个统一的返回结果。

降级的方式包括：

1. 延迟服务：比如发表了评论，重要服务，比如在文章中显示正常，但是延迟给用户增加积分，只是放到一个缓存中，等服务平稳之后再执行。
2. 在粒度范围内关闭服务（片段降级或服务功能降级）：比如关闭相关文章的推荐，直接关闭推荐区
3. 页面异步请求降级：比如商品详情页上有推荐信息/配送至等异步加载的请求，如果这些信息响应慢或者后端服务有问题，可以进行降级；
4. 页面跳转（页面降级）：比如可以有相关文章推荐，但是更多的页面则直接跳转到某一个地址
5. 写降级：比如秒杀抢购，我们可以只进行Cache的更新，然后异步同步扣减库存到DB，保证最终一致性即可，此时可以将DB降级为Cache。
6. 读降级：比如多级缓存模式，如果后端服务有问题，可以降级为只读缓存，这种方式适用于对读一致性要求不高的场景。

#### 如何设计服务的熔断？

- **异常处理**：调用受熔断器保护的服务的时候，我们必须要处理当服务不可用时的异常情况。这些异常处理通常需要视具体的业务情况而定。比如，如果应用程序只是暂时的功能降级，可能需要切换到其它的可替换的服务上来执行相同的任务或者获取相同的数据，或者给用户报告错误然后提示他们稍后重试。
- **异常的类型**：请求失败的原因可能有很多种。一些原因可能会比其它原因更严重。比如，请求会失败可能是由于远程的服务崩溃，这可能需要花费数分钟来恢复；也可能是由于服务器暂时负载过重导致超时。熔断器应该能够检查错误的类型，从而根据具体的错误情况来调整策略。比如，可能需要很多次超时异常才可以断定需要切换到断开状态，而只需要几次错误提示就可以判断服务不可用而快速切换到断开状态。
- **日志**：熔断器应该能够记录所有失败的请求，以及一些可能会尝试成功的请求，使得的管理员能够监控使用熔断器保护的服务的执行情况。 测试服务是否可用：在断开状态下，熔断器可以采用定期的ping远程的服务或者资源，来判断是否服务是否恢复，而不是使用计时器来自动切换到半断开状态。这种ping操作可以模拟之前那些失败的请求，或者可以使用通过调用远程服务提供的检查服务是否可用的方法来判断。
- **手动重置**：在系统中对于失败操作的恢复时间是很难确定的，提供一个手动重置功能能够使得管理员可以手动的强制将熔断器切换到闭合状态。同样的，如果受熔断器保护的服务暂时不可用的话，管理员能够强制的将熔断器设置为断开状态。 并发问题：相同的熔断器有可能被大量并发请求同时访问。熔断器的实现不应该阻塞并发的请求或者增加每次请求调用的负担。 资源的差异性：使用单个熔断器时，一个资源如果有分布在多个地方就需要小心。比如，一个数据可能存储在多个磁盘分区上(shard)，某个分区可以正常访问，而另一个可能存在暂时性的问题。在这种情况下，不同的错误响应如果混为一谈，那么应用程序访问的这些存在问题的分区的失败的可能性就会高，而那些被认为是正常的分区，就有可能被阻塞。
- **加快熔断器的熔断操作**:有时候，服务返回的错误信息足够让熔断器立即执行熔断操作并且保持一段时间。比如，如果从一个分布式资源返回的响应提示负载超重，那么应该等待几分钟后再重试。（HTTP协议定义了”HTTP 503 Service Unavailable”来表示请求的服务当前不可用，他可以包含其他信息比如，超时等）
- **重复失败请求**：当熔断器在断开状态的时候，熔断器可以记录每一次请求的细节，而不是仅仅返回失败信息，这样当远程服务恢复的时候，可以将这些失败的请求再重新请求一次。

### 使用缓存有哪些经验？

- **频繁修改的数据**

如果缓存中保存的是频繁修改的数据，就会出现数据写入缓存后，应用还来不及读取缓存，数据就已经失效，徒增系统负担。一般来说，数据的读写比在2：1（写入一次缓存，在数据更新前至少读取两次）以上，缓存才有意义。

- **没有热点的访问**

如果应用系统访问数据没有热点，不遵循二八定律，那么缓存就没有意义。

- **数据不一致与脏读**

一般会对缓存的数据设置失效时间，一旦超过失效时间，就要从数据库中重新加载。因此要容忍一定时间的数据不一致，如卖家已经编辑了商品属性，但是需要过一段时间才能被买家看到。还有一种策略是数据更新立即更新缓存，不过这也会带来更多系统开销和事务一致性问题。

- **缓存可用性**

缓存会承担大部分数据库访问压力，数据库已经习惯了有缓存的日子，所以当缓存服务崩溃时，数据库会因为完全不能承受如此大压力而宕机，导致网站不可用。这种情况被称作缓存雪崩，发生这种故障，甚至不能简单地重启缓存服务器和数据库服务器来恢复。

实践中，有的网站通过缓存热备份等手段提高缓存可用性：当某台缓存服务器宕机时，将缓存访问切换到热备服务器上。但这种设计有违缓存的初衷，缓存根本就不应该当做一个可靠的数据源来使用。

通过分布式缓存服务器集群，将缓存数据分布到集群多台服务器上可在一定程度上改善缓存的可用性。当一台缓存服务器宕机时，只有部分缓存数据丢失，重新从数据库加载这部分数据不会产生很大的影响。

- **缓存预热warm up**

缓存中存放的是热点数据，热点数据又是缓存系统利用LRU（最近最久未用算法）对不断访问的数据筛选淘汰出来，这个过程需要花费较长的时间。新系统的缓存系统如果没有任何数据，在重建缓存数据的过程中，系统的性能和数据库负载都不太好，那么最好在缓存系统启动时就把热点数据加载好，这个缓存预加载手段叫缓存预热。对于一些元数据如城市地名列表、类目信息，可以在启动时加载数据库中全部数据到缓存进行预热。

- **避免缓存穿透**

如果因为不恰当的业务、或者恶意攻击持续高并发地请求某个不存在的数据，由于缓存没有保存该数据，所有的请求都会落到数据库上，会对数据库造成压力，甚至崩溃。一个简单的对策是将不存在的数据也缓存起来，value设置为空。

## 场景篇

### 架构设计中有哪些技术点？

- **分层**

分层是企业应用系统中最常见的一种架构模式，将系统在横向维度上切分成几个部分，每个部分负责一部分相对简单并比较单一的职责，然后通过上层对下层的依赖和调度组成一个完整的系统。

在网站的分层架构中，常见的为3层，即`应用层`、`服务层`、`数据层`:

1. 应用层具体负责业务和视图的展示；
2. 服务层为应用层提供服务支持；
3. 数据库提供数据存储访问服务，如数据库、缓存、文件、搜索引擎等。

分层架构是逻辑上的，在物理部署上，三层架构可以部署在同一个物理机器上，但是随着网站业务的发展，必然需要对已经分层的模块分离部署，即三层结构分别部署在不同的服务器上，是网站拥有更多的计算资源以应对越来越多的用户访问。

所以虽然分层架构模式最初的目的是规划软件清晰的逻辑结构以便于开发维护，但在网站的发展过程中，分层结构对网站支持高并发向分布式方向的发展至关重要。

- **分隔**

如果说分层是将软件在横向方面进行切分，那么分隔就是在纵向方面对软件进行切分。

网站越大，功能越复杂，服务和数据处理的种类也越多，将这些不同的功能和服务分隔开来，包装成高内聚低耦合的模块单元，不仅有助于软件的开发维护也便于不同模块的分布式部署，提高网站的并发处理能力和功能扩展能力。

大型网站分隔的粒度可能会很小。比如在应用层，将不同业务进行分隔，例如将购物、论坛、搜索、广告分隔成不同的应用，有对立的团队负责，部署在不同的服务器上。

- **分布式**

对于大型网站，分层和分隔的一个主要目的是为了切分后的模块便于分布式部署，即将不同模块部署在不同的服务器上，通过远程调用协同工作。分布式意味着可以使用更多的计算机完同样的工作，计算机越多，CPU、内存、存储资源就越多，能过处理的并发访问和数据量就越大，进而能够为更多的用户提供服务。

在网站应用中，常用的分布式方案有一下几种.

1. `分布式应用和服务`：将分层和分隔后的应用和服务模块分布式部署，可以改善网站性能和并发性、加快开发和发布速度、减少数据库连接资源消耗。
2. `分布式静态资源`：网站的静态资源如JS、CSS、Logo图片等资源对立分布式部署，并采用独立的域名，即人们常说的动静分离。静态资源分布式部署可以减轻应用服务器的负载压力；通过使用独立域名加快浏览器并发加载的速度。
3. `分布式数据和存储`：大型网站需要处理以P为单位的海量数据，单台计算机无法提供如此大的存储空间，这些数据库需要分布式存储。
4. `分布式计算`：目前网站普遍使用Hadoop和MapReduce分布式计算框架进行此类批处理计算，其特点是移动计算而不是移动数据，将计算程序分发到数据所在的位置以加速计算和分布式计算。

- **集群**

对于用户访问集中的模块需要将独立部署的服务器集群化，即多台服务器部署相同的应用构成一个集群，通过负载均衡设备共同对外提供服务。

服务器集群能够为相同的服务提供更多的并发支持，因此当有更多的用户访问时，只需要向集群中加入新的机器即可；另外可以实现当其中的某台服务器发生故障时，可以通过负载均衡的失效转移机制将请求转移至集群中其他的服务器上，因此可以提高系统的可用性。

- **缓存**

缓存目的就是减轻服务器的计算，使数据直接返回给用户。在现在的软件设计中，缓存已经无处不在。具体实现有CDN、反向代理、本地缓存、分布式缓存等。

使用缓存有两个条件：访问数据热点不均衡，即某些频繁访问的数据需要放在缓存中；数据在某个时间段内有效，不过很快过期，否则会因为数据过期而脏读，影响数据的正确性。

- **异步**

使用异步，业务之间的消息传递不是同步调用，而是将一个业务操作分成多个阶段，每个阶段之间通过共享数据的方法异步执行进行协作。

具体实现则在单一服务器内部可用通过多线程共享内存对了的方式处理；在分布式系统中可用通过分布式消息队列来实现异步。

异步架构的典型就是生产者消费者方式，两者不存在直接调用。

- **冗余**

网站需要7×24小时连续运行，那么就得有相应的冗余机制，以防某台机器宕掉时无法访问，而冗余则可以通过部署至少两台服务器构成一个集群实现服务高可用。数据库除了定期备份还需要实现冷热备份。甚至可以在全球范围内部署灾备数据中心。

- **自动化**

具体有自动化发布过程，自动化代码管理、自动化测试、自动化安全检测、自动化部署、自动化监控、自动化报警、自动化失效转移、自动化失效恢复等。

- **安全**

网站在安全架构方面有许多模式：通过密码和手机校验码进行身份认证；登录、交易需要对网络通信进行加密；为了防止机器人程序滥用资源，需要使用验证码进行识别；对常见的XSS攻击、SQL注入需要编码转换；垃圾信息需要过滤等。

- **敏捷性**

积极接受需求变更，快速响应业务发展需求。

### 如何设计高并发应用？

整理思路分为三个角度：

1、横向扩展：采用分布式部署的方式把流量分流开，让每个服务器都承担一部分并发和流量。

2、缓存：使用缓存来提高系统的性能。

3、异步：在某些场景下，未处理完成之前，我们可以让请求先返回，在数据准备好之后再通知请求方，这样可以在单位时间内处理更多的请求。

### 如何设计高可用应用？

造成网站不可用的原因可能有：服务器硬件故障；发布新应用的过程；应用程序本身的问题。因此对应的，需要从系统设计和系统运维两方面来做保障高可用。

在系统设计方面，采用冗余部署多个节点，实现故障转移；设计降级策略保证核心服务稳定，防止雪崩导致整体应用不可用；设计限流策略，对并发限速来保护系统。

在系统运维方面，实现数据备份、异地容灾；发布应用以灰度发布逐步上线。

### 如何设计高性能应用？

性能上的优化分为两个方面，一是增加系统的并行处理能力，二是提高单次任务的响应时间。

针对第一方面，可以考虑增加线程、增加服务机器的方式。

针对第二方面，首先要看应用是 CPU 密集型还是 IO 密集型的。CPU 密集型系统中，需要处理大量的 CPU 运算，那么选用更高效的算法或者减少运算次数就是这类系统重要的优化手段；IO 密集型系统指的是系统的大部分操作是在等待 IO 完成，这类系统的性能瓶颈可能出在系统内部，也可能是依赖的其他系统，可以通过监控定位性能瓶颈，进而优化。

常见的一些优化手段有：

- 缓存（分布式缓存，本地缓存）
- 地理位置相关（GSLB，异地多活，单元化，让用户更容易访问到数据）
- 读写分离
- 同步变异步
- 串行改并行
- 池化技术（线程池连接池）
- 合并IO（例如数据库多次操作合并成一次）
- 优化网络，升级硬件设备

### 三高整体解决思路？

在前端方面：浏览器优化技术：合理布局，页面缓存，减少http请求数，页面压缩，减少 cookie 传输、CDN、DNS、动静分离、动态图片独立提供服务、反向代理 

在应用层反面：业务拆分、负载均衡、虚拟化服务器、容器化、无状态（以及分布式 Session）、分布式缓存、异步、事件驱动架构、多线程、动态页面静态化

在服务层架构方面：分布式微服务（分级管理，超时设置，异步调用，服务降级，幂等性设计。）

在存储层架构方面：DFS、数据同步、数据冗余

在安全架构方面：Web攻击（XSS、Sql Injection）、数据加密、密钥管理

在发布、运维方面：自动化测试与发布、灰度发布、浏览器数据采集、服务器业务数据采集、服务器性能数据采集、系统监控、系统报警

在机房方面：散热、省电、定制服务器

------

著作权归@pdai所有 原文链接：https://pdai.tech/md/interview/x-interview-2.html

## 应用场景设计篇

### 近一个小时访问频率最高的10个IP

实时输出最近一个小时内访问频率最高的10个IP，要求：

- 实时输出
- 从当前时间向前数的1个小时
- QPS可能会达到10W/s

解决方案：

1. QPS是 10万/秒，即一秒内最高有 10万个请求，那么一个小时内就有 100000*3600=360000000≈228.4228.4，向上取整，大概是 229229个请求，也不是很大。我们在内存中建立3600个`HashMap`，放在一个数组里，每秒对应一个HashMap，IP地址为key, 出现次数作为value。这样，一个小时内最多有229229个pair，每个pair占8字节，总内存大概是 229×8=232229×8=232字节，即4GB，单机完全可以存下。
2. 同时还要新建一个固定大小为10的小根堆，用于存放当前出现次数最大的10个IP。堆顶是10个IP里频率最小的IP。
3. 每次来一个请求，就把该秒对应的HashMap里对应的IP计数器增1，并查询该IP是否已经在堆中存在，
   - 如果不存在，则把该IP在3600个HashMap的计数器加起来，与堆顶IP的出现次数进行比较，如果大于堆顶元素，则替换掉堆顶元素，如果小于，则什么也不做
   - 如果已经存在，则把堆中该IP的计数器也增1，并调整堆
4. 需要有一个后台常驻线程，每过一秒，把最旧的那个HashMap销毁，并为当前这一秒新建一个HashMap，这样维持一个一小时的窗口。
5. 每次查询top 10的IP地址时，把堆里10个IP地址返回来即可。







