@autoHeader: 2.1.1.1.1.1


<p align="right">update time : {docsify-updated}</p>

## 缓存应用

在高并发的业务场景下，数据库大多数情况都是用户并发访问最薄弱的环节。

一般需要使用redis做一个缓冲操作，让请求先访问到redis，而不是直接访问Mysql等数据库。这样可以大大缓解数据库的压力。

作为缓存应用时，必须要考虑如下问题：

- 缓存穿透
- 缓存穿击
- 缓存雪崩
- 缓存污染
- 缓存一致性

### 缓存穿透

#### 问题描述

缓存穿透是指**缓存和数据库中都没有的数据**，而用户不断发起请求。由于缓存是不命中时被动写的，并且出于容错考虑，如果从存储层查不到数据则不写入缓存，这将导致这个不存在的数据每次请求都要到存储层去查询，失去了缓存的意义。

在流量大时，可能DB就挂掉了，要是有人利用不存在的key频繁攻击我们的应用，这就是漏洞，如发起为id为“-1”的数据或id为特别大不存在的数据。这时的用户很可能是攻击者，攻击会导致数据库压力过大。

#### 解决方案

1. 在业务层面增加校验，不符合业务规则的请求直接拦截掉。如用户鉴权校验，id做基础校验，id<=0的直接拦截；
2. 在缓存和数据库都没有取到的数据，将key-value写入对应的key-null，缓存时间有效期设置短一些，如多少秒，防止影响正常业务。这样可以防止用户暴力攻击。
3. 使用布隆过滤器。详见下一小节。

#### 布隆过滤器

布隆过滤器可以用于快速检索一个元素是否在一个集合中。

##### 实现原理

当一个元素被加入集合时，通过K个散列函数将这个元素映射成一个位数组中的K个点，把它们置为1。

检索时，我们只要看看这些点是不是都是1就（大约）知道集合中有没有它了：如果这些点有任何一个0，则被检元素一定不在；如果都是1，则被检元素很可能在。

![image-20230811174805441](Redis%E5%AE%9E%E6%88%98.assets/image-20230811174805441.png)

这个思想就是哈希，那和单哈希函数的不同之处呢？不同之处就是，Bloom Filter使用了k个哈希函数，每个字符串跟k个bit对应，比单哈希函数减少了哈希冲突的概率。

##### 优缺点

它的优点是时间和空间上的查询效率高。

缺点是有一定的误识别率和删除困难：

- 存在误判，可能要查到的元素并没有在容器中，但是hash之后得到的k个位置上值都是1。如果bloom filter中存储的是黑名单，那么可以通过建立一个白名单来存储可能会误判的元素。

- 删除困难。一个放入容器的元素映射到bit数组的k个位置上是1，删除的时候不能简单的直接置为0，可能会影响其他元素的判断。

##### 使用方式

在使用bloom filter时，绕不过的两点是预估数据量n以及期望的误判率fpp

在实现bloom filter时，绕不过的两点就是hash函数的选取以及bit数组的大小

对于一个确定的场景，需要的信息包括：

1、要存的数据量为n

2、期望的误判率为fpp

3、计算我们需要的Bit数组的大小m，以及hash函数的个数k，并选择hash函数

Step1：Bit数组大小

根据预估数据量n以及误判率fpp，bit数组大小的m的计算方式：

![img](Redis%E5%AE%9E%E6%88%98.assets/333333.png)

Step2：哈希函数选择，k个哈希函数都用不同的会有些麻烦，选择一个哈希函数，然后送入k个不同的参数

预估数据量n以及bit数组长度m，可以得到一个hash函数的个数k

![img](Redis%E5%AE%9E%E6%88%98.assets/16e112fbd09afad.png)

Step3：实现

```java
<dependency>
            <groupId>com.google.guava</groupId>
            <artifactId>guava</artifactId>
            <version>23.0</version>
 </dependency>   

public class TestBloomFilter {

    private static int total = 1000000;
  //创建布隆过滤器
    private static BloomFilter<Integer> bf = BloomFilter.create(Funnels.integerFunnel(), total, 0.0001);

    public static void main(String[] args) {
        // 初始化1000000条数据到过滤器中
        for (int i = 0; i < total; i++) {
            bf.put(i);
        }

        // 匹配已在过滤器中的值，是否有匹配不上的
        for (int i = 0; i < total; i++) {
            if (!bf.mightContain(i)) {
                System.out.println("有坏人逃脱了~~~");
            }
        }

        // 匹配不在过滤器中的10000个值，有多少匹配出来
        int count = 0;
        for (int i = total; i < total + 10000; i++) {
            if (bf.mightContain(i)) {
                count++;
            }
        }
        System.out.println("误伤的数量：" + count);
    }
}
```

##### 应用场景

应用于量大、但允许出现一定误差的场景下，如常见的：

- 爬虫过滤已抓到的url就不再抓，可用bloom filter过滤。
- 垃圾邮件过滤。

### 缓存击穿

#### 问题描述

缓存击穿是一个热点的Key，有大并发集中对其进行访问，突然间这个Key失效了，导致大并发全部打在数据库上，导致数据库压力剧增。

#### 解决方案

从两个方面解决：第一是否可以考虑热点key不设置过期时间。第二是否可以考虑降低打在数据库上的请求数量

1. 设置热点数据永远不过期。
2. 加互斥锁：第一个请求的线程可以拿到锁，拿到锁的线程查询到数据之后设置缓存，其他的线程获取锁失败后会等待50ms，然后重新到缓存中获取数据，这样就可以避免大量的请求落到数据库中。

> 加锁的思想代码：
>
> ```java
> public Object getData(String key) throws InterruptedException {
>     Object value = redis.get(key);
>     // 缓存值过期
>     if (value == null) {
>         // lockRedis：专门用于加锁的redis；
>         // "empty"：加锁的值随便设置都可以
>         if (lockRedis.set(key, "empty", "PX", lockExpire, "NX")) {
>             try {
>                 // 查询数据库，并写到缓存，让其他线程可以直接走缓存
>                 value = getDataFromDb(key);
>                 redis.set(key, value, "PX", expire);
>             } catch (Exception e) {
>                 // 异常处理
>             } finally {
>                 // 释放锁
>                 lockRedis.delete(key);
>             }
>         } else {
>             // sleep50ms后，进行重试
>             Thread.sleep(50);
>             return getData(key);
>         }
>     }
>     return value;
> }
> ```
>
> 

### 缓存雪崩

#### 问题描述

当某一个时刻出现大规模的缓存失效的情况，那么就会导致大量的请求直接打在数据库上面，导致数据库压力巨大，如果在高并发的情况下，可能瞬间就会导致数据库宕机。

这时候如果运维马上又重启数据库，马上又会有新的流量把数据库打死。

#### 解决方案

造成缓存雪崩的关键在于在同一时间大规模的key失效。为什么会出现这个问题呢，有几种可能，第一种可能是Redis宕机，第二种可能是采用了相同的过期时间。

对应的解决方案有：

1. 在原有的失效时间上加上一个随机值，比如1-5分钟随机。这样就避免了因为采用相同的过期时间导致的缓存雪崩。
2. 为了防止Redis宕机导致缓存雪崩的问题，可以搭建Redis集群，提高Redis的容灾性。
3. 使用接口限流和熔断机制。当流量到达一定的阈值时，就直接返回“系统拥挤”之类的提示，防止过多的请求打在数据库上。至少能保证一部分用户是可以正常使用，其他用户多刷新几次也能得到结果。
4. 提高数据库的容灾能力，可以使用分库分表，读写分离的策略。

### 缓存污染

#### 问题描述

缓存污染问题说的是缓存中一些只会被访问一次或者几次的的数据，被访问完后，再也不会被访问到，但这部分数据依然留存在缓存中，消耗缓存空间。

缓存污染会随着数据的持续增加而逐渐显露，随着服务的不断运行，缓存中会存在大量的永远不会再次被访问的数据。缓存空间是有限的，如果缓存空间满了，再往缓存里写数据时就会有额外开销，影响Redis性能。这部分额外开销主要是指写的时候判断淘汰策略，根据淘汰策略去选择要淘汰的数据，然后进行删除操作。

#### 解决方案

根据业务特性选择合适的内存淘汰策略。

Redis中8种内存淘汰策略，[详细内存淘汰机制笔记](./Redis核心机制.md)；其中noviction策略不涉及数据淘汰，因此讨论剩下的7种策略算法，根据应用场景，选择适当的内存淘汰策略。

| 内存淘汰机制                      | 适用场景                                                 | 描述                                                         |
| --------------------------------- | -------------------------------------------------------- | ------------------------------------------------------------ |
| volatile-random 和 allkeys-random | 无                                                       | 随机挑选数据的方式，在避免缓存污染这个问题上的效果非常有限。 |
| volatile-ttl                      | 业务层明确知道数据的访问时长，如具有有效期的数据访问链接 | 给数据设置合理的过期时间，再设置redis缓存使用volatile-ttl策略。当缓存写满时，剩余存活时间最短的数据就会被淘汰出局，避免滞留再缓存中，造成污染 |
| volatile-lru和allkeys-lru         | 数据被频繁访问的业务场景                                 | 在数据被频繁访问的业务场景中，LRU 策略的确能有效留存访问时间最近的数据。<br>但是，也正是因为只看数据的访问时间，使用 LRU 策略在处理扫描式单次查询操作时，无法解决缓存污染。扫描式单次查询操作，就是指应用对大量的数据进行一次全体读取，每个数据都会被读取，而且只会被读取一次。此时，因为这些被查询的数据刚刚被访问过，所以 lru 字段值都很大。 |
| volatile-lfu和allkeys-lfu         | 扫描式查询的应用场景                                     | LFU 策略更加关注数据的访问频次，在扫描式查询的应用场景中，LFU 策略就可以很好地应对缓存污染问题。<br>但在数据的请求模式大多不稳定的情况，LFU策略有明显的缺陷：在短期的时间内，对某些缓存的访问频次很高，这些缓存会立刻晋升为热点数据，而保证不会淘汰，这样会驻留在系统内存里面。而实际上，这部分数据只是短暂的高频率访问，之后将会长期不访问，瞬时的高频访问将会造成这部分数据的引用频率加快，而一些新加入的缓存很容易被快速删除。 |

#### 缓存容量如何设置

大容量缓存是能带来性能加速的收益，但是成本也会更高，而小容量缓存不一定就起不到加速访问的效果。一般来说，**建议把缓存容量设置为总数据量的 15% 到 30%，兼顾访问性能和内存空间开销**。

### 缓存一致性

#### 问题描述

缓存与数据库一致性问题指的在数据更新时，读取到缓存和数据库之间的数据不一致的情况。

（1）先更新数据库，再更新缓存  --- 产生脏数据

![image-20230814193035535](Redis%E5%AE%9E%E6%88%98.assets/image-20230814193035535.png)

同时有请求A和请求B进行更新操作，那么会出现

1. 线程A更新了数据库
2. 线程B更新了数据库
3. 线程B更新了缓存
4. 线程A更新了缓存

这就出现请求A更新缓存应该比请求B更新缓存早才对，但是因为网络等原因，B却比A更早更新了缓存。这就导致了脏数据，因此不考虑。

（2）先更新缓存，后更新数据库 --- 脏数据

![image-20230814193146625](Redis%E5%AE%9E%E6%88%98.assets/image-20230814193146625.png)

1. A 请求先将缓存的数据更新为 1
2. 然后在更新数据库前，B 请求来了
3. B将缓存的数据更新为 2
4. B将数据库更新为 2
5. A 请求将数据库的数据更新为 1

（3）先删缓存，再更新数据库 --- 产生脏数据

同时有一个请求A进行更新操作，另一个请求B进行查询操作。那么会出现如下情形:

1. 请求A进行写操作，删除缓存
2. 请求B查询发现缓存不存在
3. 请求B去数据库查询得到旧值
4. 请求B将旧值写入缓存
5. 请求A将新值写入数据库

（3）先更新数据库，再删缓存 --- cache aside 见下

#### 解决方案

对于应用缓存的大部分场景来说，追求的则是最终一致性，少部分对数据一致性要求极高的场景则会追求强一致性。

在解决缓存一致性的过程中，有多种途径可以保证缓存的最终一致性，应该根据场景来设计合适的方案：

1、读多写少的场景下，可以选择采用“ Cache-Aside + 消费数据库日志补偿机制”的方案

2、写多的场景下，可以选择采用“ Write-Through + 分布式锁”的方案 

3、写多的极端场景下，可以选择采用“ Write-Behind ” 的方案

##### Cache aside

**1.读写流程**

Cache-Aside 意为旁路缓存模式，是应用最为广泛的一种缓存策略。

- 读的时候，先读缓存，缓存没有的话，就读数据库，然后取出数据后放入缓存，同时返回响应。
- 更新的时候，先更新数据库，然后再删除缓存。

![image-20230814194429016](Redis%E5%AE%9E%E6%88%98.assets/image-20230814194429016.png)

**2. 为什么是删除缓存，而不是更新缓存？**

很多时候，在复杂点的缓存场景，缓存不单单是数据库中直接取出来的值。比如可能更新了某个表的一个字段，然后其对应的缓存，是需要查询另外两个表的数据并进行运算，才能计算出缓存最新的值的。

另外更新缓存的代价有时候是很高的。是不是说，每次修改数据库的时候，都一定要将其对应的缓存更新一份？也许有的场景是这样，但是对于比较复杂的缓存数据计算的场景，就不是这样了。如果你频繁修改一个缓存涉及的多个表，缓存也频繁更新，但该缓存可能并没有被访问到。其实删除缓存，而不是更新缓存，就是一个 lazy 计算的思想，不要每次都重新做复杂的计算，不管它会不会用到，而是让它到需要被使用的时候再重新计算。

**3. 是不是Cache Aside这个就不会有并发问题了？**

不是的，比如，一个请求A做查询操作，一个请求B做更新操作：

1. A读缓存未命中，读取数据库得到一个旧值
2. B更新数据库
3. B删除缓存
4.  A将旧值写入缓存

![image-20230814194700308](Redis%E5%AE%9E%E6%88%98.assets/image-20230814194700308.png)

理论上会出现，但实际上出现的概率可能非常低，因为这个条件需要发生在读缓存时缓存失效，而且并发着有一个写操作。而实际上数据库的写操作会比读操作慢得多，而且还要锁表，而读操作必需在写操作前进入数据库操作，而又要晚于写操作更新缓存，所有的这些条件都具备的概率基本并不大。

除此之外，在并发环境下，Cache-Aside 中也存在读请求命中缓存的时间点在写请求更新数据库之后，删除缓存之前，这样也会导致读请求查询到的缓存落后于数据库的情况：

![image-20230814194723071](Redis%E5%AE%9E%E6%88%98.assets/image-20230814194723071.png)

**4. 该设计模式下，如何解决一致性问题**

（一）延时双删

为了避免“先删除缓存，再更新数据库”这一方案在读写并发时可能带来的缓存脏数据，业界又提出了延时双删的策略，即在更新数据库之后，延迟一段时间再次删除缓存，为了保证第二次删除缓存的时间点在读请求更新缓存之后，这个延迟时间的经验值通常应稍大于业务中读请求的耗时。

1）先删除缓存

2）再写数据库

3）休眠 n 毫秒

4）再次删除缓存

延迟的实现可以在代码中 `sleep` 或采用延迟队列。

显而易见的是，无论这个值如何预估，都很难和读请求的完成时间点准确衔接，这也是延时双删被诟病的主要原因。

（二）消息队列补偿机制



##### Read/Write through

在 Cache Aside 中，应用层需要和两个数据源打交道：缓存、数据库，这增加了应用层的复杂度，能否只和一个数据源打交道？

Read/Write Through 就是用来解决这个问题的，该模式下应用层只和缓存打交道，由缓存去操作和维护数据库。



**1.1 Read Through**

Read-Through 意为读穿透模式，在查询操作中更新缓存。应用层查询数据时，当缓存未命中时，由缓存去查询数据库，并且将结果写入缓存中，最后返回结果给应用层。



**1.2 Write Through**

Write-Through 意为直写模式。应用层更新数据时，由缓存去更新数据库。

- 如果没有命中缓存，直接更新数据库，然后返回
- 如果命中了缓存，则更新缓存，然后再由Cache自己更新数据库（这是一个同步操作）

![image-20230814190536488](Redis%E5%AE%9E%E6%88%98.assets/image-20230814190536488.png)



**2. 优势**

这种方式的优势在于读请求过程简单，不需要查询数据库更新缓存等操作。

**3.劣势**

除了上面的弊端之外，这种方案还会造成更新效率低，并且两个写操作任何一次写失败都会造成数据不一致。

**4.该模式下如何保证一致性**

更新将更新数据库、更新缓存两个操作作为事务处理，可以同时失败或者同时成功，支持回滚，并且防止并发环境下的不一致。

##### Write behind cache

Write Behind 又叫 Write Back，也是Linux文件系统的Page Cache的算法。

> Linux 中的 page cache（页缓存）采用的就是 write back 机制：用户 write 时只是将数据写到 page cache，并标记为 dirty，并没有真正写到硬盘上 。内核在某个时刻会将 page cache 里的 dirty 数据 wirteback 到硬盘上。

**在更新数据的时候，只更新缓存，不更新数据库，异步地批量更新数据库。适合大量写操作的场景，常用于电商秒杀场景中库存的扣减。**

![image-20230814190944493](Redis%E5%AE%9E%E6%88%98.assets/image-20230814190944493.png)



**2.优势**

1. 因为直接操作内存，I/O操作飞快无比
2. 因为异步，write backg还可以合并对同一个数据的多次操作，提高性能

**3.缺点**

1. 复杂度高；
2. 更新后的数据还未写入数据库时，如果此时出现系统断电的情况，数据将无法找回。

####  补偿机制

存在更新数据库成功，但删除缓存失败的场景，如果发生这种情况，那么便会导致缓存中的数据落后于数据库，产生数据的不一致的问题。针对可能出现的删除失败问题，目前业界主要有以下几种补偿机制：

##### 删除重试机制

先更新数据库，成功后往消息队列发消息，消费到消息后再删除缓存，借助消息队列的重试机制来实现，达到最终一致性的效果。

由于同步重试删除在性能上会影响吞吐量，所以常通过引入消息队列，将删除失败的缓存对应的 `key` 放入消息队列中，在对应的消费者中获取删除失败的 `key` ，异步重试删除。这种方法在实现上相对简单，但由于删除失败后的逻辑需要基于业务代码的 trigger 来触发 ，对业务代码具有一定入侵性。

![image-20230814195124790](Redis%E5%AE%9E%E6%88%98.assets/image-20230814195124790.png)

##### 基于数据库日志（ MySQL binlog ）

上述方案对业务代码具有一定入侵性，所以需要一种更加优雅的解决方案，让缓存删除失败的补偿机制运行在背后，尽量少的耦合于业务代码。

一个相对成熟的方案是基于 MySQL 数据库增量日志进行解析和消费，可以借助监听binlog的消息队列来做删除缓存的操作。

这样做的好处是，不用自己引入消息队列，侵入到你的业务代码中，中间件帮你做了解耦，同时，中间件的这个东西本身就保证了高可用。

![image-20230814195501199](Redis%E5%AE%9E%E6%88%98.assets/image-20230814195501199.png)



## Redis性能突然变差，如何排查问题

也许或多或少地，也遇到过以下这些场景：

- 在 Redis 上执行同样的命令，为什么有时响应很快，有时却很慢？
- 为什么 Redis 执行 SET、DEL 命令耗时也很久？
- 为什么我的 Redis 突然慢了一波，之后又恢复正常了？
- 为什么我的 Redis 稳定运行了很久，突然从某个时间点开始变慢了？
- ...

如何排查定位这些问题？

![image-20230815211303053](Redis%E5%AE%9E%E6%88%98.assets/image-20230815211303053.png)

### 排查服务内部

首先排查服务内部，究竟是哪个环节拖慢了整个服务。比较高效的做法是，在服务内部集成链路追踪，也就是在服务访问外部依赖的出入口，记录下每次请求外部依赖的响应延时。

从你的业务服务到 Redis 这条链路变慢的原因可能也有 2 个：

1. 业务服务器到 Redis 服务器之间的网络存在问题，例如网络线路质量不佳，网络数据包在传输时存在延迟、丢包等情况
2. Redis 本身存在问题，需要进一步排查是什么原因导致 Redis 变慢

通常来说，第一种情况发生的概率比较小，如果是服务器之间网络存在问题，那部署在这台业务服务器上的所有服务都会发生网络延迟的情况，此时需要联系网络运维同事，让其协助解决网络问题。

### Redis基准测试，是否真的是Redis变慢

基准性能就是指 Redis 在一台负载正常的机器上，其最大的响应延迟和平均响应延迟，用下述的命令，查看一段时间内 Redis 的最小、最大、平均访问延迟：

```bash
redis-cli -h 127.0.0.1 -p 6379 --latency-history -i 1
```

具体步骤：

1. 在相同配置的服务器上，测试一个正常 Redis 实例的基准性能
2. 在认为可能变慢的 Redis 实例，测试这个实例的基准性能
3. 如果这个实例的运行延迟是正常 Redis 基准性能的 2 倍以上，即可认为这个 Redis 实例确实变慢了

### 查看慢日志

Redis 提供了慢日志命令的统计功能，它记录了有哪些命令在执行时耗时比较久。

查看 Redis 慢日志之前，需要设置慢日志的阈值。例如，设置慢日志的阈值为 5 毫秒，并且保留最近 500 条慢日志记录：

```text
# 命令执行耗时超过 5 毫秒，记录慢日志
CONFIG SET slowlog-log-slower-than 5000
# 只保留最近 500 条慢日志
CONFIG SET slowlog-max-len 500
```

设置完成之后，所有执行的命令如果操作耗时超过了 5 毫秒，都会被 Redis 记录下来。

此时，你可以执行SLOWLOG命令，就可以查询到最近记录的慢日志：

```text
127.0.0.1:6379> SLOWLOG get 5
1) 1) (integer) 32693       # 慢日志ID
   2) (integer) 1593763337  # 执行时间戳
   3) (integer) 5299        # 执行耗时(微秒)
   4) 1) "LRANGE"           # 具体执行的命令和参数
      2) "user_list:2000"
      3) "0"
      4) "-1"
2) 1) (integer) 32692
   2) (integer) 1593763337
   3) (integer) 5044
   4) 1) "GET"
      2) "user_info:1000"
...
```

通过查看慢日志，我们就可以知道在什么时间点，执行了哪些命令比较耗时。

通过慢日志中的命令特点排查问题：

#### 慢日志命令中复杂度高O(N)的命令

比如：

1. O(N) 以上复杂度的命令，例如 SORT、SUNION、ZUNIONSTORE 聚合类命令
2. O(N) 复杂度的命令，而且 N 的值非常大

此时观察资源使用率，很可能出现Redis并发不高，但CPU使用率很高的情况，这种情况很有可能使用了复杂度过高的命令导致的。Redis 是单线程处理客户端请求的，如果你经常使用以上命令，那么当 Redis 处理客户端请求时，一旦前面某个命令发生耗时，就会导致后面的请求发生排队，对于客户端来说，响应延迟也会变长。

**解决方案**

优化业务代码：

1. 尽量不使用 O(N) 以上复杂度过高的命令，对于数据的聚合操作，放在客户端做
2. 执行 O(N) 命令，保证 N 尽量的小（推荐 N <= 300），每次获取尽量少的数据，让 Redis 可以及时处理返回

#### 慢日志命令中都是SET等简单命令

查询慢日志发现，并不是复杂度过高的命令导致的，而都是 SET / DEL 这种简单命令出现在慢日志中，需要考虑实例否写入了 bigkey。如果一个 key 写入的 value 非常大，那么 Redis 在分配内存时就会比较耗时。同样的，当删除这个 key 时，释放内存也会比较耗时，这种类型的 key 我们一般称之为 bigkey。

此时，你需要检查你的业务代码，是否存在写入 bigkey 的情况。你需要评估写入一个 key 的数据大小，尽量避免一个 key 存入过大的数据。

> Redis 提供了扫描 bigkey 的命令，执行以下命令就可以扫描出，一个实例中 bigkey 的分布情况，输出结果是以类型维度展示的：
>
> ```shell
> $ redis-cli -h 127.0.0.1 -p 6379 --bigkeys -i 0.01
> 
> ...
> -------- summary -------
> 
> Sampled 829675 keys in the keyspace!
> Total key length in bytes is 10059825 (avg len 12.13)
> 
> Biggest string found 'key:291880' has 10 bytes
> Biggest   list found 'mylist:004' has 40 items
> Biggest    set found 'myset:2386' has 38 members
> Biggest   hash found 'myhash:3574' has 37 fields
> Biggest   zset found 'myzset:2704' has 42 members
> 
> 36313 strings with 363130 bytes (04.38% of keys, avg size 10.00)
> 787393 lists with 896540 items (94.90% of keys, avg size 1.14)
> 1994 sets with 40052 members (00.24% of keys, avg size 20.09)
> 1990 hashs with 39632 fields (00.24% of keys, avg size 19.92)
> 1985 zsets with 39750 members (00.24% of keys, avg size 20.03)
> ```
>
> 从输出结果我们可以很清晰地看到，每种数据类型所占用的最大内存 / 拥有最多元素的 key 是哪一个，以及每种数据类型在整个实例中的占比和平均大小 / 元素数量。
>
> 这个命令的原理，就是 Redis 在内部执行了 SCAN 命令，遍历整个实例中所有的 key，然后针对 key 的类型，分别执行 STRLEN、LLEN、HLEN、SCARD、ZCARD 命令，来获取 String 类型的长度、容器类型（List、Hash、Set、ZSet）的元素个数。
>
> 需要注意的是：
>
> 1. 对线上实例进行 bigkey 扫描时**，Redis 的 OPS 会突增，为了降低扫描过程中对 Redis 的影响，最好控制一下扫描的频率，指定 -i 参数即可**，它表示扫描过程中每次扫描后休息的时间间隔，单位是秒
> 2. 扫描结果中，**对于容器类型（List、Hash、Set、ZSet）的 key，只能扫描出元素最多的 key。但一个 key 的元素多，不一定表示占用内存也多，还需要根据业务情况，进一步评估内存占用情况**

**解决方案**

有几点可以优化：

1. 业务应用尽量避免写入 bigkey
2. 如果使用的 Redis 是 4.0 以上版本，用 UNLINK 命令替代 DEL，此命令可以把释放 key 内存的操作，放到后台线程中去执行，从而降低对 Redis 的影响，但依然应该避免写入bigkey
3. 如果使用的 Redis 是 6.0 以上版本，可以开启 lazy-free 机制（lazyfree-lazy-user-del = yes），在执行 DEL 命令时，释放内存也会放到后台线程中执行

#### 慢日志中无耗时命令

当发现慢日志正常的时候，需要在现象或者资源角度排查：

##### 现象上有集中延迟

- 现象

如果发现平时在操作 Redis 时，并没有延迟很大的情况发生，但在某个时间点突然出现一波延时，其现象表现为：变慢的时间点很有规律，例如某个整点，或者每间隔多久就会发生一波延迟。

需要排查业务代码中是否存在设置大量 key 集中过期的情况。

- 原因

因为key主动过期的任务是在主线程中执行的，也就是说如果在执行主动过期的过程中，出现了需要大量删除过期 key 的情况，那么此时应用程序在访问 Redis 时，必须要等待这个过期任务执行结束，Redis 才可以服务这个客户端请求，此时就会出现，应用访问 Redis 延时变大，而且，**这个操作延迟的命令并不会记录在慢日志中**。因为慢日志中**只记录一个命令真正操作内存数据的耗时**，而 Redis 主动删除过期 key 的逻辑，是在命令真正执行之前执行的。所以，慢日志中没有操作耗时的命令，但应用程序却感知到了延迟变大。

- 解决方案

需要检查业务代码，是否存在集中过期 key 的逻辑，一般集中过期使用的是 expireat / pexpireat 命令，一般有两种方案规避这个问题：

1. 集中过期 key 增加一个随机过期时间，把集中过期的时间打散，降低 Redis 清理过期 key 的压力
2. 如果使用的 Redis 是 4.0 以上版本，可以开启 lazy-free 机制，当删除过期 key 时，把释放内存的操作放到后台线程中执行，避免阻塞主线程

##### 现象上写入新数据延迟变慢

- 现象

如果 Redis 实例设置了内存上限 maxmemory，那么也有可能导致 Redis 变慢。当实例的内存达到了 maxmemory 后，你可能会发现，在此之后每次写入新数据，操作延迟变大了。

- 原因

当 Redis 内存达到 maxmemory 后，每次写入新的数据之前，Redis 必须先从实例中踢出一部分数据，让整个实例的内存维持在 maxmemory 之下，然后才能把新数据写进来。

- 解决方案

1. 根据业务情况，选择何时的内存淘汰策略。
2. 避免存储 bigkey，降低释放内存的耗时
3. 拆分实例，把淘汰 key 的压力分摊到多个实例上
4. 如果使用的是 Redis 4.0 以上版本，开启 layz-free 机制，把淘汰 key 释放内存的操作放到后台线程中执行（配置 lazyfree-lazy-eviction = yes）

##### 延迟发生在持久化期间

- 现象

在定时RDB或者AOF重写持久化期间发送延迟

- 原因

这部分的原因包含很多因素：

**1 fork子进程耗时严重**

后台 RDB 和 AOF rewrite 后，在执行时，它们都需要主进程创建出一个子进程进行数据的持久化。主进程创建子进程，会调用操作系统提供的 fork 函数。而 fork 在执行过程中，**主进程需要拷贝自己的内存页表给子进程**，如果这个实例很大，那么这个拷贝的过程也会比较耗时。

在完成 fork 之前，整个 Redis 实例会被阻塞住，无法处理任何客户端请求。如果此时CPU 资源本来就很紧张，那么 fork 的耗时会更长，甚至达到秒级，这会严重影响 Redis 的性能。

那如何确认确实是因为 fork 耗时导致的 Redis 延迟变大呢？

在 Redis 上执行 **INFO** 命令，查看 latest_fork_usec 项，单位微秒。

```text
# 上一次 fork 耗时，单位微秒
latest_fork_usec:59477
```

这个时间就是主进程在 fork 子进程期间，整个实例阻塞无法处理客户端请求的时间。



**2 开启了内存大页导致耗时**

应用程序向操作系统申请内存时，是按**内存页**进行申请的，而常规的内存页大小是 4KB。Linux 内核从 2.6.38 开始，支持了**内存大页机制**，该机制允许应用程序以 2MB 大小为单位，向操作系统申请内存。应用程序每次向操作系统申请的内存单位变大了，但这也意味着申请内存的耗时变长。

主进程在拷贝内存数据时，这个阶段就涉及到新内存的申请，如果此时操作系统开启了内存大页，那么在此期间，客户端即便只修改 10B 的数据，Redis 在申请内存时也会以 2MB 为单位向操作系统申请，申请内存的耗时变长，进而导致每个写请求的延迟增加，影响到 Redis 性能。

查看 Redis 机器是否开启了内存大页：

```text
$ cat /sys/kernel/mm/transparent_hugepage/enabled
[always] madvise never
```

如果输出选项是 always，就表示目前开启了内存大页机制。



**3 AOF 重写时IO紧张导致耗时**

- 解决方案

**1 针对fork子进程耗时**

1. 控制 Redis 实例的内存：尽量在 10G 以下，执行 fork 的耗时与实例大小有关，实例越大，耗时越久
2. 合理配置数据持久化策略：在 slave 节点执行 RDB 备份，推荐在低峰期执行，而对于丢失数据不敏感的业务（例如把 Redis 当做纯缓存使用），可以关闭 AOF 和 AOF rewrite
3. Redis 实例不要部署在虚拟机上：fork 的耗时也与系统也有关，虚拟机比物理机耗时更久
4. 降低主从库全量同步的概率：适当调大 repl-backlog-size 参数，避免主从全量同步

**2 针对内存大页**

关闭内存大页机制。

```shell
$ echo never > /sys/kernel/mm/transparent_hugepage/enabled
```

**3 针对AOF重写时IO紧张**

1. 如果占用磁盘资源的是其他应用程序，定位到是哪个应用程序在大量写磁盘，然后把这个应用程序迁移到其他机器上执行就好了，避免对 Redis 产生影响。

2. 如果是Redis本身AOF重写导致的IO紧张，Redis 提供了一个配置项，当子进程在 AOF rewrite 期间，可以让后台子线程不执行刷盘（不触发 fsync 系统调用）操作。

这相当于在 AOF rewrite 期间，临时把 appendfsync 设置为了 none，配置如下：

```text
# AOF rewrite 期间，AOF 后台子线程不进行刷盘操作
# 相当于在这期间，临时把 appendfsync 设置为了 none
no-appendfsync-on-rewrite yes
```

当然，开启这个配置项，在 AOF rewrite 期间，如果实例发生宕机，那么此时会丢失更多的数据，性能和数据安全性，你需要权衡后进行选择。

3. 如果对 Redis 的性能和数据安全都有很高的要求，那么建议从**硬件层面**来优化，更换为 SSD 磁盘，提高磁盘的 IO 能力，保证 AOF 期间有充足的磁盘资源可以使用。

##### 其他资源配置上

**1 是否绑定了CPU**

- 原因

 Redis 在绑定 CPU 时，是有很多考究的，如果不了解 Redis 的运行原理，随意绑定 CPU 不仅不会提高性能，甚至有可能会带来相反的效果。

一般现代的服务器会有多个 CPU，而每个 CPU 又包含多个物理核心，每个物理核心又分为多个逻辑核心，每个物理核下的逻辑核共用 L1/L2 Cache。

而 Redis Server 除了主线程服务客户端请求之外，还会创建子进程、子线程。

其中子进程用于数据持久化，而子线程用于执行一些比较耗时操作，例如异步释放 fd、异步 AOF 刷盘、异步 lazy-free 等等。

如果把 Redis 进程只绑定了一个 CPU 逻辑核心上，那么当 Redis 在进行数据持久化时，fork 出的子进程会继承父进程的 CPU 使用偏好。**此时的子进程会消耗大量的 CPU 资源进行数据持久化（把实例数据全部扫描出来需要耗费CPU），这就会导致子进程会与主进程发生 CPU 争抢，进而影响到主进程服务客户端请求，访问延迟变大。**

这就是 Redis 绑定 CPU 带来的性能问题。

- 解决

可以优化的方案是，不要让 Redis 进程只绑定在一个 CPU 逻辑核上，而是绑定在多个逻辑核心上，而且，绑定的多个逻辑核心最好是同一个物理核心，这样它们还可以共用 L1/L2 Cache。

当然，即便我们把 Redis 绑定在多个逻辑核心上，也只能在一定程度上缓解主线程、子进程、后台线程在 CPU 资源上的竞争。

因为这些子进程、子线程还是会在这多个逻辑核心上进行切换，存在性能损耗。

进一步优化可以让主线程、子进程、后台线程，分别绑定在固定的 CPU 核心上，不让它们来回切换，这样一来，他们各自使用的 CPU 资源互不影响。

其实，这个方案 Redis 官方已经想到了。

Redis 在 6.0 版本已经推出了这个功能，我们可以通过以下配置，对主线程、后台线程、后台 RDB 进程、AOF rewrite 进程，绑定固定的 CPU 逻辑核心：

```text
# Redis Server 和 IO 线程绑定到 CPU核心 0,2,4,6
server_cpulist 0-7:2

# 后台子线程绑定到 CPU核心 1,3
bio_cpulist 1,3

# 后台 AOF rewrite 进程绑定到 CPU 核心 8,9,10,11
aof_rewrite_cpulist 8-11

# 后台 RDB 进程绑定到 CPU 核心 1,10,11
# bgsave_cpulist 1,10-1
```

一般来说，Redis 的性能已经足够优秀，除非对 Redis 的性能有更加严苛的要求，否则不建议绑定 CPU。



**2 是否使用了swap**

- 原因

发现 Redis 突然变得非常慢，**每次的操作耗时都达到了几百毫秒甚至秒级**，那此时就需要检查 Redis 是否使用到了 Swap，在这种情况下 Redis 基本上已经无法提供高性能的服务了。

操作系统为了缓解内存不足对应用程序的影响，允许把一部分内存中的数据换到磁盘上，以达到应用程序对内存使用的缓冲，这些内存数据被换到磁盘上的区域，就是 Swap。

问题就在于，当内存中的数据被换到磁盘上后，Redis 再访问这些数据时，就需要从磁盘上读取，访问磁盘的速度要比访问内存慢几百倍。尤其是针对 Redis 这种对性能要求极高、性能极其敏感的数据库来说，这个操作延时是无法接受的。

此时，需要检查 Redis 机器的内存使用情况，确认是否存在使用了 Swap。

可以通过以下方式来查看 Redis 进程是否使用到了 Swap：

```shell
# 先找到 Redis 的进程 ID
$ ps -aux | grep redis-server

# 查看 Redis Swap 使用情况
$ cat /proc/$pid/smaps | egrep '^(Swap|Size)'
```

- 解决方案

此时的解决方案是：

1. 增加机器的内存，让 Redis 有足够的内存可以使用
2. 整理内存空间，释放出足够的内存供 Redis 使用，然后释放 Redis 的 Swap，让 Redis 重新使用内存



**3 是否使用了碎片整理**

- 原因

开启内存碎片整理，也有可能会导致 Redis 性能下降。

原因在于，Redis 的碎片整理工作是也在**主线程**中执行的，当其进行碎片整理时，必然会消耗 CPU 资源，产生更多的耗时，从而影响到客户端的请求。

Redis 碎片整理的参数配置如下：

```text
# 开启自动内存碎片整理（总开关）
activedefrag yes

# 内存使用 100MB 以下，不进行碎片整理
active-defrag-ignore-bytes 100mb

# 内存碎片率超过 10%，开始碎片整理
active-defrag-threshold-lower 10
# 内存碎片率超过 100%，尽最大努力碎片整理
active-defrag-threshold-upper 100

# 内存碎片整理占用 CPU 资源最小百分比
active-defrag-cycle-min 1
# 内存碎片整理占用 CPU 资源最大百分比
active-defrag-cycle-max 25

# 碎片整理期间，对于 List/Set/Hash/ZSet 类型元素一次 Scan 的数量
active-defrag-max-scan-fields 1000
```

- 解决方案

需要结合 Redis 机器的负载情况，以及应用程序可接受的延迟范围进行评估，合理调整碎片整理的参数，尽可能降低碎片整理期间对 Redis 的影响。



## 大key问题



## 运维监控



