@autoHeader: 2.1.1.1.1.1


<p align="right">update time : {docsify-updated}</p>

## 缓存应用

在高并发的业务场景下，数据库大多数情况都是用户并发访问最薄弱的环节。

一般需要使用redis做一个缓冲操作，让请求先访问到redis，而不是直接访问Mysql等数据库。这样可以大大缓解数据库的压力。

作为缓存应用时，必须要考虑如下问题：

- 缓存穿透
- 缓存穿击
- 缓存雪崩
- 缓存污染
- 缓存一致性

### 缓存穿透

#### 问题描述

缓存穿透是指**缓存和数据库中都没有的数据**，而用户不断发起请求。由于缓存是不命中时被动写的，并且出于容错考虑，如果从存储层查不到数据则不写入缓存，这将导致这个不存在的数据每次请求都要到存储层去查询，失去了缓存的意义。

在流量大时，可能DB就挂掉了，要是有人利用不存在的key频繁攻击我们的应用，这就是漏洞，如发起为id为“-1”的数据或id为特别大不存在的数据。这时的用户很可能是攻击者，攻击会导致数据库压力过大。

#### 解决方案

1. 在业务层面增加校验，不符合业务规则的请求直接拦截掉。如用户鉴权校验，id做基础校验，id<=0的直接拦截；
2. 在缓存和数据库都没有取到的数据，将key-value写入对应的key-null，缓存时间有效期设置短一些，如多少秒，防止影响正常业务。这样可以防止用户暴力攻击。
3. 使用布隆过滤器。详见下一小节。

#### 布隆过滤器

布隆过滤器可以用于快速检索一个元素是否在一个集合中。

##### 实现原理

当一个元素被加入集合时，通过K个散列函数将这个元素映射成一个位数组中的K个点，把它们置为1。

检索时，我们只要看看这些点是不是都是1就（大约）知道集合中有没有它了：如果这些点有任何一个0，则被检元素一定不在；如果都是1，则被检元素很可能在。

![image-20230811174805441](Redis%E5%AE%9E%E6%88%98.assets/image-20230811174805441.png)

这个思想就是哈希，那和单哈希函数的不同之处呢？不同之处就是，Bloom Filter使用了k个哈希函数，每个字符串跟k个bit对应，比单哈希函数减少了哈希冲突的概率。

##### 优缺点

它的优点是时间和空间上的查询效率高。

缺点是有一定的误识别率和删除困难：

- 存在误判，可能要查到的元素并没有在容器中，但是hash之后得到的k个位置上值都是1。如果bloom filter中存储的是黑名单，那么可以通过建立一个白名单来存储可能会误判的元素。

- 删除困难。一个放入容器的元素映射到bit数组的k个位置上是1，删除的时候不能简单的直接置为0，可能会影响其他元素的判断。

##### 使用方式

在使用bloom filter时，绕不过的两点是预估数据量n以及期望的误判率fpp

在实现bloom filter时，绕不过的两点就是hash函数的选取以及bit数组的大小

对于一个确定的场景，需要的信息包括：

1、要存的数据量为n

2、期望的误判率为fpp

3、计算我们需要的Bit数组的大小m，以及hash函数的个数k，并选择hash函数

Step1：Bit数组大小

根据预估数据量n以及误判率fpp，bit数组大小的m的计算方式：

![img](Redis%E5%AE%9E%E6%88%98.assets/333333.png)

Step2：哈希函数选择，k个哈希函数都用不同的会有些麻烦，选择一个哈希函数，然后送入k个不同的参数

预估数据量n以及bit数组长度m，可以得到一个hash函数的个数k

![img](Redis%E5%AE%9E%E6%88%98.assets/16e112fbd09afad.png)

Step3：实现

```java
<dependency>
            <groupId>com.google.guava</groupId>
            <artifactId>guava</artifactId>
            <version>23.0</version>
 </dependency>   

public class TestBloomFilter {

    private static int total = 1000000;
  //创建布隆过滤器
    private static BloomFilter<Integer> bf = BloomFilter.create(Funnels.integerFunnel(), total, 0.0001);

    public static void main(String[] args) {
        // 初始化1000000条数据到过滤器中
        for (int i = 0; i < total; i++) {
            bf.put(i);
        }

        // 匹配已在过滤器中的值，是否有匹配不上的
        for (int i = 0; i < total; i++) {
            if (!bf.mightContain(i)) {
                System.out.println("有坏人逃脱了~~~");
            }
        }

        // 匹配不在过滤器中的10000个值，有多少匹配出来
        int count = 0;
        for (int i = total; i < total + 10000; i++) {
            if (bf.mightContain(i)) {
                count++;
            }
        }
        System.out.println("误伤的数量：" + count);
    }
}
```

##### 应用场景

应用于量大、但允许出现一定误差的场景下，如常见的：

- 爬虫过滤已抓到的url就不再抓，可用bloom filter过滤。
- 垃圾邮件过滤。

### 缓存击穿

#### 问题描述

缓存击穿是一个热点的Key，有大并发集中对其进行访问，突然间这个Key失效了，导致大并发全部打在数据库上，导致数据库压力剧增。

#### 解决方案

从两个方面解决：第一是否可以考虑热点key不设置过期时间。第二是否可以考虑降低打在数据库上的请求数量

1. 设置热点数据永远不过期。
2. 加互斥锁：第一个请求的线程可以拿到锁，拿到锁的线程查询到数据之后设置缓存，其他的线程获取锁失败后会等待50ms，然后重新到缓存中获取数据，这样就可以避免大量的请求落到数据库中。

> 加锁的思想代码：
>
> ```java
> public Object getData(String key) throws InterruptedException {
>     Object value = redis.get(key);
>     // 缓存值过期
>     if (value == null) {
>         // lockRedis：专门用于加锁的redis；
>         // "empty"：加锁的值随便设置都可以
>         if (lockRedis.set(key, "empty", "PX", lockExpire, "NX")) {
>             try {
>                 // 查询数据库，并写到缓存，让其他线程可以直接走缓存
>                 value = getDataFromDb(key);
>                 redis.set(key, value, "PX", expire);
>             } catch (Exception e) {
>                 // 异常处理
>             } finally {
>                 // 释放锁
>                 lockRedis.delete(key);
>             }
>         } else {
>             // sleep50ms后，进行重试
>             Thread.sleep(50);
>             return getData(key);
>         }
>     }
>     return value;
> }
> ```
>
> 

### 缓存雪崩

#### 问题描述

当某一个时刻出现大规模的缓存失效的情况，那么就会导致大量的请求直接打在数据库上面，导致数据库压力巨大，如果在高并发的情况下，可能瞬间就会导致数据库宕机。

这时候如果运维马上又重启数据库，马上又会有新的流量把数据库打死。

#### 解决方案

造成缓存雪崩的关键在于在同一时间大规模的key失效。为什么会出现这个问题呢，有几种可能，第一种可能是Redis宕机，第二种可能是采用了相同的过期时间。

对应的解决方案有：

1. 在原有的失效时间上加上一个随机值，比如1-5分钟随机。这样就避免了因为采用相同的过期时间导致的缓存雪崩。
2. 为了防止Redis宕机导致缓存雪崩的问题，可以搭建Redis集群，提高Redis的容灾性。
3. 使用接口限流和熔断机制。当流量到达一定的阈值时，就直接返回“系统拥挤”之类的提示，防止过多的请求打在数据库上。至少能保证一部分用户是可以正常使用，其他用户多刷新几次也能得到结果。
4. 提高数据库的容灾能力，可以使用分库分表，读写分离的策略。

### 缓存污染

#### 问题描述

缓存污染问题说的是缓存中一些只会被访问一次或者几次的的数据，被访问完后，再也不会被访问到，但这部分数据依然留存在缓存中，消耗缓存空间。

缓存污染会随着数据的持续增加而逐渐显露，随着服务的不断运行，缓存中会存在大量的永远不会再次被访问的数据。缓存空间是有限的，如果缓存空间满了，再往缓存里写数据时就会有额外开销，影响Redis性能。这部分额外开销主要是指写的时候判断淘汰策略，根据淘汰策略去选择要淘汰的数据，然后进行删除操作。

#### 解决方案

根据业务特性选择合适的内存淘汰策略。

Redis中8种内存淘汰策略，[详细内存淘汰机制笔记](./Redis核心机制.md)；其中noviction策略不涉及数据淘汰，因此讨论剩下的7种策略算法，根据应用场景，选择适当的内存淘汰策略。

| 内存淘汰机制                      | 适用场景                                                 | 描述                                                         |
| --------------------------------- | -------------------------------------------------------- | ------------------------------------------------------------ |
| volatile-random 和 allkeys-random | 无                                                       | 随机挑选数据的方式，在避免缓存污染这个问题上的效果非常有限。 |
| volatile-ttl                      | 业务层明确知道数据的访问时长，如具有有效期的数据访问链接 | 给数据设置合理的过期时间，再设置redis缓存使用volatile-ttl策略。当缓存写满时，剩余存活时间最短的数据就会被淘汰出局，避免滞留再缓存中，造成污染 |
| volatile-lru和allkeys-lru         | 数据被频繁访问的业务场景                                 | 在数据被频繁访问的业务场景中，LRU 策略的确能有效留存访问时间最近的数据。<br>但是，也正是因为只看数据的访问时间，使用 LRU 策略在处理扫描式单次查询操作时，无法解决缓存污染。扫描式单次查询操作，就是指应用对大量的数据进行一次全体读取，每个数据都会被读取，而且只会被读取一次。此时，因为这些被查询的数据刚刚被访问过，所以 lru 字段值都很大。 |
| volatile-lfu和allkeys-lfu         | 扫描式查询的应用场景                                     | LFU 策略更加关注数据的访问频次，在扫描式查询的应用场景中，LFU 策略就可以很好地应对缓存污染问题。<br>但在数据的请求模式大多不稳定的情况，LFU策略有明显的缺陷：在短期的时间内，对某些缓存的访问频次很高，这些缓存会立刻晋升为热点数据，而保证不会淘汰，这样会驻留在系统内存里面。而实际上，这部分数据只是短暂的高频率访问，之后将会长期不访问，瞬时的高频访问将会造成这部分数据的引用频率加快，而一些新加入的缓存很容易被快速删除。 |

#### 缓存容量如何设置

大容量缓存是能带来性能加速的收益，但是成本也会更高，而小容量缓存不一定就起不到加速访问的效果。一般来说，**建议把缓存容量设置为总数据量的 15% 到 30%，兼顾访问性能和内存空间开销**。

### 缓存一致性

#### 问题描述

缓存与数据库一致性问题指的在数据更新时，读取到缓存和数据库之间的数据不一致的情况。

（1）先更新数据库，再更新缓存  --- 产生脏数据

![image-20230814193035535](Redis%E5%AE%9E%E6%88%98.assets/image-20230814193035535.png)

同时有请求A和请求B进行更新操作，那么会出现

1. 线程A更新了数据库
2. 线程B更新了数据库
3. 线程B更新了缓存
4. 线程A更新了缓存

这就出现请求A更新缓存应该比请求B更新缓存早才对，但是因为网络等原因，B却比A更早更新了缓存。这就导致了脏数据，因此不考虑。

（2）先更新缓存，后更新数据库 --- 脏数据

![image-20230814193146625](Redis%E5%AE%9E%E6%88%98.assets/image-20230814193146625.png)

1. A 请求先将缓存的数据更新为 1
2. 然后在更新数据库前，B 请求来了
3. B将缓存的数据更新为 2
4. B将数据库更新为 2
5. A 请求将数据库的数据更新为 1

（3）先删缓存，再更新数据库 --- 产生脏数据

同时有一个请求A进行更新操作，另一个请求B进行查询操作。那么会出现如下情形:

1. 请求A进行写操作，删除缓存
2. 请求B查询发现缓存不存在
3. 请求B去数据库查询得到旧值
4. 请求B将旧值写入缓存
5. 请求A将新值写入数据库

（3）先更新数据库，再删缓存 --- cache aside 见下

#### 解决方案

对于应用缓存的大部分场景来说，追求的则是最终一致性，少部分对数据一致性要求极高的场景则会追求强一致性。

在解决缓存一致性的过程中，有多种途径可以保证缓存的最终一致性，应该根据场景来设计合适的方案：

1、读多写少的场景下，可以选择采用“ Cache-Aside + 消费数据库日志补偿机制”的方案

2、写多的场景下，可以选择采用“ Write-Through + 分布式锁”的方案 

3、写多的极端场景下，可以选择采用“ Write-Behind ” 的方案

##### Cache aside

**1.读写流程**

Cache-Aside 意为旁路缓存模式，是应用最为广泛的一种缓存策略。

- 读的时候，先读缓存，缓存没有的话，就读数据库，然后取出数据后放入缓存，同时返回响应。
- 更新的时候，先更新数据库，然后再删除缓存。

![image-20230814194429016](Redis%E5%AE%9E%E6%88%98.assets/image-20230814194429016.png)

**2. 为什么是删除缓存，而不是更新缓存？**

很多时候，在复杂点的缓存场景，缓存不单单是数据库中直接取出来的值。比如可能更新了某个表的一个字段，然后其对应的缓存，是需要查询另外两个表的数据并进行运算，才能计算出缓存最新的值的。

另外更新缓存的代价有时候是很高的。是不是说，每次修改数据库的时候，都一定要将其对应的缓存更新一份？也许有的场景是这样，但是对于比较复杂的缓存数据计算的场景，就不是这样了。如果你频繁修改一个缓存涉及的多个表，缓存也频繁更新，但该缓存可能并没有被访问到。其实删除缓存，而不是更新缓存，就是一个 lazy 计算的思想，不要每次都重新做复杂的计算，不管它会不会用到，而是让它到需要被使用的时候再重新计算。

**3. 是不是Cache Aside这个就不会有并发问题了？**

不是的，比如，一个请求A做查询操作，一个请求B做更新操作：

1. A读缓存未命中，读取数据库得到一个旧值
2. B更新数据库
3. B删除缓存
4.  A将旧值写入缓存

![image-20230814194700308](Redis%E5%AE%9E%E6%88%98.assets/image-20230814194700308.png)

理论上会出现，但实际上出现的概率可能非常低，因为这个条件需要发生在读缓存时缓存失效，而且并发着有一个写操作。而实际上数据库的写操作会比读操作慢得多，而且还要锁表，而读操作必需在写操作前进入数据库操作，而又要晚于写操作更新缓存，所有的这些条件都具备的概率基本并不大。

除此之外，在并发环境下，Cache-Aside 中也存在读请求命中缓存的时间点在写请求更新数据库之后，删除缓存之前，这样也会导致读请求查询到的缓存落后于数据库的情况：

![image-20230814194723071](Redis%E5%AE%9E%E6%88%98.assets/image-20230814194723071.png)

**4. 该设计模式下，如何解决一致性问题**

（一）延时双删

为了避免“先删除缓存，再更新数据库”这一方案在读写并发时可能带来的缓存脏数据，业界又提出了延时双删的策略，即在更新数据库之后，延迟一段时间再次删除缓存，为了保证第二次删除缓存的时间点在读请求更新缓存之后，这个延迟时间的经验值通常应稍大于业务中读请求的耗时。

1）先删除缓存

2）再写数据库

3）休眠 n 毫秒

4）再次删除缓存

延迟的实现可以在代码中 `sleep` 或采用延迟队列。

显而易见的是，无论这个值如何预估，都很难和读请求的完成时间点准确衔接，这也是延时双删被诟病的主要原因。

（二）消息队列补偿机制



##### Read/Write through

在 Cache Aside 中，应用层需要和两个数据源打交道：缓存、数据库，这增加了应用层的复杂度，能否只和一个数据源打交道？

Read/Write Through 就是用来解决这个问题的，该模式下应用层只和缓存打交道，由缓存去操作和维护数据库。



**1.1 Read Through**

Read-Through 意为读穿透模式，在查询操作中更新缓存。应用层查询数据时，当缓存未命中时，由缓存去查询数据库，并且将结果写入缓存中，最后返回结果给应用层。



**1.2 Write Through**

Write-Through 意为直写模式。应用层更新数据时，由缓存去更新数据库。

- 如果没有命中缓存，直接更新数据库，然后返回
- 如果命中了缓存，则更新缓存，然后再由Cache自己更新数据库（这是一个同步操作）

![image-20230814190536488](Redis%E5%AE%9E%E6%88%98.assets/image-20230814190536488.png)



**2. 优势**

这种方式的优势在于读请求过程简单，不需要查询数据库更新缓存等操作。

**3.劣势**

除了上面的弊端之外，这种方案还会造成更新效率低，并且两个写操作任何一次写失败都会造成数据不一致。

**4.该模式下如何保证一致性**

更新将更新数据库、更新缓存两个操作作为事务处理，可以同时失败或者同时成功，支持回滚，并且防止并发环境下的不一致。

##### Write behind cache

Write Behind 又叫 Write Back，也是Linux文件系统的Page Cache的算法。

> Linux 中的 page cache（页缓存）采用的就是 write back 机制：用户 write 时只是将数据写到 page cache，并标记为 dirty，并没有真正写到硬盘上 。内核在某个时刻会将 page cache 里的 dirty 数据 wirteback 到硬盘上。

**在更新数据的时候，只更新缓存，不更新数据库，异步地批量更新数据库。适合大量写操作的场景，常用于电商秒杀场景中库存的扣减。**

![image-20230814190944493](Redis%E5%AE%9E%E6%88%98.assets/image-20230814190944493.png)



**2.优势**

1. 因为直接操作内存，I/O操作飞快无比
2. 因为异步，write backg还可以合并对同一个数据的多次操作，提高性能

**3.缺点**

1. 复杂度高；
2. 更新后的数据还未写入数据库时，如果此时出现系统断电的情况，数据将无法找回。

####  补偿机制

存在更新数据库成功，但删除缓存失败的场景，如果发生这种情况，那么便会导致缓存中的数据落后于数据库，产生数据的不一致的问题。针对可能出现的删除失败问题，目前业界主要有以下几种补偿机制：

##### 删除重试机制

先更新数据库，成功后往消息队列发消息，消费到消息后再删除缓存，借助消息队列的重试机制来实现，达到最终一致性的效果。

由于同步重试删除在性能上会影响吞吐量，所以常通过引入消息队列，将删除失败的缓存对应的 `key` 放入消息队列中，在对应的消费者中获取删除失败的 `key` ，异步重试删除。这种方法在实现上相对简单，但由于删除失败后的逻辑需要基于业务代码的 trigger 来触发 ，对业务代码具有一定入侵性。

![image-20230814195124790](Redis%E5%AE%9E%E6%88%98.assets/image-20230814195124790.png)

##### 基于数据库日志（ MySQL binlog ）

上述方案对业务代码具有一定入侵性，所以需要一种更加优雅的解决方案，让缓存删除失败的补偿机制运行在背后，尽量少的耦合于业务代码。

一个相对成熟的方案是基于 MySQL 数据库增量日志进行解析和消费，可以借助监听binlog的消息队列来做删除缓存的操作。

这样做的好处是，不用自己引入消息队列，侵入到你的业务代码中，中间件帮你做了解耦，同时，中间件的这个东西本身就保证了高可用。

![image-20230814195501199](Redis%E5%AE%9E%E6%88%98.assets/image-20230814195501199.png)

## 性能调优



## 运维监控



