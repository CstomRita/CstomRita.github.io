@autoHeader: 2.1.1.1.1.1


<p align="right">update time : {docsify-updated}</p>

## 基础篇

### Redis有哪些数据类型，使用场景？

Redis的基础数据类型包括5种：字符串String、字典Hash存储键值对、列表List存储多个有序的字符串、集合Set存储无序、非重复的字符串集合、有序集合SortedSet对存储元素进行排序。

Redis中还有三种扩展类型，基数统计类型可以统计一批数据中抛去重复元素后的集合；位存储类型用于存储仅有0和1状态的元素，可用于状态标记等场景；地理信息类型提供了关于地理信息方面的计算功能。

### Redis是单线程还是多线程？

Redis在执行命令时是单线程的。

除了主线程外，也有一些后台线程处理一些较为缓慢的操作，比如释放无用连接等。

### Redis底层结构是什么？ //todo



### Redis管道技术？

管道技术（Pipeline）是客户端提供的一种批处理技术，用于一次处理多个 Redis 命令，从而提高整个交互的性能，把多个命令整合到一起发送给服务器端处理之后统一返回给客户端，这样就免去了每条命令执行后都要等待的情况，从而有效地提高了程序的执行效率。

## 持久化

### Redis如何实现持久化？

Redis实现持久化方案分为RDB和AOF两种。

RDB持久化是把当前进程数据生成快照保存到硬盘的过程，通过RDB文件可以还原数据库的状态。

AOF持久化以独立日志的方式记录每次写命令， 重启时再重新执行AOF文件中的命令达到恢复数据的目的。

### RDB和AOF的触发时机？

RDB分为主动触发和自动触发两种方式：

- 主动触发对应save和bgsave命令。
  - save命令：阻塞当前Redis服务器，直到RDB过程完成为止，对于内存比较大的实例会造成长时间阻塞，线上环境不建议使用。

  - bgsave命令：Redis进程执行fork操作创建子进程，RDB持久化过程由子进程负责，完成后自动结束。
- 被动触发RDB的场景主要包括：
  - 使用save相关配置，如“save m n”。表示m秒内数据集存在n次修改时，自动触发bgsave。
  - 如果从节点执行全量复制操作，主节点自动执行bgsave生成RDB文件并发送给从节点
  - 执行debug reload命令重新加载Redis时，也会自动触发save操作
  - 默认情况下执行shutdown命令时，如果没有开启AOF持久化功能则自动执行bgsave

AOF每次命令执行后都会写入缓冲区，对于缓冲区和磁盘日志的文件时机，Redis提供了三种配置机制，通过配置参数选定：

- Always：每个写append命令执行完，立马同步地将日志写回磁盘。
- EverySec：每隔一秒把缓冲区中的内容写入磁盘
- No：由操作系统决定何时将缓冲区内容写回磁盘，由操作系统定期或当io缓冲区填满时，自动将io缓冲区的数据写入到aof文件。

### RDB和AOF的执行流程？

【一】RDB，如果是Save命令则由主进程执行备份，若为bgsave命令由子进程备份，以bgsave命令执行流程为例：

- 若为bgsave命令，主进程判断当前是否已经存在正在执行的子进程，如果存在，那么主进程直接返回；如果不存在正在执行的子进程，那么就fork一个新的子进程进行持久化数据，fork过程是阻塞的，fork操作完成后主进程即可执行其他操作；
- 备份进程先将数据写入到临时的rdb文件中，待快照数据写入完成后再原子替换旧的rdb文件；
- 同时发送信号给主进程，通知主进程rdb持久化完成。

【二】AOF日志记录Redis的每个写命令，步骤分为：

1. 命令追加（append）：服务器每执行一个写命令，都会把该命令以协议格式先追加到AOF文件的内存缓存区的末尾，而不是直接写入文件，避免每次有命令都直接写入硬盘，减少硬盘IO次数

2. 文件写入（write）：将AOF缓存区的内容写入IO缓冲区。

3. 文件同步（fsync）：将IO缓冲区的内容同步到磁盘上的AOF文件。

### RDB和AOF的优缺点，如何选择？

**RDB | 优点**

1. 只有一个紧凑的二进制文件，非常适合备份、全量复制的场景。
2. 容灾性好，可以把RDB文件拷贝道远程机器或者文件系统张，用于容灾恢复。
3. 恢复速度快，RDB恢复数据的速度远远快于AOF的方式

**RDB | 缺点**

1. 实时性低，RDB 是间隔一段时间进行持久化，没法做到实时持久化/秒级持久化。如果在这一间隔事件发生故障，数据会丢失。
2. 存在兼容问题，Redis演进过程存在多个格式的RDB版本，存在老版本Redis无法兼容新版本RDB的问题。

**AOF | 优点**

1. **实时性好**，aof 持久化可以配置 `appendfsync` 属性，有 `always`，每进行一次命令操作就记录到 aof 文件中一次，数据更完整，
2. AOF文件是一个只进行追加的日志文件，且写入操作是以Redis协议的格式保存的，内容是可读的，适合误删紧急恢复

**AOF | 缺点**

1. 对于相同的数据集，AOF文件的体积要大于RDB文件，数据恢复也会比较慢

【如何选择】在实际使用中：

- 一般情况下，通常同时使用RDB和AOF混合持久化机制，使用RDB机制进行数据快照，AOF日志中记录持久化开始至持久化结束的增量日志，Redis重启时先加载RDB 的内容，然后再重放增量 AOF 日志进行数据恢复。
- 特殊情况下：如果可以接受部分数据丢失的话，可以选择用RDB持久化方式；如果业务中对Redis中的数据不敏感、能从别的地方找回，也可以不做持久化。

### Redis如何进行数据恢复？

把RDB或者AOF文件拷贝到Redis的数据目录下，直接启动Redis即可，Redis会自动加载数据，加载流程为：

1. AOF持久化开启且存在AOF文件时，优先加载AOF文件，其中会在AOF文件中判断是否开启了混合模式，如果包含REDIS开头，则证明开启了持久化，则先载入RDB，再载入AOF；否则优先载入AOF。
2. AOF关闭或者AOF文件不存在时，加载RDB文件。
3. 加载AOF/RDB文件成功后，Redis启动成功。
4. AOF/RDB文件存在错误时，Redis启动失败并打印错误信息。

## 内存淘汰、过期删除

### Redis有哪些内存淘汰策略

Redis中有八种内存淘汰策略：

1、一种不淘汰数据，也是默认的淘汰策略：noeviction（Redis3.0之后，默认的内存淘汰策略） ：它表示当运行内存超过最大设置内存时，不淘汰任何数据，这时如果有新的数据写入，会报错通知禁止写入，不淘汰任何数据，但是如果没用数据写入的话，只是单纯的查询或者删除操作的话，还是可以正常工作。

2、在设置了过期时间的数据中进行淘汰的四种机制：

- volatile-random：随机淘汰设置了过期时间的任意键值；
- volatile-ttl：优先淘汰更早过期的键值。
- volatile-lru（Redis3.0 之前，默认的内存淘汰策略）：淘汰所有设置了过期时间的键值中，最久未使用的键值；
- volatile-lfu（Redis 4.0 后新增的内存淘汰策略）：淘汰所有设置了过期时间的键值中，最少使用的键值；

3、在所有数据范围内进行淘汰的三种机制：

- allkeys-random：随机淘汰任意键值;
- allkeys-lru：淘汰整个键值中最久未使用的键值；
- allkeys-lfu（Redis 4.0 后新增的内存淘汰策略）：淘汰整个键值中最少使用的键值。

### Redis的过期删除机制

Redis 是可以对 key 设置过期时间的，因此需要有相应的机制将已过期的键值对删除，过期删除机制包括：

1、定时删除

在设置 key 的过期时间时，同时创建一个定时事件，当时间到达时，由事件处理器自动执行 key 的删除操作。

可以保证过期 key 会被尽快删除，也就是内存可以被尽快地释放；但在过期key比较多时，会对CPU造成压力。

2、惰性删除

不主动删除过期键，每次从数据库访问 key 时，都检测 key 是否过期，如果过期则删除该 key。

这种方式的优点是占用的系统资源少，但缺点是只要这个过期 key 一直没有被访问，它所占用的内存就不会释放，造成了一定的内存空间浪费。

3、定期删除

每隔一段时间「随机」从数据库中取出一定数量的 key 进行检查，并删除其中的过期key。

这种方式在定时和惰性之间做了平衡，但缺点是难以确定删除操作执行的时长和频率。

在Redis中， 选择了「惰性删除+定期删除」这两种策略配合使用。

## 事务

### Redis事务支持回滚吗？

不支持回滚。

- 作者认为发生事务回滚的原因大部分都是程序错误导致，这种情况一般发生在开发和测试阶段，而生产环境很少出现。
- 对于逻辑性错误，比如本来应该把一个数加 1，但是程序逻辑写成了加2，那么这种错误也是无法通过事务回滚来进行解决的。
- Redis追求的是简单高效，而传统事务的实现相对比较复杂，这和 Redis的设计思想相违背。

### Redis事务支持ACID吗？

Redis的事务机制可满足原子性、一致性、隔离性，不满足持久性。

原子性：官方给出的解释是Redis的事务是原子性的：所有的命令，要么全部执行，要么全部不执行，但不是完全成功。

一致性指的就是事务执行前后的数据符合数据库的定义和要求。这一点 `Redis` 中的事务是符合要求的，上面讲述原子性的时候已经提到，不论是发生语法错误还是运行时错误，错误的命令均不会被执行。

可以使用watch命令满足隔离性：并发操作在 `EXEC` 命令前执行，隔离性需要通过 `WATCH` 机制保证；并发操作在 `EXEC` 命令之后，隔离性可以保证。

redis事务是不保证持久性的，这是因为redis持久化策略中不管是RDB还是AOF都是异步执行的，都存在数据丢失的情况。

## 高可用-哨兵

### 大致说一下主从复制？

主从复制，是指将一台 Redis 服务器的数据，复制到其他的 Redis 服务器。前者称为主节点，后者称为 从节点。数据的复制是单向的，只能由主节点到从节点，Redis 主从复制支持主从同步和从从同步两种。

主从复制是Redis高可用的基础，他可以：

- 实现数据冗余： 主从复制实现了数据的热备份，是持久化之外的一种数据冗余方式。
- 实现故障恢复： 当主节点出现问题时，可以由从节点提供服务，实现快速的故障恢复 。
- 实现负载均衡： 在主从复制的基础上，配合读写分离，可以由主节点提供写服务，由从节点提供读服，分担服务器负载。

### 主从有哪些拓扑结构？

根据拓扑复杂性可以分为以下三种：一主一从、一主多从、树状主从结构。

- 一主一从结构是最简单的复制拓扑结构，用于主节点出现宕机时从节点提供故障转移支持
- 一主多从结构使得应用端可以利用多个从节点实现读写分离，对于读占比较大的场景，可以把读命令发送到从节点来分担主节点压力
- 树状主从结构中，从节点不但可以复制主节点数据，同时可以作为其他从节点的主节点继续向下层复制。通过引入复制中间层，可以有效降低主节点负载和需要传送给从节点的数据量。

### 主从复制流程？

1. 保存主节点（master）信息：这一步只是保存主节点信息，保存主节点的ip和port。
2. 主从建立连接：从节点（slave）发现新的主节点后，会尝试和主节点建立网络连接。
3. 发送ping命令：连接建立成功后从节点发送ping请求进行首次通信，主要是检测主从之间网络套接字是否可用、主节点当前是否可接受处理命令。
4. 权限验证：如果主节点要求密码验证，从节点必须正确的密码才能通过验证。
5. 同步数据集：主从复制连接正常通信后，主节点会把持有的数据全部发送给从节点。
6. 命令持续复制：接下来主节点会持续地把写命令发送给从节点，保证主从数据一致性

### 数据同步流程？

使用psync命令完成主从数据同步，同步过程分为：全量复制和部分复制。

【全量复制】一般用于初次复制场景，会把主节点全部数据一次性发送给从节点，当数据量较大时，会对主从节点和网络造成很大的开销，其过程为：

1. 发送psync命令进行数据同步，由于是第一次进行复制，从节点没有复制偏移量和主节点的运行ID，所以发送psync-1。
2. 主节点解析出当前为全量复制，发送自己的运行ID和offset，从节点接收到并保存
3. 主节点执行bgsave保存RDB文件到本地，发送给给从节点，从节点把接收的RDB文件保存在本地作为从节点的数据文件
4. 对于从节点开始接收RDB快照到接收完成期间，主节点仍然响应读写命令，因此主节点会把这期间写命令数据保存在缓冲区内，当从节点加载完RDB文件后，主节点再把缓冲区内的数据发送给从节点，保证主从之间数据一致性。
5. 从节点接收完主节点传送来的全部数据后会清空自身旧数据，开始加载RDB文件，加载完RDB后，如果当前节点开启了AOF持久化功能， 立刻执行一次AOF重写，为了保证全量复制后AOF持久化文件立刻可用

【增量复制】针对全量复制的过高开销做出的一种优化措施：

1. 由于从节点之前保存了自身已复制的偏移量和主节点的运行ID，因此会把它们当作参数发送给主节点，要求进行部分复制操作；
2. 主节点接到命令后首先核对参数runId是否与自身一致，如果一致，说明之前复制的是当前主节点；之后根据参数offset在自身缓冲区查找；
3. 如果偏移量之后的数据存在缓冲区中，主节点把缓冲区里的数据发送给从节点，保证主从复制进入正常

### 你知道哨兵机制吗？

在主从复制中，一旦主节点出现故障，需要手动将一个从节点晋升为主节点，同时需要修改应用方的主节点地址，还需要命令其他从节点去复制新的主节点，整个过程都需要人工干预。而哨兵机制就是为了解决这个问题，实现故障自动转移的方案。

哨兵系统由一个或多个哨兵节点组成，哨兵节点是特殊的节点，不存储数据，只对数据节点进行监控：

- 会不断地检查主节点和从节点是否运作正常
- 当主节点不能正常工作时，哨兵会其中一个从节点升级为新的主节点，并让其他从节点改为复制新的主节点
- 客户端通过连接哨兵来获得当前 Redis 服务的主节点地址，当主节点发生变化时，哨兵会把更改结果发送到客户端

### 哨兵机制的运行原理？

哨兵节点通过定时监控任务实现对各个节点的发现和监控：

1. 隔10秒，每个哨兵节点会向主节点和从节点发送info命令获取最新的拓扑结构
2. 每隔2秒，每个哨兵节点会发送自己对于主节点的判断以及当前哨兵节点的信息
3. 每隔1秒，每个Sentinel节点会向其他节点发送一条ping命令做一次心跳检测，来确认这些节点当前是否可达

当某个哨兵节点发送心跳检测，超过一定时间没有进行有效回复，Sentinel节点就会对该节点做失败判定，这个行为叫做主观下线

若该节点正好是主节点，哨兵节点会向其他哨兵节点询问对主节点的判断，若超过一定数量，则确认主节点确实有问题，此时行为叫做客观下线。当下线主节点时，哨兵节点之间会选取一个leader节点进行故障转移，选出新的主节点，并通知客户端。

### 如何选取哨兵leader节点？

使用了Raft算法实现领导者选举，大致流程如下：

1. 每个在线的哨兵节点都有资格成为领导者，当它确认主节点主观下线时候，会向其他哨兵节点发送自己成为leader的请求。
2. 收到请求的哨兵节点，如果之前还没有同意过其他哨兵节点leader请求的行为，将同意该请求，否则拒绝。
3. 当某个该哨兵节点发现自己已经获得多数的票数，则成为领导者。
4. 如果此过程没有选举出领导者，等待选举时间超时后发起下一次选举。

### 如何选举新的主节点？

首先，过滤掉“不健康”（主观下线、断线）、5秒内没有回复过ping响应、与主节点失联超过一定时间的节点，在剩下的节点中：

- 优先节点优先级更高的节点，如果存在则返回，不存在则继续
- 优先选复制偏移量最大的节点，表示数据最完整的节点，如果存在则返回，不存在则继续
- 选择运行ID最小的节点

## 可拓展-集群

### Redis集群分区？

数据分区是Redis集群最核心的功能，将数据分散到多个节点，一方面突破了 Redis 单机内存大小的限制，存储容量大大增加；另一方面 每个主节点都可以对外提供读服务和写服务，大大提高了集群的响应能力。

Redis集群使用的是虚拟槽分区策略，该策略是一致性哈希分区的基础上改进，引入了虚拟节点的概念。其中，槽是介于数据和实际节点之间的虚拟概念，每个槽包含哈希值在一定范围内的数据，每个实际节点包含一定数量的槽。

在虚拟槽分区策略中，槽是数据管理和迁移的基本单位，每一个节点负责维护一部分槽以及槽所映射的键值数据，当删除节点时，只需要把该节点的哈希槽移动到其他节点即可，简化了扩容和收缩的难度。

### Redis集群如何实现故障转移？

Redis集群的故障转移和哨兵的故障转移类似，但是Redis集群中所有的节点都要承担状态维护的任务。

1. Redis集群内节点通过ping消息实现节点通信，集群中每个节点都会定期向其他节点发送ping消息，如果在一定时间内通信一直失败，则发送节点会认为接收节点存在故障，把接收节点标记为主观下线状态，并把下线节点状态在集群中广播。
2. 当半数以上的主节点都标记某个节点是主观下线时，触发客观下线流程，若该节点是主节点，则需要在从节点中再选一个主节点，选取过程为：
   - 每个从节点都要检查最后与主节点断线时间，当断线时间超过限制时，没有资格替换主节点
   - 集群中持有槽的主节点只能投票给一个从节点，当某个从节点大于N/2+1的选票时，即替换为主节点。

### Redis规模要求？

在投票选举的环节，故障主节点也算在投票数内，假设集群内节点规模是3主3从，其中有2 个主节点部署在一台机器上，当这台机器宕机时，由于从节点无法收集到 3/2+1个主节点选票将导致故障转移失败。这个问题也适用于故障发现环节。

因此部署集群时所有主节点最少需要部署在3台物理机上才能避免单点问题。

### 你还知道哪些分区策略？

常见的分区规则，除了虚拟槽之外，还有节点取余、一致性哈希：

1、节点取余分区

使用特定的数据，比如Redis的键，或者用户ID之类，对响应的hash值取余：hash（key）%N，来确定数据映射到哪一个节点上。该方案最大的问题是，当节点数量变化时，如扩容或收缩节点，数据节点映射关 系需要重新计算，会导致数据的重新迁移。

2、一致性哈希分区

将整个 Hash 值空间组织成一个虚拟的圆环，然后将缓存节点的 IP 地址或者主机名做 Hash 取值后，放置在这个圆环上。当我们需要确定某一个 Key 需 要存取到哪个节点上的时候，先对这个 Key 做同样的 Hash 取值，确定在环上的位置，然后按照顺时针方向在环上“行走”，遇到的第一个缓存节点就是要访问的节点。

这种方式相比节点取余最大的好处在于加入和删除节点只影响哈希环中相邻的节点，对其他节点无影响。

但是，缓存节点在圆环上分布不平均，会造成部分缓存节点的压力较大，且当某个节点故障时，这个节点所要承担的所有访问都会被顺移到另一个节点上，会对后面这个节点造成力。

## 应用篇

### 项目中是如何使用Redis的？

首先，使用Redis作为数据库缓存，减少数据库访问次数，例如使用String存放数据的访问路径信息，当该数据第一次访问时由数据库查询到路径信息并存放在缓存中，并设置过期时间，清理缓存。在项目中，大多数的数据请求都是分散的，会请求到各个位置区域；但是存在基础数据，在业务中访问量会比较大，因此作为热点数据，提前写入缓存中，并设置长久有效。

在项目中，对每个用户的访问次数进行了限制，需要实时扣减，因此使用了Hash结构存储用户的结构化信息，每次接口访问时修改对应用户的访问次数字段的值，并异步定期同步到数据库中。虽然定期同步可能存在扣减次数延迟的情况，但是在我们项目场景里认为这部分是业务可忍受的，因此采用了异步的方式。

此外，项目中采用List数据结构作为消息队列，协调数据处理和数据推送环节间的任务调度，数据处理完成后写入LIst，由数据推送线程从LIst中拿取数据进行推送。

### 平时使用Redis遇到的问题，如何解决的？

项目中的用到的缓存是为了缓存数据的相关属性信息，比如数据id、路径等。

查询请求现在缓存中查询，缓存中没有再去查数据库，以减少数据库的压力。

需要注意的问题分为以下几点：

1、要注意缓存穿透，用一个不存在的数据id重复请求，由于缓存中没有，重复去查询查询数据库，对数据库造成压力。解决方案是发现请求数据不存在时，向缓存写入一个空值，设置短一点的有效期。

2、要注意缓存雪崩，当某一个时刻出现大规模的缓存失效的情况，那么就会导致大量的请求直接打在数据库上面，导致数据库压力巨大，因此需要在失效时间上加上一个随机值。

3、要注意缓存和数据库的一致性，由于业务读多写少的业务特点，采用旁路缓存模式，更新时先更新数据库再删除缓存，以保证最终一致性。

### 说一下缓存穿透？

缓存穿透是指**缓存和数据库中都没有的数据**，而用户不断发起请求。由于缓存是不命中时被动写的，并且出于容错考虑，如果从存储层查不到数据则不写入缓存，这将导致这个不存在的数据每次请求都要到存储层去查询，失去了缓存的意义。

解决方案包括：

1. 在业务层面增加校验，不符合业务规则的请求直接拦截掉。如用户鉴权校验，id做基础校验，id<=0的直接拦截；
2. 在缓存和数据库都没有取到的数据，将key-value写入对应的key-null，缓存时间有效期设置短一些，如多少秒，防止影响正常业务。这样可以防止用户暴力攻击。
3. 使用布隆过滤器快速检索一个元素是否在一个集合中，但布隆过滤器存在误判额可能性，适用于对准确性要求不高的场景。

### 说一下缓存击穿？

缓存击穿是一个热点的Key，有大并发集中对其进行访问，突然间这个Key失效了，导致大并发全部打在数据库上，导致数据库压力剧增。

从两个方面解决：第一可以考虑热点key不设置过期时间。第二可以考虑降低打在数据库上的请求数量，从数据库读数据时加互斥锁，避免大量的请求落到数据库中。

### 说一下缓存雪崩？

当某一个时刻出现大规模的缓存失效的情况，那么就会导致大量的请求直接打在数据库上面，导致数据库压力巨大，如果在高并发的情况下，可能瞬间就会导致数据库宕机。

对应的解决方案有：

1. 在原有的失效时间上加上一个随机值，比如1-5分钟随机。这样就避免了因为采用相同的过期时间导致的缓存雪崩。
2. 为了防止Redis宕机导致缓存雪崩的问题，可以搭建Redis集群，提高Redis的容灾性。
3. 使用接口限流和熔断机制。当流量到达一定的阈值时，就直接返回“系统拥挤”之类的提示，防止过多的请求打在数据库上。至少能保证一部分用户是可以正常使用，其他用户多刷新几次也能得到结果。
4. 提高数据库的容灾能力，可以使用分库分表，读写分离的策略。

### 说一下缓存污染？

缓存污染问题说的是缓存中一些只会被访问一次或者几次的的数据，被访问完后，再也不会被访问到，但这部分数据依然留存在缓存中，消耗缓存空间。

解决方案是根据业务特性选择何时的内存淘汰策略。

### 布隆过滤器是什么？

布隆过滤器，它是一个连续的数据结构，每个存储位存储都是一个bit，即0或者1, 来标识数据是否存在。存储数据的时时候，使用K个不同的哈希函数将这个变量映射为bit列表的的K个点，把它们置为1。

主要思想就是哈希，不同的是，布隆过滤器使用了k个哈希函数，每个字符串跟k个bit对应，比单哈希函数减少了哈希冲突的概率。

检索时，我们只要看看这些点是不是都是1就（大约）知道集合中有没有它了：如果这些点有任何一个0，则被检元素一定不在；如果都是1，则被检元素很可能在。

它的优点是时间和空间上的查询效率高。缺点是有一定的误识别率和删除困难：

### 如何保证缓存和数据库的一致性？

在一般业务情况下，是允许缓存和数据库短暂不一致，保障最终一致性的：

- 在读多写少的场景下

  可以选择采用“ Cache-Aside + 消费数据库日志补偿机制”的方案。更新的时候，先更新数据库，再删除对应的缓存，其中删除缓存的操作是借助监听binlog的消息队列来做删除缓存的操作，利用重试机制保证删除缓存的成功性。使用binlog的消息队列的优势是无需额外引入消息队列。

> 删除缓存，而不是更新缓存，就是一个 lazy 计算的思想，不要每次都重新做复杂的计算，不管它会不会用到，而是让它到需要被使用的时候再重新计算。

- 在写多的场景下，有高并发的写操作

  可以选择直写模式，直接操作缓存，应用层更新数据时，只更新缓存，不更新数据库，由缓存层异步批量更新数据库。

如果是要求强一致性的场景，要求实时一致性的话：

- 在数据库记录中增加版本号，每次读取时需要先查询数据库中的版本号和缓存中的版本号进行对比，这种方式性能损耗很多
- 采用加锁的方式，在写请求中保证“更新数据库&删除缓存”的串行执行为原子性操作，读操作需要将查询Cache不存在之后的操作锁住。

### **多客户端同时并发写**一个 key问题？

某个时刻，多个系统实例都去更新某个 key。

1. 可以基于 zookeeper 实现分布式锁，每个系统通过 zookeeper 获取分布式锁，确保同一时间，只能有一个系统实例在操作某个 key，别人都不允许读和写。

2. 增加时间戳，写入缓存的数据，都是从 mysql 里查出来的，时间戳也查出来。每次要写之前，先判断一下当前这个 value 的时间戳是否比缓存里的 value 的时间戳要新。如果是的话，那么可以写，否则，就不能用旧的数据覆盖新的数据。

### Redis里面有1亿个key，其中有10w个key是以某个固定的已知的前缀开头的，如何将它们全部找出来？

最简单的方式可以使用keys指令可以扫出指定模式的key列表。

但由于Redis是单线程的，keys指令会导致线程阻塞一段时间，如果查询的Redis正在给线上业务提供服务，会导致线上服务停顿，直到keys命令执行完毕，服务才能恢复。

因此，如果是现实Redis，可以使用scan命令，scan指令可以无阻塞的提取出指定模式的key列表，但是会有一定的重复概率，需要再额外做一次去重就可以了，整体所花费的时间会比直接用keys指令长。

### Redis如何实现异步队列？

【方案一】使用list作为队列，lpush生产消息，rpop循环消费消息，当队列中没有消息时，可以通过让消费者休眠的方式的方式来处理，但是这样又会又消息的延迟问题。

【方案二】使用list作为队列，lpush生产消息，brpop消费消息。brpop是rpop的阻塞版本，list为空的时候，它会一直阻塞，直到list中有值或者超时，但只能实现一对一的消息队列。

【方案三】使用Redis的发布订阅模式进行消息发布/订阅。发布者将消息发布到指定的频道频道，订阅相应频道的客户端都能收到消息。

### Redis如何实现延迟队列？

> 延迟队列是指把当前要做的事情，往后推迟一段时间再做。延迟队列的常见使用场景有以下几种：
>
> - 在淘宝、京东等购物平台上下单，超过一定时间未付款，订单会自动取消；
> - 打车的时候，在规定时间没有车主接单，平台会取消你的单并提醒你暂时没有车主接单；
> - 点外卖的时候，如果商家在10分钟还没接单，就会自动取消订单；

在 Redis 可以使用有序集合的方式来实现延迟消息队列的，ZSet 有一个 Score 属性可以用来存储延迟执行的时间。

使用 zadd score1 value1 命令就可以一直往内存中生产消息。

利用 zrangebysocre 查询符合条件的所有待处理的任务， 通过循环执行队列任务即可。

### 说一下大key问题？

Redis使用过程中，有时候会出现单个简单的key存储的value很大的大key问题。

【大key会造成什么问题呢？】

- 客户端超时阻塞。由于 Redis 执行命令是单线程处理，然后在操作大 key 时会比较耗时，那么就会阻塞 Redis，从客户端这一视角看，就是很久很久都没有响应。
- 引发网络阻塞。每次获取大 key 产生的网络流量较大，如果一个 key 的大小是 1 MB，每秒访问量为 1000，那么每秒会产生 1000MB 的流量，这对于普通千兆网卡的服务器来说是灾难性的。
- 阻塞工作线程。如果使用 del 删除大 key 时，会阻塞工作线程，这样就没办法处理后续的命令。
- 内存分布不均。集群模型在 slot 分片均匀情况下，会出现数据和查询倾斜情况，部分有大 key 的 Redis 节点占用内存多，QPS 也会比较大。

【如何找到大key？】

- bigkeys命令：使用bigkeys命令以遍历的方式分析Redis实例中的所有Key，并返回整体统计信息与每个数据类型中Top1的大Key
- rdb-tools：使用 RdbTools 第三方开源工具，可以用来解析 Redis 快照（RDB）文件，找到其中的大 key。

【如何解决大key问题？】

- **对于可删除的大key，尽可能删除大key**
  - 异步删除：当Redis版本大于4.0时，可使用UNLINK命令安全地删除大Key，该命令能够以非阻塞的方式，逐步地清理传入的Key。
  - 批量删除：当Redis版本小于4.0时，避免使用阻塞式命令KEYS，而是建议通过SCAN命令执行增量迭代扫描key，然后判断进行删除。
- **对于不能删除的key，尽可能压缩和拆分key**
  - 当vaule是string时，比较难拆分，则使用序列化、压缩算法将key的大小控制在合理范围内，但是序列化和反序列化都会带来更多时间上的消耗。
  - 当value是string，压缩之后仍然是大key，则需要进行拆分，一个大key分为不同的部分，记录每个部分的key，使用multiget等操作实现事务读取。
  - 当value是list/set等集合类型时，根据预估的数据规模来进行分片，不同的元素计算后分到不同的片

### 说一下热点key的问题？



### 设计动态缓存热点数据策略？//todo

由于数据存储受限，系统并不是将所有数据都需要存放到缓存中的，而只是将其中一部分热点数据缓存起来。

热点数据动态缓存的策略总体思路：**通过数据最新访问时间来做排名，并过滤掉不常访问的数据，只留下经常访问的数据**。

以电商平台场景中的例子，现在要求只缓存用户经常访问的 Top 1000 的商品。具体细节如下：

- 先通过缓存系统做一个排序队列（比如存放 1000 个商品），系统会根据商品的访问时间，更新队列信息，越是最近访问的商品排名越靠前；
- 同时系统会定期过滤掉队列中排名最后的 200 个商品，然后再从数据库中随机读取出 200 个商品加入队列中；
- 这样当请求每次到达的时候，会先从队列中获取商品 ID，如果命中，就根据 ID 再从另一个缓存数据结构中读取实际的商品信息，并返回。

这个方案的劣势在于可能存在某个近期的热点key在数据库中，一直未被随机选中，导致缓存中没有这个热点key的问题。

### 利用Redis实现排行榜功能？//todo

> 这个和上面的区别在于：
>
> 动态缓存热点数据策略只缓存K个key值
>
> 排行榜功能缓存全部Key值，只是实时返回TOP K

