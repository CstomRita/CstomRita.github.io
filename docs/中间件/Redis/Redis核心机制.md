@autoHeader: 2.1.1.1.1.1
<p align="right">update time : {docsify-updated}</p>

## 订阅机制

Redis 的 SUBSCRIBE 命令可以让客户端订阅任意数量的频道， 每当有新信息发送到被订阅的频道时， 信息就会被发送给所有订阅指定频道的客户端。

![image-20230815132246819](Redis%E6%A0%B8%E5%BF%83%E6%9C%BA%E5%88%B6.assets/image-20230815132246819.png)

### 基于频道Channel的订阅

#### 使用命令

**发布**

发布者发布消息的命令是 publish,用法是 publish channel message，如向 channel1.1说一声hi

```bash
127.0.0.1:6379> publish channel:1 hi
(integer) 1
```

这样消息就发出去了。返回值表示接收这条消息的订阅者数量。发出去的消息不会被持久化，也就是有客户端订阅channel:1后只能接收到后续发布到该频道的消息，之前的就接收不到了。

**订阅**

订阅频道的命令是 subscribe，可以同时订阅多个频道，用法是 subscribe channel1 [channel2 ...]

```shell
127.0.0.1:6379> subscribe channel:1
Reading messages... (press Ctrl-C to quit)
1) "subscribe" // 消息类型
2) "channel:1" // 频道
3) "hi" // 消息内容
```

进入订阅状态后客户端可能收到3种类型的回复。每种类型的回复都包含3个值，第一个值是消息的类型，根据消类型的不同，第二个和第三个参数的含义不同：。

消息类型的取值可能是以下3个:

- subscribe。表示订阅成功的反馈信息。第二个值是订阅成功的频道名称，第三个是当前客户端订阅的频道数量。
- message。表示接收到的消息，第二个值表示产生消息的频道名称，第三个值是消息的内容。
- unsubscribe。表示成功取消订阅某个频道。第二个值是对应的频道名称，第三个值是当前客户端订阅的频道数量，当此值为0时客户端会退出订阅状态，之后就可以执行其他非"发布/订阅"模式的命令了。

#### 内部实现

底层是通过字典（图中的pubsub_channels）实现的，这个字典就用于保存订阅频道的信息：字典的键为正在被订阅的频道， 而字典的值则是一个链表， 链表中保存了所有订阅这个频道的客户端。

 ![image-20230815133111566](Redis%E6%A0%B8%E5%BF%83%E6%9C%BA%E5%88%B6.assets/image-20230815133111566.png)

- 当客户端调用 SUBSCRIBE 命令时， 程序就将客户端和要订阅的频道在 pubsub_channels 字典中关联起来。
- 当调用 `PUBLISH channel message` 命令， 程序首先根据 channel 定位到字典的键， 然后将信息发送给字典值链表中的所有客户端。
- 使用 UNSUBSCRIBE 命令可以退订指定的频道， 这个命令执行的是订阅的反操作： 它从 pubsub_channels 字典的给定频道（键）中， 删除关于当前客户端的信息， 这样被退订频道的信息就不会再发送给这个客户端。

### 基于模式Pattern的订阅

如果有某个/某些模式和这个频道匹配的话，那么所有订阅这个/这些频道的客户端也同样会收到信息。

#### 使用命令

通配符中?表示1个占位符，*表示任意个占位符(包括0)，?*表示1个以上占位符。

**发布 publish**

```sh
127.0.0.1:6379> publish c m1
(integer) 0
```

**订阅psubscribe**

```shell
127.0.0.1:6379> psubscribe c? b* d?*
Reading messages... (press Ctrl-C to quit)
1) "psubscribe"
2) "c?"
3) (integer) 1
1) "psubscribe"
2) "b*"
3) (integer) 2
1) "psubscribe"
```

1. 使用psubscribe命令可以重复订阅同一个频道，如客户端执行了`psubscribe c? c?*`。这时向c1发布消息客户端会接受到两条消息，而同时publish命令的返回值是2而不是1。同样的，如果有另一个客户端执行了`subscribe c1` 和`psubscribe c?*`的话，向c1发送一条消息该客户顿也会受到两条消息(但是是两种类型:message和pmessage)，同时publish命令也返回2.
2. punsubscribe命令可以退订指定的规则，用法是: `punsubscribe [pattern [pattern ...]]`,如果没有参数则会退订所有规则。
3. 使用punsubscribe只能退订通过psubscribe命令订阅的规则，不会影响直接通过subscribe命令订阅的频道；同样unsubscribe命令也不会影响通过psubscribe命令订阅的规则。另外需要**注意punsubscribe命令退订某个规则时不会将其中的通配符展开，而是进行严格的字符串匹配**，所以`punsubscribe *` 无法退订`c*`规则，而是必须使用`punsubscribe c*`才可以退订。

#### 内部实现

底层是List<pubsubPattern>。

```c
typedef struct pubsubPattern {
    redisClient *client;
    robj *pattern;
} pubsubPattern;
```

lient 属性保存着订阅模式的客户端，而 pattern 属性则保存着被订阅的模式。

- 每当调用 PSUBSCRIBE 命令订阅一个模式时， 程序就创建一个包含客户端信息和被订阅模式的 pubsubPattern 结构， 并将该结构添加到 redisServer.pubsub_patterns 链表中。

![image-20230815133333311](Redis%E6%A0%B8%E5%BF%83%E6%9C%BA%E5%88%B6.assets/image-20230815133333311.png)

- 发送信息到模式的工作也是由 PUBLISH 命令进行的, 通过遍历整个 pubsub_patterns 链表，程序可以检查所有正在被订阅的模式，以及订阅这些模式的客户端。通过匹配模式获得Channels，然后再把消息发给客户端。
- 退订： 程序会删除 redisServer.pubsub_patterns 链表中， 所有和被退订模式相关联的 pubsubPattern 结构， 这样客户端就不会再收到和模式相匹配的频道发来的信息。

## 持久化机制

### 持久化的必要性

Redis是个基于内存的数据库。那服务一旦宕机，内存中的数据将全部丢失。

通常的解决方案是从后端数据库恢复这些数据，但后端数据库有性能瓶颈，如果是大数据量的恢复，1、会对数据库带来巨大的压力，2、数据库的性能不如Redis。导致程序响应慢。

所以对Redis来说，实现数据的持久化，避免从后端数据库中恢复数据，是至关重要的。

### RDB机制

#### 实现方式

RDB是Redis默认的持久化方式。

RDB持久化是通过**快照**的方式，即在指定的时间间隔内将内存中的数据集快照写入磁盘。在创建快照之后，用户可以备份该快照，可以将快照复制到其他服务器以创建相同数据的服务器副本，或者在重启服务器后恢复数据。

RDB持久化会生成RDB文件，该文件是一个**压缩**过的**二进制文件**，可以通过该文件还原快照时的数据库状态，即生成该RDB文件时的服务器数据。

#### 触发时机

触发rdb持久化的方式有2种，分别是**手动触发**和**自动触发**。

##### 手动触发

手动触发分别对应save和bgsave命令。

- save命令：阻塞当前Redis服务器，直到RDB过程完成为止，对于内存 比较大的实例会造成长时间阻塞，线上环境不建议使用。

- bgsave命令：Redis进程执行fork操作创建子进程，RDB持久化过程由子进程负责，完成后自动结束。阻塞只发生在fork子进程的阶段，一般时间很短，具体流程：
  - redis客户端执行bgsave命令或者自动触发bgsave命令；
  - 主进程判断当前是否已经存在正在执行的子进程，如果存在，那么主进程直接返回；
  - 如果不存在正在执行的子进程，那么就fork一个新的子进程进行持久化数据，fork过程是阻塞的，fork操作完成后主进程即可执行其他操作；
  - 子进程先将数据写入到临时的rdb文件中，待快照数据写入完成后再原子替换旧的rdb文件；
  - 同时发送信号给主进程，通知主进程rdb持久化完成，主进程更新相关的统计信息（info Persitence下的rdb_*相关选项）

![image-20230814212103665](Redis%E6%A0%B8%E5%BF%83%E6%9C%BA%E5%88%B6.assets/image-20230814212103665.png)

##### 自动触发

在以下4种情况时会自动触发：

1. redis.conf中配置`save m n`，即在m秒内有n次修改时，自动触发bgsave生成rdb文件；
2. 主从复制时，从节点要从主节点进行全量复制时也会触发bgsave操作，生成当时的快照发送到从节点；
3. 执行debug reload命令重新加载redis时也会触发bgsave操作；
4. 默认情况下执行shutdown命令时，如果没有开启aof持久化，那么也会触发bgsave操作；

#### 配置参数

redis.conf中的配置

**1 快照周期**

内存快照虽然可以通过技术人员手动执行SAVE或BGSAVE命令来进行，但生产环境下多数情况都会设置其周期性执行条件，其参数根据自己的实际请求压力进行设置调整。

```shell
# 周期性执行条件的设置格式为
save <seconds> <changes>

# 默认的设置为：
save 900 1 # 如果900秒内有1条Key信息发生变化，则进行快照；
save 300 10
save 60 10000

# 以下设置方式为关闭RDB快照功能
save ""
```

*2 文件名称**

RDB文件在磁盘上的名称

```she
# 文件名称
dbfilename dump.rdb
```

**3 存储路径**

RDB文件的存储路径。默认设置为“./”，也就是Redis服务的主目录

```shell
# 文件保存路径
dir /home/work/app/redis/data/
```

**4 持久化出错**

提到的在快照进行过程中，主进程照样可以接受客户端的任何写操作的特性，是指在快照操作正常的情况下。

如果快照操作出现异常（例如操作系统用户权限不够、磁盘空间写满等等）时，Redis就会禁止写操作。这个特性的主要目的是使运维人员在第一时间就发现Redis的运行错误，并进行解决。一些特定的场景下，您可能需要对这个特性进行配置，这时就可以调整这个参数项。该参数项默认情况下值为yes，如果要关闭这个特性，指定即使出现快照错误Redis一样允许写操作，则可以将该值更改为no。

```shell
# 如果持久化出错，主进程是否停止写入
stop-writes-on-bgsave-error yes
```

**5 是否压缩**

该属性将在字符串类型的数据被快照到磁盘文件时，启用LZF压缩算法。

Redis官方的建议是请保持该选项设置为yes，因为“it’s almost always a win”

```shell
# 是否压缩
rdbcompression yes
```

**6 导入检查**

RDB快照功能的version 5 版本开始，一个64位的CRC冗余校验编码会被放置在RDB文件的末尾，以便对整个RDB文件的完整性进行验证。这个功能大概会多损失10%左右的性能，但获得了更高的数据可靠性。

```shell
# 导入时是否检查
rdbchecksum yes
```



#### 优缺点

**优点**

- RDB文件是某个时间节点的快照，默认使用LZF算法进行压缩，压缩后的文件体积远远小于内存大小，适用于备份、全量复制等场景；
- Redis加载RDB文件恢复数据要远远快于AOF方式；

**缺点**

- RDB方式实时性不够，无法做到秒级的持久化；
- 每次调用bgsave都需要fork子进程，fork子进程属于重量级操作，频繁执行成本较高；
- RDB文件是二进制的，没有可读性，AOF文件在了解其结构的情况下可以手动修改或者补全；
- 版本兼容RDB文件问题；

#### 实战问题

##### 快照过程中的数据一致性

**问题描述**

由于生产环境中我们为Redis开辟的内存区域都比较大（例如6GB），那么将内存中的数据同步到硬盘的过程可能就会持续比较长的时间，而实际情况是这段时间Redis服务一般都会收到数据写操作请求。那么如何保证数据一致性呢？

**解答**

RDB中的核心思路是Copy-on-Write，来保证在进行快照操作的这段时间，需要压缩写入磁盘上的数据在内存中不会发生变化。

在正常的快照操作中，一方面Redis主进程会fork一个新的快照进程专门来做这个事情，这样保证了Redis服务不会停止对客户端包括写请求在内的任何响应。另一方面这段时间发生的数据变化会以副本的方式存放在另一个新的内存区域，待快照操作结束后才会同步到原来的内存区域。

> 比如：如果主线程对这些数据也都是读操作（例如图中的键值对 A），那么，主线程和 bgsave 子进程相互不影响。但是，如果主线程要修改一块数据（例如图中的键值对 C），那么，这块数据就会被复制一份，生成该数据的副本。然后，bgsave 子进程会把这个副本数据写入 RDB 文件，而在这个过程中，主线程仍然可以直接修改原来的数据。
>
> ![img](Redis%E6%A0%B8%E5%BF%83%E6%9C%BA%E5%88%B6.assets/redis-x-aof-42.jpg)

##### 快照过程中服务崩溃

**问题描述**

在进行快照操作的这段时间，如果发生服务崩溃怎么办？

**解答**

在没有将数据全部写入到磁盘前，这次快照操作都不算成功。

如果出现了服务崩溃的情况，将以上一次完整的RDB快照文件作为恢复内存数据的参考。也就是说，在快照操作过程中不能影响上一次的备份数据。

Redis服务会在磁盘上创建一个临时文件进行数据操作，待操作成功后才会用这个临时文件替换掉上一次的备份。

##### 快照频率

**问题描述**

可以一秒做一次快照吗？如何尽可能避免丢失数据。

**解答**

快照的间隔时间变得很短，即使某一时刻发生宕机了，因为上一时刻快照刚执行，丢失的数据也不会太多。但是，如果频繁地执行全量快照，也会带来两方面的开销：

一方面，频繁将全量数据写入磁盘，会给磁盘带来很大压力，多个快照竞争有限的磁盘带宽，前一个快照还没有做完，后一个又开始做了，容易造成恶性循环。

另一方面，bgsave 子进程需要通过 fork 操作从主线程创建出来。虽然，子进程在创建后不会再阻塞主线程，但是，fork 这个创建过程本身会阻塞主线程，而且主线程的内存越大，阻塞时间越长。如果频繁 fork 出 bgsave 子进程，这就会频繁阻塞主线程了。

为了避免丢失数据，可以使用增量快照，采用RDB和AOF的混合模式。

### AOF机制

#### 实现方式

AOF持久化会把被执行的写命令写到AOF文件的末尾，记录数据的变化。AOF日志采用写后日志，即先写内存，后写日志。

Redis先执行命令，把数据写入内存，然后才记录日志。日志里记录的是Redis收到的每一条命令，这些命令是以文本形式保存。

> 其实大多数的数据库采用的是写前日志（WAL），例如MySQL，通过写前日志和两阶段提交，实现数据和逻辑的一致性。

**Redis为什么采用写后日志**？

Redis要求高性能，采用写后日志有两方面好处：

1. 避免额外的检查开销：Redis 在向 AOF 里面记录日志的时候，并不会先去对这些命令进行语法检查。所以，如果先记日志再执行命令的话，日志中就有可能记录了错误的命令，Redis 在使用日志恢复数据时，就可能会出错。
2. 不会阻塞当前的写操作

但这种方式存在潜在风险：

1. 如果命令执行完成，写日志之前宕机了，会丢失数据。
2. 主线程写磁盘压力大，导致写盘慢，阻塞后续操作。

#### 步骤及触发时机

##### AOF文件结构

执行两个写操作

```shell
127.0.0.1:6379> set s1 hello
OK
127.0.0.1:6379> set s2 world
OK
```

查看AOF中的记录：

```shell
*3
$3
set
$2
s1
$5
hello
*3
$3
set
$2
s2
$5
world
```

该命令格式为Redis的序列化协议（RESP）:

其中`*3`代表这个命令有三个参数，`$3`表示该命令中的参数a length长度为3

##### AOF步骤

AOF日志记录Redis的每个写命令，步骤分为：

1. 命令追加（append）：服务器每执行一个写命令，都会把该命令以协议格式先追加到AOF文件的内存缓存区的末尾，而不是直接写入文件，避免每次有命令都直接写入硬盘，减少硬盘IO次数

2. 文件写入（write）：将AOF缓存区的内容写入IO缓冲区。

3. 文件同步（fsync）：将IO缓冲区的内容同步到磁盘上的AOF文件。

##### AOF执行时机

其中，文件写入及同步的时机，Redis中有三种策略：

> 为了提高文件写入效率，在现代操作系统中，当用户调用write函数，将一些数据写入文件时，操作系统通常会将数据暂存到一个内存缓冲区里，当缓冲区的空间被填满或超过了指定时限后，才真正将缓冲区的数据写入到磁盘里。 这样的操作虽然提高了效率，但也为数据写入带来了安全问题：如果计算机停机，内存缓冲区中的数据会丢失。为此，系统提供了fsync、fdatasync同步函数，可以强制操作系统立刻将缓冲区中的数据写入到硬盘里，从而确保写入数据的安全性。

| 配置项   | 写回时机                                                     | 优点                       | 缺点                             |
| -------- | ------------------------------------------------------------ | -------------------------- | -------------------------------- |
| Always   | 每个写append命令执行完，立马同步地将日志写回磁盘。<br>一旦aof缓冲区有数据时，就调用fsync命令强制往aof文件写数据 | 可靠性高，数据基本上不丢失 | 每个命令都同步落盘，性能影响较大 |
| Everysec | 每个append命令执行完，只是先把日志写到AOF缓冲区，每隔一秒把缓冲区中的内容写入磁盘（有另外一个线程负责）<br>一旦aof缓冲区有数据时，就调用write命令往io缓冲区写数据，同时每秒调用一次fsync命令强制将io缓冲区的数据写入到aof文件 | 性能适中                   | 宕机时一般情况下不超过2秒的数据  |
| No       | 每个写append命令执行完，只是先把日志写到AOF内存缓冲区，由操作系统决定何时将缓冲区内容写回磁盘<br>一旦aof缓冲区有数据时，就调用wirte命令往io缓冲区写数据。由操作系统定期或当io缓冲区填满时，自动将io缓冲区的数据写入到aof文件 | 性能好                     | 宕机时丢失数据较多               |

**Always**

在这种模式下，每次执行完一个命令之后， write和 fsync 都会被执行。

另外，因为 fsync 是由 Redis 主进程执行的，所以在 fsync 执行期间，主进程会被阻塞，不能接受命令请求。

**Everysec**

在这种模式中， SAVE 原则上每隔一秒钟就会执行一次， 因为 SAVE 操作是由后台子线程调用的， 所以它不会引起服务器主进程阻塞。

注意， 在上一句的说明里面使用了词语“原则上”， 在实际运行中， 程序在这种模式下对 `fsync` 的调用并不是每秒一次， 它和调用时 Redis 所处的状态有关：

![image-20230815082536396](Redis%E6%A0%B8%E5%BF%83%E6%9C%BA%E5%88%B6.assets/image-20230815082536396.png)

**No**

在这种模式下， 每次调用 append 函数， WRITE 都会被执行， 但 fsync 会被略过。

在这种模式下， SAVE 只会在以下任意一种情况中被执行：

- Redis 被关闭
- AOF 功能被关闭
- 系统的写缓存被刷新（可能是缓存已经被写满，或者定期保存操作被执行）

这三种情况下的 SAVE 操作都会引起 Redis 主进程阻塞。

#### 配置参数

默认情况下，Redis是没有开启AOF的，可以通过配置redis.conf文件来开启AOF持久化。

```shell
# appendonly参数开启AOF持久化
appendonly no

# AOF持久化的文件名，默认是appendonly.aof
appendfilename "appendonly.aof"

# AOF文件的保存位置和RDB文件的位置相同，都是通过dir参数设置的
dir ./

# 同步策略
# appendfsync always
appendfsync everysec
# appendfsync no

# aof重写期间是否同步
no-appendfsync-on-rewrite no

# 重写触发配置
auto-aof-rewrite-percentage 100
auto-aof-rewrite-min-size 64mb

# 加载aof出错如何处理
aof-load-truncated yes

# 文件重写策略
aof-rewrite-incremental-fsync yes
```

#### 优缺点

优点：

- 数据更完整，安全性更高，秒级数据丢失（取决fsync策略，如果是everysec，最多丢失1秒的数据）
- AOF文件是一个只进行追加的日志文件，且写入操作是以Redis协议的格式保存的，内容是可读的，适合误删紧急恢复

缺点：

- 对于相同的数据集，AOF文件的体积要大于RDB文件，数据恢复也会比较慢
- 根据所使用的 fsync 策略，AOF 的速度可能会慢于 RDB。 不过在一般情况下， 每秒 fsync 的性能依然非常高

#### AOF重写

AOF会记录每个写命令到AOF文件，随着时间越来越长，AOF文件会变得越来越大。如果不加以控制，会对Redis服务器，甚至对操作系统造成影响，而且AOF文件越大，数据恢复也越慢。

为了解决AOF文件体积膨胀的问题，Redis提供AOF文件重写机制来对AOF文件进行“瘦身”，新旧两个AOF文件保存的数据一致，但新AOF文件没有冗余命令。

![img](Redis%E6%A0%B8%E5%BF%83%E6%9C%BA%E5%88%B6.assets/redis-x-aof-1.jpg)

**AOF文件重写并不需要对现有的AOF文件进行任何读取、分享和写入操作，而是通过读取服务器当前的数据库状态来实现的**

##### 手动触发

手动触发执行`bgrewriteaof`命令，该命令的执行跟`bgsave`触发快照时类似的，都是先`fork`一个子进程做具体的工作：

```shell
127.0.0.1:6379> bgrewriteaof
Background append only file rewriting started
```

##### 自动触发

自动触发会根据`auto-aof-rewrite-percentage`和`auto-aof-rewrite-min-size 64mb`配置来自动执行`bgrewriteaof`命令：

```shell
# 表示当AOF文件的体积大于64MB，且AOF文件的体积比上一次重写后的体积大了一倍（100%）时，会执行`bgrewriteaof`命令
auto-aof-rewrite-percentage 100
auto-aof-rewrite-min-size 64mb
```

##### 重写流程

![image-20230815084026661](Redis%E6%A0%B8%E5%BF%83%E6%9C%BA%E5%88%B6.assets/image-20230815084026661.png)

- 重写会有大量的写入操作，所以服务器进程会`fork`一个子进程来创建一个新的AOF文件
- 在重写期间，服务器进程继续处理命令请求，如果有写入的命令，追加到`aof_buf`的同时，还会追加到`aof_rewrite_buf`AOF重写缓冲区
- 当子进程完成重写之后，会给父进程一个信号，然后父进程会把AOF重写缓冲区的内容写进新的AOF临时文件中，再对新的AOF文件改名完成替换，这样可以保证新的AOF文件与当前数据库数据的一致性

**子进程复制内存数据**

**AOF文件重写不对现有的AOF文件操作，而是复制一份当前内存中的数据。**

采用操作系统提供的写时复制（copy on write）机制，就是为了避免一次性拷贝大量内存数据给子进程造成阻塞。

fork子进程时，子进程时会拷贝父进程的页表，而不会拷贝物理内存。这个拷贝会消耗大量cpu资源，并且拷贝完成前会阻塞主线程，阻塞时间取决于内存中的数据量，数据量越大，则内存页表越大。拷贝完成后，父子进程使用相同的内存地址空间。

主进程是可以有数据写入的，操作系统会创建这个页面的副本（页c的副本），即拷贝当前页的物理数据，将其映射到主进程中，而子进程还是使用原来的的页c。

![image-20230815085019356](Redis%E6%A0%B8%E5%BF%83%E6%9C%BA%E5%88%B6.assets/image-20230815085019356.png)

##### 其他问题

**1 在重写日志整个过程时，主线程有哪些地方会被阻塞**

1. fork子进程时，需要拷贝虚拟页表，会对主线程阻塞。
2. 主进程有bigkey写入时，操作系统会创建页面的副本，并拷贝原有的数据，会对主线程阻塞。
3. 子进程重写日志完成后，主进程追加aof重写缓冲区时可能会对主线程阻塞。

**2 为什么AOF重写不复用原AOF日志**？

1. 父子进程写同一个文件会产生竞争问题，影响父进程的性能。
2. 如果AOF重写过程中失败了，相当于污染了原本的AOF文件，无法做恢复数据使用。

**3 重写日志时，有新数据写入情况**

在fork出子进程时的拷贝，以及在重写时，如果有新数据写入，主线程就会将命令记录到两个aof日志内存缓冲区中。如果AOF写回策略配置的是always，则直接将命令写回旧的日志文件，并且保存一份命令至AOF重写缓冲区，这些操作对新的日志文件是不存在影响的。

而在bgrewriteaof子进程完成会日志文件的重写操作后，会提示主线程已经完成重写操作，主线程会将AOF重写缓冲中的命令追加到新的日志文件后面。这时候在高并发的情况下，AOF重写缓冲区积累可能会很大，这样就会造成阻塞，Redis后来通过Linux管道技术让aof重写期间就能同时进行回放，这样aof重写结束后只需回放少量剩余的数据即可。

最后通过修改文件名的方式，保证文件切换的原子性。

**4 重写过程宕机**

在AOF重写日志期间发生宕机的话，因为日志文件还没切换，所以恢复数据时，用的还是旧的日志文件。

#### 如何选择RDB和AOF

1、如果是数据不那么敏感，且可以从其他地方重新生成补回的，那么可以关闭持久化

2、如果是数据比较重要，不想再从其他地方获取，且可以承受数分钟的数据丢失，比如缓存等，那么可以只使用RDB

3、如果是用做内存数据库，要使用Redis的持久化，建议是RDB和AOF都开启，或者定期执行`bgsave`做快照备份，RDB方式更适合做数据的备份，AOF可以保证数据的不丢失。

### AOF和RDB混合方式(4.0)

Redis 4.0 中提出了一个**混合使用 AOF 日志和内存快照**的方法：内存快照RDB以一定的频率执行，在两次快照之间，使用 AOF 日志记录这期间的所有命令操作。

> 这样一来，快照不用很频繁地执行，这就避免了频繁 fork 对主线程的影响。而且，AOF 日志也只用记录两次快照间的操作，也就是说，不需要记录所有操作了，因此，就不会出现文件过大的情况了，也可以避免重写开销。

如下图所示，T1 和 T2 时刻的修改，用 AOF 日志记录，等到第二次做全量快照时，就可以清空 AOF 日志，因为此时的修改都已经记录到快照中了，恢复时就不再用日志了。

![img](Redis%E6%A0%B8%E5%BF%83%E6%9C%BA%E5%88%B6.assets/redis-x-rdb-4-20230815083307446.jpg)

在引入了混合持久化之后，使用 AOF 重建数据集时，会通过文件开头是否为“REDIS”来判断是否为混合持久化。

### 数据恢复

想要从文件中恢复数据，只需要重新启动Redis即可。

![image-20230909150056498](Redis%E6%A0%B8%E5%BF%83%E6%9C%BA%E5%88%B6.assets/image-20230909150056498.png)

- redis重启时判断是否开启aof，如果开启了aof，那么就优先加载aof文件；**在AOF文件中判断是否开启了混合模式，如果包含REDIS开头，则证明开启了持久化，则先载入RDB，再载入AOF；否则直接载入AOF**
- 如果aof存在，那么就去加载aof文件，加载成功的话redis重启成功，如果aof文件加载失败，那么会打印日志表示启动失败，此时可以去修复aof文件后重新启动；
- 若aof文件不存在，那么redis就会转而去加载rdb文件，如果rdb文件不存在，redis直接启动成功；
- 如果rdb文件存在就会去加载rdb文件恢复数据，如加载失败则打印日志提示启动失败，如加载成功，那么redis重启成功，且使用rdb文件恢复数据；

**为什么会优先加载AOF**

因为AOF保存的数据更完整，AOF基本上最多损失2s的数据。

### 实际经验

RDB的快照、AOF的重写都需要fork，这是一个重量级操作，会对Redis造成阻塞。因此为了不影响Redis主进程响应，我们需要尽可能降低阻塞：

- 降低fork的频率，比如可以手动来触发RDB生成快照、与AOF重写；
- 控制Redis最大使用内存，防止fork耗时过长；
- 使用更牛逼的硬件；
- 合理配置Linux的内存分配策略，避免因为物理内存不足导致fork失败。

有什么实践经验：

- 如果Redis中的数据并不是特别敏感或者可以通过其它方式重写生成数据，可以关闭持久化，如果丢失数据可以通过其它途径补回；
- 自己制定策略定期检查Redis的情况，然后可以手动触发备份、重写数据；
- 单机如果部署多个实例，要防止多个机器同时运行持久化、重写操作，防止出现内存、CPU、IO资源竞争，让持久化变为串行；
- 可以加入主从机器，利用一台从机器进行备份处理，其它机器正常响应客户端的命令；
- RDB持久化与AOF持久化可以同时存在，配合使用。

## 事务机制

Redis 事务的本质是一组命令的集合。事务支持一次执行多个命令，一个事务中所有命令都会被序列化。在事务执行过程，会按照顺序串行化执行队列中的命令，其他客户端提交的命令请求不会插入到事务执行命令序列中。

总结说：redis事务就是一次性、顺序性、排他性的执行一个队列中的一系列命令。

### 使用事务

#### 使用命令

- MULTI ：开启事务，redis会将后续的命令逐个放入队列中，然后使用EXEC命令来原子化执行这个命令系列。
- EXEC：执行事务中的所有操作命令。
- DISCARD：取消事务，放弃执行事务块中的所有命令。
- WATCH：监视一个或多个key,如果事务在执行前，这个key(或多个key)被其他命令修改，则事务被中断，不会执行事务中的任何命令。
- UNWATCH：取消WATCH对所有key的监视。

#### 错误处理

| 错误描述                                                     | 错误处理                                                     |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
| 事务在执行 `EXEC` 之前，命令可能会产生语法错误（参数数量错误，参数名错误等等），或者其他更严重的错误，比如内存不足（如果服务器使用 `maxmemory` 设置了最大内存限制的话） | 服务器会对命令入队失败的情况进行记录，并在客户端调用 `EXEC` 命令时，拒绝执行并自动放弃这个事务 |
| 命令可能在 `EXEC` 调用之后失败，如运行时类型错误等           | 没有特殊处理：事务中有某个/某些命令在执行时产生了错误， 事务中的其他命令仍然会继续执行。 |

### watch命令

#### watch命令做了什么

WATCH 命令监控某个key，事务exec时，会跟原值做比较，一旦发现它被修改过，则拒绝执行命令，并且会返回 `nil` 给客户端，表示事务已经失败。

watch命令为Redis事务提供乐观锁。

> 举个例子， 假设我们需要原子性地为某个值进行增 1 操作。
>
> 首先我们可能会这样做：
>
> ```bash
> val = GET mykey
> val = val + 1
> SET mykey $val
> ```
>
> 上面的这个实现在只有一个客户端的时候可以执行得很好。 但是， 当多个客户端同时对同一个键进行这样的操作时， 就会产生竞争条件。举个例子， 如果客户端 A 和 B 都读取了键原来的值， 比如 10 ， 那么两个客户端都会将键的值设为 11 ， 但正确的结果应该是 12 才对。
>
> 有了 WATCH ，我们就可以轻松地解决这类问题了：
>
> ```bash
> WATCH mykey
> val = GET mykey
> val = val + 1
> MULTI
> SET mykey $val
> EXEC
> ```
>
> 使用上面的代码， 如果在 WATCH 执行之后， EXEC 执行之前， 有其他客户端修改了 mykey 的值， 那么当前客户端的事务就会失败。 程序需要做的， 就是不断重试这个操作， 直到没有发生碰撞为止。

举例：

在事务开始前用WATCH监控k1，之后修改k1为11，说明事务开始前k1值被改变，MULTI开始事务，修改k1值为12，k2为22，执行EXEC，发回nil，说明事务回滚；查看下k1、k2的值都没有被事务中的命令所改变。

```bash
127.0.0.1:6379> set k1 v1
OK
127.0.0.1:6379> set k2 v2
OK
127.0.0.1:6379> WATCH k1
OK
127.0.0.1:6379> set k1 11
OK
127.0.0.1:6379> MULTI
OK
127.0.0.1:6379> set k1 12
QUEUED
127.0.0.1:6379> set k2 22
QUEUED
127.0.0.1:6379> EXEC
(nil)
127.0.0.1:6379> get k1
"11"
127.0.0.1:6379> get k2
"v2"
```

#### 如何实现

Redis使用WATCH命令来决定事务是继续执行还是回滚，那就需要在MULTI之前使用WATCH来监控某些键值对，然后使用MULTI命令来开启事务，执行对数据结构操作的各种命令，此时这些命令入队列。

当使用EXEC执行事务时，首先会比对WATCH所监控的键值对，如果没发生改变，它会执行事务队列中的命令，提交事务；如果发生变化，将不会执行事务中的任何命令，同时事务回滚。当然无论是否回滚，Redis都会取消执行事务前的WATCH命令。

![img](Redis%E6%A0%B8%E5%BF%83%E6%9C%BA%E5%88%B6.assets/db-redis-trans-2.png)

### 执行步骤

redis事务执行是三个阶段：

1. **开启**：以MULTI开始一个事务
2. **入队**：将多个命令入队到事务中，接到这些命令并不会立即执行，而是放到等待执行的事务队列里面
3. **执行**：由EXEC命令触发事务

当一个客户端切换到事务状态之后， 服务器会根据这个客户端发来的不同命令执行不同的操作：

- 如果客户端发送的命令为 EXEC 、 DISCARD 、 WATCH 、 MULTI 四个命令的其中一个， 那么服务器立即执行这个命令。
- 与此相反， 如果客户端发送的命令是 EXEC 、 DISCARD 、 WATCH 、 MULTI 四个命令以外的其他命令， 那么服务器并不立即执行这个命令， 而是将这个命令放入一个事务队列里面， 然后向客户端返回 QUEUED 回复。

> 根据这个步骤看上面错误处理：
>
> - 编译错误在入队时被发现，此时真的Redis命令还未执行，因此值均为改变。
> - 运行错误发送在已经入完队，正在执行命令的过程中，错误之前的语句已经执行过，值的更改已经发生。

### 其他问题

#### Redis事务不支持回滚

主要就是 3个原因：

- 作者认为发生事务回滚的原因大部分都是程序错误导致，这种情况一般发生在开发和测试阶段，而生产环境很少出现。
- 对于逻辑性错误，比如本来应该把一个数加 1，但是程序逻辑写成了加2，那么这种错误也是无法通过事务回滚来进行解决的。
- Redis追求的是简单高效，而传统事务的实现相对比较复杂，这和 Redis的设计思想相违背。

#### Redis事务满足ACID吗

Redis的事务机制可满足原子性、一致性、隔离性，不满足持久性。

- **原子性atomicity**

首先通过上文知道 运行期的错误是不会回滚的，很多文章由此说Redis事务违背原子性的；而官方文档认为是遵从原子性的。

Redis官方文档给的理解是，**Redis的事务是原子性的：所有的命令，要么全部执行，要么全部不执行，但不是完全成功。**

- **一致性consistency**

一致性指的就是事务执行前后的数据符合数据库的定义和要求。这一点 `Redis` 中的事务是符合要求的，上面讲述原子性的时候已经提到，不论是发生语法错误还是运行时错误，错误的命令均不会被执行。

- **隔离性Isolation**

可以使用watch命令满足隔离性：

1. 并发操作在 `EXEC` 命令前执行，隔离性需要通过 `WATCH` 机制保证；
2. 并发操作在 `EXEC` 命令之后，隔离性可以保证。

- **持久性Durability**

**redis事务是不保证持久性的**，这是因为redis持久化策略中不管是RDB还是AOF都是异步执行的，都存在数据丢失的情况。

## 高可用机制（todo）

> [!note]主从复制避免单点故障，主从库之间采用的是读写分离的方式；哨兵机制解决了主从复制模式下故障转移，实现主从库自动切换。

### 主从复制机制

主从库之间采用的是**读写分离**的方式。

- 读操作：主库、从库都可以接收；
- 写操作：首先到主库执行，然后，主库将写操作同步给从库。

![img](Redis%E6%A0%B8%E5%BF%83%E6%9C%BA%E5%88%B6.assets/db-redis-copy-1.png)

> 在2.8版本之前只有全量复制，而2.8版本后有全量和增量复制。
>
> 主从复制共有三种模式：**全量复制、基于长连接的命令传播、增量复制**。
>
> 主从服务器第一次同步的时候，就是采用全量复制。
>
> 第一次同步完成后，主从服务器都会维护着一个长连接，主服务器在接收到写操作命令后，就会通过这个连接将写命令传播给从服务器，来保证主从服务器的数据一致性。
>
> 如果遇到网络断开，则使用增量复制续传。

#### 全量复制

##### 确定主从 replicaof

当我们启动多个 Redis 实例的时候，它们相互之间就可以通过 replicaof（Redis 5.0 之前使用 slaveof）命令形成主库和从库的关系，之后会按照三个阶段完成数据的第一次同步。

例如，现在有实例 1（ip：172.16.19.3）和实例 2（ip：172.16.19.5），我们在实例 2 上执行以下这个命令后，实例 2 就变成了实例 1 的从库，并从实例 1 上复制数据：

```bash
replicaof 172.16.19.3 6379
```

##### 全量复制阶段

![img](Redis%E6%A0%B8%E5%BF%83%E6%9C%BA%E5%88%B6.assets/db-redis-copy-2.jpg)

- **第一阶段是主从库间建立连接、协商同步的过程**

主要是为全量复制做准备。在这一步，从库和主库建立起连接，并告诉主库即将进行同步，主库确认回复后，主从库间就可以开始同步了。

从库给主库发送 psync 命令，表示要进行数据同步，主库根据这个命令的参数来启动复制。psync 命令包含了主库的 runID 和复制进度 offset 两个参数。

> runID，是每个 Redis 实例启动时都会自动生成的一个随机 ID，用来唯一标记这个实例。当从库和主库第一次复制时，因为不知道主库的 runID，所以将 runID 设为“？”。
>
> offset，此时设为 -1，表示第一次复制。

主库收到 psync 命令后，会用 FULLRESYNC 响应命令带上两个参数：主库 runID 和主库目前的复制进度 offset，返回给从库。

从库收到响应后，会记录下这两个参数。这里有个地方需要注意，FULLRESYNC 响应表示第一次复制采用的全量复制，也就是说，主库会把当前所有的数据都复制给从库。

- **第二阶段，主库将所有数据同步给从库**。

从库收到数据后，在本地完成数据加载。<font color=red>这个过程依赖于内存快照生成的 RDB 文件。</font>

主库执行 bgsave 命令，生成 RDB 文件，接着将文件发给从库。

从库接收到 RDB 文件后，会先清空当前数据库，然后加载 RDB 文件。这是因为从库在通过 replicaof 命令开始和主库同步前，可能保存了其他数据。为了避免之前数据的影响，从库需要先把当前数据库清空。

在主库将数据同步给从库的过程中，主库不会被阻塞，仍然可以正常接收请求。否则，Redis 的服务就被中断了。但是，这些请求中的写操作并没有记录到刚刚生成的 RDB 文件中。为了保证主从库的数据一致性，主库会在内存中用专门的 replication buffer，记录 RDB 文件生成后收到的所有写操作。

- **第三个阶段，主库会把第二阶段执行过程中新收到的写命令，再发送给从库**

当主库完成 RDB 文件发送后，就会把此时 replication buffer 中的修改操作发给从库，从库再重新执行这些操作。这样一来，主从库就实现同步。

##### buffer 

- `replication buffer`

在全量复制中，在主库将数据同步给从库的过程中，主库不会被阻塞，仍然可以正常接收请求，主库会在内存中用专门的 replication buffer，记录 RDB 文件生成后收到的所有写操作。

#### 命令传播

主从服务器在完成第一次同步后，双方之间就会维护一个 TCP 连接。

![图片](Redis%E6%A0%B8%E5%BF%83%E6%9C%BA%E5%88%B6.assets/03eacec67cc58ff8d5819d0872ddd41e.png)

后续主服务器可以通过这个连接继续将写操作命令传播给从服务器，然后从服务器执行该命令，使得与主服务器的数据库状态相同。

而且这个连接是长连接的，目的是避免频繁的 TCP 连接和断开带来的性能开销。

上面的这个过程被称为**基于长连接的命令传播**，通过这种方式来保证第一次同步后的主从服务器的数据一致性。

#### 增量复制 //todo

如果主从库在命令传播时出现了网络闪断，那么，从库就会和主库重新进行一次全量复制，开销非常大。

从 Redis 2.8 开始，<font color=red>网络断了之后，主从库会采用增量复制的方式继续同步。</font>

##### 两个buffer

- `replication buffer`


在增量同步时，从库作为一个client，也会分配一个buffer，先把数据写到这个buffer中，然后再把buffer中的数据发到client socket中再通过网络发送出去，专门用来传播用户的写命令到从库，保证主从数据一致。

- `repl_backlog_buffer`

断开重连增量复制的实现奥秘就是 `repl_backlog_buffer` 缓冲区，不管在什么时候 master 都会将写指令操作记录在 `repl_backlog_buffer` 中，因为内存有限， `repl_backlog_buffer` 是一个定长的环形数组，**如果数组内容满了，就会从头开始覆盖前面的内容**

repl_baklog中会记录Redis处理过的命令日志及offset，包括master当前的offset和slave已经拷贝的offset： `master_repl_offset`记录master节点的位置偏移量， `slave_repl_offset`记录slave已经同步的偏移量：master 收到写操作，偏移量则会增加；从库持续执行同步的写指令后，slave_repl_offset 也在不断增加。

因此：

- 正常情况下，这两个偏移量基本相等。
- 在网络断连阶段，主库可能会收到新的写操作命令，所以 `master_repl_offset`会大于 `slave_repl_offset`。

> repl_backlog示意图如下，slave与master的offset之间存在差异，就是slave需要增量拷贝的数据了。
>
> ![image-20231211192336285](Redis%E6%A0%B8%E5%BF%83%E6%9C%BA%E5%88%B6.assets/image-20231211192336285.png)
>
> 随着不断有数据写入，master的offset会逐渐变大，slave也不断拷贝，追赶这master的offset，直到数组被填满：
>
> ![image-20231211192410738](Redis%E6%A0%B8%E5%BF%83%E6%9C%BA%E5%88%B6.assets/image-20231211192410738.png)
>
> 此时，如果有新的数据写入，就会覆盖数组中旧的数据了。不过，旧的数据只要是绿色的，说明是已经被同步到slave的数据，即便被覆盖了也没有什么影响。因为未同步的部分仅仅是红色部分的。
>
> 但是如果slave出现了网络阻塞，或者其他情况，导致master的offset远远的超过了slave的offset，如果master继续写入新的数据，其offset就会覆盖旧的数据，直到将slave现在的offset也覆盖掉：
>
> ![image-20231211192458103](Redis%E6%A0%B8%E5%BF%83%E6%9C%BA%E5%88%B6.assets/image-20231211192458103.png)
>
> 棕色框中的红色部分，就是尚未同步，但是却已经被覆盖的数据。此时如果slave恢复，需要同步的时候，却发现自己的offset没有了，无法完成增量同步了。在这种情况下，只能做全量同步了。

如果从库断开时间太久，repl_backlog_buffer环形缓冲区被主库的写命令覆盖了，那么从库连上主库后只能乖乖地进行一次全量复制，repl_backlog_buffer配置尽量大一些，可以降低主从断开后全量复制的概率。

计算公式：

 ```text
 repl_backlog_buffer = second * write_size_per_second
 ```

 1. **second**：从服务器断开重连主服务器所需的平均时间；
 2. **write_size_per_second**：master 平均每秒产生的命令数据量大小（写命令和数据大小总和）；

 例如，如果主服务器平均每秒产生 1 MB 的写数据，而从服务器断线之后平均要 5 秒才能重新连接上主服务器，那么复制积压缓冲区的大小就不能低于 5 MB。

 为了安全起见，可以将复制积压缓冲区的大小设为`2 * second * write_size_per_second`，这样可以保证绝大部分断线情况都能用部分重同步来处理。

##### 流程

![img](Redis%E6%A0%B8%E5%BF%83%E6%9C%BA%E5%88%B6.assets/db-redis-copy-3.jpg)





#### 总结

##### 全量同步和增量同步的区别？

全量同步：master将完整的内存数据生成RDB文件，发送RDB文件到slave。后续命令则记录在repl_baklog，逐个发送给slave；

增量同步：slave提交自己的offset到master，master获取到repl_baklog中从offset之后的命令给slave。

##### 全量同步和增量同步的执行时机？

**什么时候执行全量同步？**

1. slave节点第一次连接master时候；
2. slave节点断开时间太久了，repl_baklog中的offset已经被覆盖时候

**什么时候执行增量同步？**

slave节点断开又恢复，并且在repl_baklog中找到了对应的offset的时候

### 故障转移-哨兵机制

> 哨兵是 Redis 的一种运行模式，它专注于**对 Redis 实例（主节点、从节点）运行状态的监控，并能够在主节点发生故障时通过一系列的机制实现选主及主从切换，实现故障转移，确保整个 Redis 系统的可用性**。

#### 哨兵架构

##### 单哨兵架构

![image-20231211194147069](Redis%E6%A0%B8%E5%BF%83%E6%9C%BA%E5%88%B6.assets/image-20231211194147069.png)

##### 多哨兵架构

![image-20231211194232226](Redis%E6%A0%B8%E5%BF%83%E6%9C%BA%E5%88%B6.assets/image-20231211194232226.png)

#### 哨兵机制原理

Redis 哨兵具备的能力有如下几个：

- **监控**：持续监控 master 、slave 是否处于预期工作状态。
- **自动切换主库**：当 Master 运行故障，哨兵启动自动故障恢复流程：从 slave 中选择一台作为新 master。
- **通知**：让 slave 执行 replicaof ，与新的 master 同步；并且通知客户端与新 master 建立连接。

##### 监控

哨兵会每隔 1 秒给所有主从节点发送 PING 命令，当主从节点收到 PING 命令后，会发送一个响应命令给哨兵，这样就可以判断它们是否在正常运行：

- 如果主节点或者从节点没有在规定的时间内响应哨兵的 PING 命令，哨兵就会将它们标记为「**主观下线**」。这个「规定的时间」是配置项 `down-after-milliseconds` 参数设定的，单位是毫秒。
- 

![哨兵监控主从节点](Redis%E6%A0%B8%E5%BF%83%E6%9C%BA%E5%88%B6.assets/26f88373d8454682b9e0c1d4fd1611b4-20230309233114856.png)



##### 自动切换







## 可拓展-Redis集群（todo）

> 主从复制和哨兵机制保障了高可用，就读写分离而言虽然slave节点扩展了主从的读并发能力，但是**写能力**和**存储能力**是无法进行扩展，就只能是master节点能够承载的上限。
>
> 如果面对海量数据那么必然需要构建master（主节点分片)之间的集群，同时必然需要吸收高可用（主从复制和哨兵机制）能力，即每个master分片节点还需要有slave节点，这是分布式系统中典型的纵向扩展（集群的分片技术）的体现；在 Redis 3.0版本中对应的设计就是Redis Cluster





## 内存淘汰机制

Redis共支持八种淘汰策略，分别是noeviction、volatile-random、volatile-ttl、volatile-lru、volatile-lfu、allkeys-lru、allkeys-random 和 allkeys-lfu 策略，可以分成三类看。

![image-20230812190309584](Redis%E6%A0%B8%E5%BF%83%E6%9C%BA%E5%88%B6.assets/image-20230812190309584.png)

### 不淘汰策略 

#### noeviction

Redis4.0后新增的淘汰策略，该策略是Redis的默认策略。

在这种策略下，一旦缓存被写满了，再有写请求来时，Redis 不再提供服务，而是直接返回错误。这种策略不会淘汰数据，所以无法解决缓存污染问题。一般生产环境不建议使用。

### 对设置了过期时间的数据进行淘汰 

#### volatile-random

在设置了过期时间的键值对中，进行随机删除。因为是随机删除，无法把不再访问的数据筛选出来，所以可能依然会存在缓存污染现象，无法解决缓存污染问题。

#### Volatile-ttl

Redis在筛选需删除的数据时，越早过期的数据越优先被选择。

#### volatile-lru

##### LRU算法

LRU 算法的全称是 Least Recently Used，按照最近使用的原则来筛选数据，最近使用的数据会留在缓存中，是一种按照访问时间进行淘汰的算法。

**LRU 策略的核心思想：如果一个数据刚刚被访问，那么这个数据肯定是热数据，还会被再次访问**。

LRU 会把所有的数据组织成一个链表，链表的头和尾分别表示 MRU 端和 LRU 端，分别代表最近最常使用的数据和最近最不常用的数据。

![image-20230812185829269](Redis%E6%A0%B8%E5%BF%83%E6%9C%BA%E5%88%B6.assets/image-20230812185829269.png)



##### Redis中LRU实现

LRU 算法在实际实现时，需要用链表管理所有的缓存数据，这会带来额外的空间开销。而且，当有数据被访问时，需要在链表上把该数据移动到 MRU 端，如果有大量数据被访问，就会带来很多链表移动操作，会很耗时，进而会降低 Redis 缓存性能。所以，在 Redis 中，LRU 算法被做了简化，以减轻数据淘汰对缓存性能的影响。

Redis 在实现 LRU 策略时使用了两个近似方法：

1、RedisObject 结构中设置了一个 lru 字段，用来记录数据的访问时间戳；

2、Redis 并没有为所有的数据维护一个全局的链表，而是通过随机采样方式，选取一定数量的数据放入候选集合，后续在候选集合中根据 lru 字段值的大小进行筛选。

具体淘汰过程为：

1. 第一次会随机选出 N 个数据，把它们作为一个候选集合。接下来，Redis 会比较这 N 个数据的 lru 字段，把 lru 字段值最小的数据从缓存中淘汰出去。
2. 当需要再次淘汰数据时，Redis 需要挑选数据进入第一次淘汰时创建的候选集合。这儿的挑选标准是：能进入候选集合的数据的 lru 字段值必须小于候选集合中最小的 lru 值。当有新数据进入候选数据集后，如果候选数据集中的数据个数达到了 maxmemory-samples，Redis 就把候选数据集中 lru 字段值最小的数据淘汰出去。这样一来，Redis 缓存不用为所有的数据维护一个大链表，也不用在每次数据访问时都移动链表项，提升了缓存的性能。

![image-20230812185405802](Redis%E6%A0%B8%E5%BF%83%E6%9C%BA%E5%88%B6.assets/image-20230812185405802.png)

Redis 提供了一个配置参数 maxmemory-samples，这个参数就是 Redis 选出的数据个数 N。例如，执行如下命令，可以让 Redis 选出 100 个数据作为候选数据集：

> CONFIG SET maxmemory-samples 100

##### LRU的优劣

优势：

在数据被频繁访问的业务场景中，LRU 策略的确能有效留存访问时间最近的数据。而且，因为留存的这些数据还会被再次访问，所以又可以提升业务应用的访问速度。

劣势：

1. **只看数据的访问时间**，使用 LRU 策略在处理扫描式单次查询操作时，无法解决缓存污染。
2. 临时数据可能会取代真正经常使用的数据。比如，短时间内，大量临时数据涌入 redis，而触发发生内存淘汰，可能会将那些真正经常使用的数据驱逐。

> 扫描式单次查询操作，就是指应用对大量的数据进行一次全体读取，每个数据都会被读取，而且只会被读取一次。此时，因为这些被查询的数据刚刚被访问过，所以 lru 字段值都很大。

#### volatile-lfu

LFU 算法的全称是 Least Frequently Used，也就是每次淘汰那些使用次数最少的数据，是一种按照访问频次进行淘汰的算法。

##### LFU算法

LFU将数据和数据的访问频次保存在一个容量有限的容器中，当访问一个数据时：

1. 该数据在容器中，则将该数据的访问频次加1。
2. 该数据不在容器中，则将该数据加入到容器中，且访问频次为1。

当数据量达到容器的限制后，会剔除掉访问频次最低的数据。

![image-20230812193611958](Redis%E6%A0%B8%E5%BF%83%E6%9C%BA%E5%88%B6.assets/image-20230812193611958.png)

**常规LFU算法面临的问题**

在数据请求模式比较稳定（没有对于某个数据突发的高频访问这样的不稳定模式）的情况下，LFU的表现还是很不错的。

但在数据的请求模式大多不稳定的情况下，LFU一般会有这样一些问题：

1. **热点数据问题**：热点数据一般只是几天内有较高的访问频次，过了这段时间就没那么大意义去缓存了。但是因为在热点期间他的频次被刷上去了，导致之后很长一段时间内很难被淘汰；
2. **新增数据问题**：如果采用只记录缓存中的数据的访问信息，新加入的高频访问数据在刚加入的时候由于没有累积优势，很容易被淘汰掉；
3. **空间问题**：如果记录全部出现过的数据的访问信息，会占用更多的内存空间。

##### Redis中LFU实现

Redis 在实现 LFU 策略的时候，同样采用了近似的实现方法，引入了三个策略：

1. 概率量级计数：非线性递增的技术方法节省计数器字段空间，可配参数server.lfu_log_factor，影响计数的量级范围，整计数器counter的增长速度，lfu-log-factor越大，counter增长的越慢。
2. 计数衰减：可以解决热点数据问题，配置参数server.lfu-decay-time，控制LFU计数衰减，是一个以分钟为单位的数值，可以调整counter的减少速度。
3. 复用LRU字段，把原来 24bit 大小的 lru 字段，又进一步拆分成了两部分:
   - ldt 值：lru 字段的前 16bit，表示数据的访问时间戳；
   - counter 值：lru 字段的后 8bit，表示数据的访问次数。

当 LFU 策略筛选数据时，Redis 会在候选集合中，根据数据 lru 字段的后 8bit选择访问次数最少的数据进行淘汰。当访问次数相同时，再根据 lru 字段的前 16bit 值大小，选择访问时间最久远的数据进行淘汰。

**（一）计数衰减**

某个key的counter被衰减的时机是在它被访问的时候。计数衰减的触发也是被动的，而非Redis主动或者定时触发的。在缓存被访问时，会更新数据的访问计数，更新的步骤是：

1. 先在现有数据的计数上进行计数衰减。
2. 再对完成衰减后的计数进行概率增加。

计数衰减的思想为：可配参数server.lfu-decay-time所代表的含义是计数衰减的周期长度，单位是分钟。**当时间过去一个周期（也就是lfu-decay-time分钟），计数值就会减1**。基于这样的思想，其具体过程为：

1. redisObject结构中的lru字段的高16bit，记录的是该key上次进行衰减的时间。通过**(当前时间-上次衰减的时间）/ （周期单位）**即为key需要将counter衰减的数量n。
2. 通过`LFUDecrAndReturn`方法得到该key的counter，将counter=counter-n。

**（二）概率量级计数**

Redis中给counter配置了8bit的存储空间，也就是counter最大值为255：

1. 当counter等于最大值 255 时，不再增加counter。
2. 当counter小于 255 时，Redis会计算一个阈值 p，以及一个取值为 0 到 1 之间的随机概率值 r。如果概率 r 小于阈值 p，counter加 1；否则counter不变。

其中，`p=1/(counter*factor+1)`，可配参数server.lfu_log_factor越大时，概率p在同等情况下则会越低，counter字段8 bit一共255的上限也就越不容易被触达，换句话说，factor越大，Redis的counter字段能够记录的访问频次量级也就越高。

**（三）key的初始化及更新**

1、key被创建时，对 redisObject 结构体中的 lru 变量初始化值，会由两部分组成：

- ldt值设置为当前时间。
- counter值，被设置为宏定义 LFU_INIT_VAL，默认值为 5。

2、key被访问时更新变量值：

- 根据距离上次访问的时长，衰减访问计数
- 根据当前访问次数更新访问counter值
- 调用 LFUGetTimeInMinutes 函数，来获取当前的时间戳，并和更新后的访问次数组合，形成最新的访问频率信息，赋值给键值对的 lru 变量。

##### LFU的优劣

优点：通过key的访问频率和访问时间比较来淘汰key，重点突出的是Frequently Used，用于在缓存容量有限时决定哪些缓存块应该被清除，避免了LRU算法的明显缺陷。

缺点：最近加入的数据总是易于被剔除（缓存末端抖动），因为他起始的频率很低。

### 对全部数据进行淘汰 

#### allkeys-random

从所有键值对中随机选择并删除数据。

volatile-random 跟 allkeys-random算法一样。

#### allkeys-lru

使用 LRU 算法在所有数据中进行筛选。

具体LFU算法跟上述 volatile-lru 中介绍的一致，只是筛选的数据范围是全部缓存。

#### allkeys-lfu

使用 LFU算法在所有数据中进行筛选。

具体LFU算法跟上述 volatile-lfu 中介绍的一致，只是筛选的数据范围是全部缓存。

### 淘汰过程

![image-20230812221333276](Redis%E6%A0%B8%E5%BF%83%E6%9C%BA%E5%88%B6.assets/image-20230812221333276.png)

真正的淘汰包括下面的内容：

- 何时清理
- 如何清理，清理哪些 --- 依据淘汰策略指定
- 清理多少

#### 清理时机

每一条客户端的请求处理之后，看是否有必要进行内存淘汰。如果需要，走淘汰逻辑，此时分两种情况：

1. 淘汰数据少：这种很理想，一次性可以搞定。
2. 淘汰数据多：如果数据过多，为避免长时间阻塞，提供了一些可配置的限制，如果达到限制条件还没有清理完成，暂时放入到时间事件中，等待下一轮清理。

#### 清理多少

待清理的大小 = used - maxmemory，即当前使用内存大小 - 设定的阈值。

一次性没处理完（可以设置一定时长限制），可以扔到时间事件中，周期性的处理，直到达到目标 ...

清理的目标是使得当前内存小于maxmemory

## 过期删除机制

Redis 是可以对 key 设置过期时间的，因此需要有相应的机制将已过期的键值对删除，而做这个工作的就是过期键值删除策略。

### 设置过期时间

设置 key 过期时间的命令一共有 4 个：

- `expire key n  `：设置 key 在 n 秒后过期；
- `pexpire key n`：设置 key 在 n 毫秒后过期;
- `expireat key n  `：设置 key 在某个时间戳（精确到秒）之后过期；
- `pexpireat key n`：设置 key 在某个时间戳（精确到毫秒）之后过期；

当然，在设置字符串时，也可以同时对 key 设置过期时间，共有 3 种命令：

- `set key value ex n ` ：设置键值对的时候，同时指定过期时间（精确到秒）；
- `set key value px n ` ：设置键值对的时候，同时指定过期时间（精确到毫秒）；
- `setex key n value   ` ：设置键值对的时候，同时指定过期时间（精确到秒）。

### 判断key过期

当对一个 key 设置了过期时间时，Redis 会把该 key 带上过期时间存储到一个**过期字典**（expires dict）中，其数据结构如下。

![image-20230812224425577](Redis%E6%A0%B8%E5%BF%83%E6%9C%BA%E5%88%B6.assets/image-20230812224425577.png)

其中，过期字典的 key 是一个指针，指向某个键对象；过期字典的 value 是一个 long long 类型的整数，这个整数保存了 key 的过期时间；

当我们查询一个 key 时，Redis 首先检查该 key 是否存在于过期字典中：

- 如果不在，则正常读取键值；
- 如果存在，则会获取该 key 的过期时间，然后与当前系统时间进行比对，如果比系统时间大，那就没有过期，否则判定该 key 已过期。

### 过期删除策略

#### 定时删除

定时删除策略的做法是，**在设置 key 的过期时间时，同时创建一个定时事件，当时间到达时，由事件处理器自动执行 key 的删除操作。**

定时删除策略的**优点**：

- 可以保证过期 key 会被尽快删除，也就是内存可以被尽快地释放。因此，定时删除对内存是最友好的。

定时删除策略的**缺点**：

- 在过期 key 比较多的情况下，删除过期 key 可能会占用相当一部分 CPU 时间，在内存不紧张但 CPU 时间紧张的情况下，将 CPU 时间用于删除和当前任务无关的过期键上，无疑会对服务器的响应时间和吞吐量造成影响。所以，定时删除策略对 CPU 不友好。

#### 惰性删除

惰性删除策略的做法是，**不主动删除过期键，每次从数据库访问 key 时，都检测 key 是否过期，如果过期则删除该 key。**

惰性删除策略的**优点**：

- 因为每次访问时，才会检查 key 是否过期，所以此策略只会使用很少的系统资源，因此，惰性删除策略对 CPU 时间最友好。

惰性删除策略的**缺点**：

- 如果一个 key 已经过期，而这个 key 又仍然保留在数据库中，那么只要这个过期 key 一直没有被访问，它所占用的内存就不会释放，造成了一定的内存空间浪费。所以，惰性删除策略对内存不友好。

#### 定期删除

定期删除策略的做法是，**每隔一段时间「随机」从数据库中取出一定数量的 key 进行检查，并删除其中的过期key。**

定期删除策略的**优点**：

- 通过限制删除操作执行的时长和频率，来减少删除操作对 CPU 的影响，同时也能删除一部分过期的数据减少了过期键对空间的无效占用。

定期删除策略的**缺点**：

- 内存清理方面没有定时删除效果好，同时没有惰性删除使用的系统资源少。
- 难以确定删除操作执行的时长和频率。如果执行的太频繁，定期删除策略变得和定时删除策略一样，对CPU不友好；如果执行的太少，那又和惰性删除一样了，过期 key 占用的内存不会及时得到释放。

#### Redis中使用的删除策略

前面介绍了三种过期删除策略，每一种都有优缺点，仅使用某一个策略都不能满足实际需求。

**Redis 选择了「惰性删除+定期删除」这两种策略配合使用**。



**惰性删除**

Redis 在访问或者修改 key 之前，都会调用 expireIfNeeded 函数对其进行检查，检查 key 是否过期：

1. 如果过期，则删除该 key，至于选择异步删除，还是选择同步删除，根据 `lazyfree_lazy_expire` 参数配置决定（Redis 4.0版本开始提供参数），然后返回 null 客户端；

   > server.lazyfree_lazy_expire 为 1 表示异步删除，不为1时表示同步删除

2. 如果没有过期，不做任何处理，然后返回正常的键值对给客户端；



**定期删除**

每隔一段时间「随机」从数据库中取出一定数量的 key 进行检查，并删除其中的过期key。

1、这个间隔检查的时间是多长呢？

在 Redis 中，默认每秒进行 10 次过期检查一次数据库，此配置可通过 Redis 的配置文件 redis.conf 进行配置，配置键为 hz ，默认值是 10。

特别强调下，每次检查数据库并不是遍历过期字典中的所有 key，而是从数据库中随机抽取一定数量的 key 进行过期检查。

2、随机抽查的数量是多少呢？

定期删除的实现在 expire.c 文件下的 `activeExpireCycle` 函数中，其中随机抽查的数量由 `ACTIVE_EXPIRE_CYCLE_LOOKUPS_PER_LOOP` 定义的，它是写死在代码中的，数值是 20。也就是说，数据库每轮抽查时，会随机选择 20 个 key 判断是否过期。

3、删除流程是什么样的？

	1. 从过期字典中随机抽取 20 个 key；
 	2. 检查这 20 个 key 是否过期，并删除已过期的 key；
 	3. 如果本轮检查的已过期 key 的数量，超过 5 个（20/4），也就是「已过期 key 的数量」占比「随机抽取 key 的数量」大于 25%，则继续重复步骤 1；如果已过期的 key 比例小于 25%，则停止继续删除过期 key，然后等待下一轮再检查。可以看到，定期删除是一个循环的流程。Redis 为了保证定期删除不会出现循环过度，导致线程卡死现象，为此增加了定期删除循环流程的时间上限，默认不会超过 25ms。

![image-20230813160316780](Redis%E6%A0%B8%E5%BF%83%E6%9C%BA%E5%88%B6.assets/image-20230813160316780.png)

### 持久化处理过期

#### RDB

**1 从内存数据库持久化数据到RDB文件**

持久化key之前，会检查是否过期，过期的key不进入RDB文件 

**2 从RDB文件恢复数据到内存数据库**

数据载入数据库之前，会对key先进行过期检查，如果过期，不导入数据库

#### AOF

**1 从内存数据库持久化数据到AOF文件**

当key过期后，还没有被删除，此时进行执行持久化操作（该key是不会进入aof文件的，因为没有发生修改命令） 当key过期后，在发生删除操作时，程序会向aof文件追加一条del命令（在将来的以aof文件恢复数据的时候该过期的键就会被删掉） AOF重写：重写时，会先判断key是否过期，已过期的key不会重写到aof文件

### 过期删除机制和内存淘汰机制

如果缓存中的数据永久存在，那占用的内存就会变得越来越大，而内存是有限的，所以缓存系统需要在需要的时候删除一些不必要的缓存数据以节约内存空间。

Redis提供了两种机制配合来达到上述目的：**过期删除机制**和**内存淘汰机制**。

因此我们可以得出两种的机制的关系：

1. 相似性：都是为了清理Redis中的缓存，释放内存的机制。
2. 不同性：过期删除机制的目的是删除掉缓存中过期的key，清理的数据是已经过期的数据，是无用的。内存淘汰机制是在当前内存超出阈值的时候，通过算法选择出要淘汰的key，此时的数据是还未过期的，选择出相对价值小的数据淘汰掉。

