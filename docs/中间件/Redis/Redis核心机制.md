@autoHeader: 2.1.1.1.1.1
<p align="right">update time : {docsify-updated}</p>

## 持久化机制



## 高可用机制

### 主从复制机制



### 哨兵机制





## 分片机制





## 内存淘汰机制

Redis共支持八种淘汰策略，分别是noeviction、volatile-random、volatile-ttl、volatile-lru、volatile-lfu、allkeys-lru、allkeys-random 和 allkeys-lfu 策略，可以分成三类看。

![image-20230812190309584](Redis%E6%A0%B8%E5%BF%83%E6%9C%BA%E5%88%B6.assets/image-20230812190309584.png)

### 不淘汰策略 

#### noeviction

Redis4.0后新增的淘汰策略，该策略是Redis的默认策略。

在这种策略下，一旦缓存被写满了，再有写请求来时，Redis 不再提供服务，而是直接返回错误。这种策略不会淘汰数据，所以无法解决缓存污染问题。一般生产环境不建议使用。

### 对设置了过期时间的数据进行淘汰 

#### volatile-random

在设置了过期时间的键值对中，进行随机删除。因为是随机删除，无法把不再访问的数据筛选出来，所以可能依然会存在缓存污染现象，无法解决缓存污染问题。

#### Volatile-ttl

Redis在筛选需删除的数据时，越早过期的数据越优先被选择。

#### volatile-lru

##### LRU算法

LRU 算法的全称是 Least Recently Used，按照最近使用的原则来筛选数据，最近使用的数据会留在缓存中，是一种按照访问时间进行淘汰的算法。

**LRU 策略的核心思想：如果一个数据刚刚被访问，那么这个数据肯定是热数据，还会被再次访问**。

LRU 会把所有的数据组织成一个链表，链表的头和尾分别表示 MRU 端和 LRU 端，分别代表最近最常使用的数据和最近最不常用的数据。

![image-20230812185829269](Redis%E6%A0%B8%E5%BF%83%E6%9C%BA%E5%88%B6.assets/image-20230812185829269.png)



##### Redis中LRU实现

LRU 算法在实际实现时，需要用链表管理所有的缓存数据，这会带来额外的空间开销。而且，当有数据被访问时，需要在链表上把该数据移动到 MRU 端，如果有大量数据被访问，就会带来很多链表移动操作，会很耗时，进而会降低 Redis 缓存性能。所以，在 Redis 中，LRU 算法被做了简化，以减轻数据淘汰对缓存性能的影响。

Redis 在实现 LRU 策略时使用了两个近似方法：

1、RedisObject 结构中设置了一个 lru 字段，用来记录数据的访问时间戳；

2、Redis 并没有为所有的数据维护一个全局的链表，而是通过随机采样方式，选取一定数量的数据放入候选集合，后续在候选集合中根据 lru 字段值的大小进行筛选。

具体淘汰过程为：

1. 第一次会随机选出 N 个数据，把它们作为一个候选集合。接下来，Redis 会比较这 N 个数据的 lru 字段，把 lru 字段值最小的数据从缓存中淘汰出去。
2. 当需要再次淘汰数据时，Redis 需要挑选数据进入第一次淘汰时创建的候选集合。这儿的挑选标准是：能进入候选集合的数据的 lru 字段值必须小于候选集合中最小的 lru 值。当有新数据进入候选数据集后，如果候选数据集中的数据个数达到了 maxmemory-samples，Redis 就把候选数据集中 lru 字段值最小的数据淘汰出去。这样一来，Redis 缓存不用为所有的数据维护一个大链表，也不用在每次数据访问时都移动链表项，提升了缓存的性能。

![image-20230812185405802](Redis%E6%A0%B8%E5%BF%83%E6%9C%BA%E5%88%B6.assets/image-20230812185405802.png)

Redis 提供了一个配置参数 maxmemory-samples，这个参数就是 Redis 选出的数据个数 N。例如，执行如下命令，可以让 Redis 选出 100 个数据作为候选数据集：

> CONFIG SET maxmemory-samples 100

##### LRU的优劣

优势：

在数据被频繁访问的业务场景中，LRU 策略的确能有效留存访问时间最近的数据。而且，因为留存的这些数据还会被再次访问，所以又可以提升业务应用的访问速度。

劣势：

1. **只看数据的访问时间**，使用 LRU 策略在处理扫描式单次查询操作时，无法解决缓存污染。
2. 临时数据可能会取代真正经常使用的数据。比如，短时间内，大量临时数据涌入 redis，而触发发生内存淘汰，可能会将那些真正经常使用的数据驱逐。

> 扫描式单次查询操作，就是指应用对大量的数据进行一次全体读取，每个数据都会被读取，而且只会被读取一次。此时，因为这些被查询的数据刚刚被访问过，所以 lru 字段值都很大。

#### volatile-lfu

LFU 算法的全称是 Least Frequently Used，也就是每次淘汰那些使用次数最少的数据，是一种按照访问频次进行淘汰的算法。

##### LFU算法

LFU将数据和数据的访问频次保存在一个容量有限的容器中，当访问一个数据时：

1. 该数据在容器中，则将该数据的访问频次加1。
2. 该数据不在容器中，则将该数据加入到容器中，且访问频次为1。

当数据量达到容器的限制后，会剔除掉访问频次最低的数据。

![image-20230812193611958](Redis%E6%A0%B8%E5%BF%83%E6%9C%BA%E5%88%B6.assets/image-20230812193611958.png)

**常规LFU算法面临的问题**

在数据请求模式比较稳定（没有对于某个数据突发的高频访问这样的不稳定模式）的情况下，LFU的表现还是很不错的。

但在数据的请求模式大多不稳定的情况下，LFU一般会有这样一些问题：

1. **热点数据问题**：热点数据一般只是几天内有较高的访问频次，过了这段时间就没那么大意义去缓存了。但是因为在热点期间他的频次被刷上去了，导致之后很长一段时间内很难被淘汰；
2. **新增数据问题**：如果采用只记录缓存中的数据的访问信息，新加入的高频访问数据在刚加入的时候由于没有累积优势，很容易被淘汰掉；
3. **空间问题**：如果记录全部出现过的数据的访问信息，会占用更多的内存空间。

##### Redis中LFU实现

Redis 在实现 LFU 策略的时候，同样采用了近似的实现方法，引入了三个策略：

1. 概率量级计数：非线性递增的技术方法节省计数器字段空间，可配参数server.lfu_log_factor，影响计数的量级范围，整计数器counter的增长速度，lfu-log-factor越大，counter增长的越慢。
2. 计数衰减：可以解决热点数据问题，配置参数server.lfu-decay-time，控制LFU计数衰减，是一个以分钟为单位的数值，可以调整counter的减少速度。
3. 复用LRU字段，把原来 24bit 大小的 lru 字段，又进一步拆分成了两部分:
   - ldt 值：lru 字段的前 16bit，表示数据的访问时间戳；
   - counter 值：lru 字段的后 8bit，表示数据的访问次数。

当 LFU 策略筛选数据时，Redis 会在候选集合中，根据数据 lru 字段的后 8bit选择访问次数最少的数据进行淘汰。当访问次数相同时，再根据 lru 字段的前 16bit 值大小，选择访问时间最久远的数据进行淘汰。

**（一）计数衰减**

某个key的counter被衰减的时机是在它被访问的时候。计数衰减的触发也是被动的，而非Redis主动或者定时触发的。在缓存被访问时，会更新数据的访问计数，更新的步骤是：

1. 先在现有数据的计数上进行计数衰减。
2. 再对完成衰减后的计数进行概率增加。

计数衰减的思想为：可配参数server.lfu-decay-time所代表的含义是计数衰减的周期长度，单位是分钟。**当时间过去一个周期（也就是lfu-decay-time分钟），计数值就会减1**。基于这样的思想，其具体过程为：

1. redisObject结构中的lru字段的高16bit，记录的是该key上次进行衰减的时间。通过**(当前时间-上次衰减的时间）/ （周期单位）**即为key需要将counter衰减的数量n。
2. 通过`LFUDecrAndReturn`方法得到该key的counter，将counter=counter-n。

**（二）概率量级计数**

Redis中给counter配置了8bit的存储空间，也就是counter最大值为255：

1. 当counter等于最大值 255 时，不再增加counter。
2. 当counter小于 255 时，Redis会计算一个阈值 p，以及一个取值为 0 到 1 之间的随机概率值 r。如果概率 r 小于阈值 p，counter加 1；否则counter不变。

其中，`p=1/(counter*factor+1)`，可配参数server.lfu_log_factor越大时，概率p在同等情况下则会越低，counter字段8 bit一共255的上限也就越不容易被触达，换句话说，factor越大，Redis的counter字段能够记录的访问频次量级也就越高。

**（三）key的初始化及更新**

1、key被创建时，对 redisObject 结构体中的 lru 变量初始化值，会由两部分组成：

- ldt值设置为当前时间。
- counter值，被设置为宏定义 LFU_INIT_VAL，默认值为 5。

2、key被访问时更新变量值：

- 根据距离上次访问的时长，衰减访问计数
- 根据当前访问次数更新访问counter值
- 调用 LFUGetTimeInMinutes 函数，来获取当前的时间戳，并和更新后的访问次数组合，形成最新的访问频率信息，赋值给键值对的 lru 变量。

##### LFU的优劣

优点：通过key的访问频率和访问时间比较来淘汰key，重点突出的是Frequently Used，用于在缓存容量有限时决定哪些缓存块应该被清除，避免了LRU算法的明显缺陷。

缺点：最近加入的数据总是易于被剔除（缓存末端抖动），因为他起始的频率很低。

### 对全部数据进行淘汰 

#### allkeys-random

从所有键值对中随机选择并删除数据。

volatile-random 跟 allkeys-random算法一样。

#### allkeys-lru

使用 LRU 算法在所有数据中进行筛选。

具体LFU算法跟上述 volatile-lru 中介绍的一致，只是筛选的数据范围是全部缓存。

#### allkeys-lfu

使用 LFU算法在所有数据中进行筛选。

具体LFU算法跟上述 volatile-lfu 中介绍的一致，只是筛选的数据范围是全部缓存。

### 淘汰过程

![image-20230812221333276](Redis%E6%A0%B8%E5%BF%83%E6%9C%BA%E5%88%B6.assets/image-20230812221333276.png)

真正的淘汰包括下面的内容：

- 何时清理
- 如何清理，清理哪些 --- 依据淘汰策略指定
- 清理多少

#### 清理时机

每一条客户端的请求处理之后，看是否有必要进行内存淘汰。如果需要，走淘汰逻辑，此时分两种情况：

1. 淘汰数据少：这种很理想，一次性可以搞定。
2. 淘汰数据多：如果数据过多，为避免长时间阻塞，提供了一些可配置的限制，如果达到限制条件还没有清理完成，暂时放入到时间事件中，等待下一轮清理。

#### 清理多少

待清理的大小 = used - maxmemory，即当前使用内存大小 - 设定的阈值。

一次性没处理完（可以设置一定时长限制），可以扔到时间事件中，周期性的处理，直到达到目标 ...

清理的目标是使得当前内存小于maxmemory

## 过期删除机制

Redis 是可以对 key 设置过期时间的，因此需要有相应的机制将已过期的键值对删除，而做这个工作的就是过期键值删除策略。

### 设置过期时间

设置 key 过期时间的命令一共有 4 个：

- `expire key n  `：设置 key 在 n 秒后过期；
- `pexpire key n`：设置 key 在 n 毫秒后过期;
- `expireat key n  `：设置 key 在某个时间戳（精确到秒）之后过期；
- `pexpireat key n`：设置 key 在某个时间戳（精确到毫秒）之后过期；

当然，在设置字符串时，也可以同时对 key 设置过期时间，共有 3 种命令：

- `set key value ex n ` ：设置键值对的时候，同时指定过期时间（精确到秒）；
- `set key value px n ` ：设置键值对的时候，同时指定过期时间（精确到毫秒）；
- `setex key n value   ` ：设置键值对的时候，同时指定过期时间（精确到秒）。

### 判断key过期

当对一个 key 设置了过期时间时，Redis 会把该 key 带上过期时间存储到一个**过期字典**（expires dict）中，其数据结构如下。

![image-20230812224425577](Redis%E6%A0%B8%E5%BF%83%E6%9C%BA%E5%88%B6.assets/image-20230812224425577.png)

其中，过期字典的 key 是一个指针，指向某个键对象；过期字典的 value 是一个 long long 类型的整数，这个整数保存了 key 的过期时间；

当我们查询一个 key 时，Redis 首先检查该 key 是否存在于过期字典中：

- 如果不在，则正常读取键值；
- 如果存在，则会获取该 key 的过期时间，然后与当前系统时间进行比对，如果比系统时间大，那就没有过期，否则判定该 key 已过期。

### 过期删除策略

#### 定时删除



#### 惰性删除



#### 定期删除



### 持久化处理过期

#### RDB

**1 从内存数据库持久化数据到RDB文件**

持久化key之前，会检查是否过期，过期的key不进入RDB文件 

**2 从RDB文件恢复数据到内存数据库**

数据载入数据库之前，会对key先进行过期检查，如果过期，不导入数据库

#### AOF

**1 从内存数据库持久化数据到AOF文件**

当key过期后，还没有被删除，此时进行执行持久化操作（该key是不会进入aof文件的，因为没有发生修改命令） 当key过期后，在发生删除操作时，程序会向aof文件追加一条del命令（在将来的以aof文件恢复数据的时候该过期的键就会被删掉） AOF重写：重写时，会先判断key是否过期，已过期的key不会重写到aof文件

### 过期删除机制和内存淘汰机制

如果缓存中的数据永久存在，那占用的内存就会变得越来越大，而内存是有限的，所以缓存系统需要在需要的时候删除一些不必要的缓存数据以节约内存空间。

Redis提供了两种机制配合来达到上述目的：**过期删除机制**和**内存淘汰机制**。

因此我们可以得出两种的机制的关系：

1. 相似性：都是为了清理Redis中的缓存，释放内存的机制。
2. 不同性：过期删除机制的目的是删除掉缓存中过期的key，清理的数据是已经过期的数据，是无用的。内存淘汰机制是在当前内存超出阈值的时候，通过算法选择出要淘汰的key，此时的数据是还未过期的，选择出相对价值小的数据淘汰掉。

