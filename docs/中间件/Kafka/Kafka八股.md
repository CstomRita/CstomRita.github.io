@autoHeader: 2.1.1.1.1.1
<p align="right">update time : {docsify-updated}</p>

## 架构篇

### 说一下Kafka的架构？

Kafka架构可以从分布式、面向主题、多分区、多副本四个方面来理解。

对于分布式，Kafka集群中每个Kafka服务节点称为broker，一个集群由多个broker组成，一个broker可以容纳多个topic。

对于面向主题方面，主题可以理解为一个队列，Producer生产消息发送到Kafka中，由Consumer消费者从Kafka中接收消息进行业务处理。

在多分区方面，一个topic可以分为一个或多个分区，分区是Kafka实现高吞吐的方式，每个topic可以分成多个分区，分布到多个broker上。

在多副本方面，Kafka同一分区的数据可以在多个broker上存在多 个副本，通常只有主副本对外提供读写服务，当主副本所在 节点崩溃时，重新选择新的 Leader 副本对外提供读写服务，多副本机制是保障高可用的手段。

同时，Kafka在消费层面具有消费者组机制， 一个消费者组可以包含一个或多个消费者，消费者组内每个消费者负责消费不同分区的数据，一个分区只能由一个组内消费者消费；消费者组之间互不影响。

### Kafka中的组件？

Kafka架构中的组件主要包括：

1、Producer：发送消息者，生产者负责创建消息，然后将其发送到 Kafka。

2、Consumer：消息接受者，消费者连接到 Kafka 并接收消息，进而进行相应的业务逻辑处理。

3、Consumer Group(消费组): 一个消费者组可以包含一个或多个消费者。消费者组内每个消费者负责消费不同分区的数据，一个分区只能由一个组内消费者消费；消费者组之间互不影响，所有的消费者都属于某个消费者组，即消费者组是逻辑上的一个订阅者。

4、broker：每个kafka实例(server)。Broker 是 Kafka 的服务节点，即 Kafka 的服务器。一个集群由多个broker组成。一个broker可以容纳多个topic。

5、Topic:可以理解为一个队列，一个 Topic 又分为一个或多个分区。

6、Partition(分区)：是Kafka实现高吞吐的方式，一个非常大的topic可以分布到多个broker（即服务器）上，一个topic可以分为多个partition，每个partition是一个有序的队列。

7、Replication(副本)：是 Kafka 保证数据高可用的方式，Kafka 同一Partition 的数据可以在多 Broker 上存在多 个副本，通常只有主副本对外提供读写服务，当主副本所在 Broker 崩溃或发生网络一场，Kafka 会在 Controller 的管理下会重新选择新的 Leader 副本对外提供读写服务。

8、Kafka Controller：其中有一个broker会被选举为控制器（Kafka Controller），**它的主要作用是在 ZooKeeper 的帮助下管理和协调整个 Kafka 集群**，

9、Zookeeper：依赖集群保持元信息。他的作用包括管理和协调Broker，broker的注册、出现故障的broker等。

### kafka的consumer是拉模式还是推模式

kafka的consumer为拉pull模式，生产者将消息推送到broker，消费者从broker主动拉取消息。

pull模式的不足之处是，如果Kafka没有数据，消费者可能会陷入循环中，一直返回空数据。

在push模式中，由broker决定消息推送的速率，很难适应所有消费者的消费速度，因此kafka没有选择这种模式。

### 什么是消费者组？

消费者组是 Kafka 提供的可扩展且具有容错性的消费者机制。

消费者组是一个由多个消费者实例构成的组，多个实例共同订阅若干个主题，实现共同消费。同个消费者组下的每个实例都配置有相同的组 ID，被分配不同的分区；当某个实例挂掉的时候，其他实例会自动地承担起它负责消费的分区。

kafka通过消费者组机制实现队列和发布订阅两种消息模型：

1、对于队列模型，消费者组内每个消费者负责消费不同分区的数据，每个分区的消息只能被同一个消费者组中的同一个消费者消费。

2、对于发布订阅模型，消费者组之间不影响，每个分区的消息可以被不同消费者组里的消费者消费，以此可实现广播效果。

### offset的作用？

在 Kafka 中，每个主题分区下的每条消息都被赋予了一个唯一的 ID 数值，用于标识它在分区中的位置。

这个 ID 数值，就被称为位移，或者叫偏移量，它的作用是为了唯一地区别分区中的每条消息。

### 底层是怎么存储消息的？

在物理结构上，Kafka底层选用日志文件+哈希稀疏索引的结构存储消息。

在逻辑结构上，kafka是面向主题的，具有分区-分段-索引三层结构：

- 每个主题被分成多个分区，分区从物理上可以理解成一个文件夹，命名规则为topic名称+有序序号
- 每个分区又被划分成了多个分段Segment，分段从物理上可以理解成一个「数据文件 + 索引文件」

其中：

1、数据文件为log文件，采用append追加写，存储offset和消息数据；

2、索引文件为哈希稀疏索引，Kafka将消息划分成若干个块，只索引每个块第一个消息的offset，先根据大小关系找到对应块，然后在块数据中顺序搜索。

### Kafka是怎么做文件清理的？

Kafka中默认的日志保存时间为7天，提供的日志清理策略有delete和compact两种。

1、delete策略为删除策略，按照时间属性，删除过期数据。

2、compact策略为压缩策略，对于相同key的不同value值，只保留最新版本。

### 说一下Kafka Controller？

Kafka Controller是一种特殊的broker，比普通的broker多了一些职责:

1、主题管理：执行kafka-topic脚本时，帮助我们完成对 Kafka 主题创建、删除和增加分区的操作。

2、处理副本leader的选举

3、通过观察zookeeper路径，接收broker的增减，监听broker的变化。

4、存储集群元数据信息，比如broker列表和信息、topic及分区信息等，向其他broker提供元数据服务。

### Kafka Controller中存储了什么信息？

broker controller 保存了大量的 Kafka 集群数据，主要分为三类：

1、broker 上的所有信息，包括 broker 中的所有分区，broker 所有分区副本，当前都有哪些运行中的 broker，哪些正在关闭中的 broker 。

2、所有主题信息，包括具体的分区信息，比如领导者副本是谁，ISR 集合中有哪些副本等。

3、所有涉及运维任务的分区。包括当前正在进行 Preferred 领导者选举以及分区重分配的分区列表

### Kafka Controller的选举机制？

Controller节点的选举规则为：集群中启动的 broker， 会在 ZooKeeper 里创建一个临时节点 `/controller` ，第一个创建临时节点的broker即为Controller。

若当前Controller下线，zookeeper中的临时节点就会消失，其他节点收到消息后会尝试创建临时节点，一个创建成功的即为新的Controller。

### 什么是控制器脑裂，如何解决？

控制器脑裂现象为：如果控制器所在broker挂掉了或者Full GC停顿时间太长出现假死情况下，Kafka集群必须选举出新的控制器，但如果之前被取代的控制器又恢复正常了，它依旧是控制器身份，这样集群就会出现两个控制器，这就是控制器脑裂问题。

解决方法：

ZooKeeper中还有一个与Controller有关的信息，存放的是一个整形值的编号，称为纪元编号。集群中每选举一次控制器，就会通过Zookeeper创建一个更大的纪元编号，如果有broker收到的Controller编号小于当前纪元编号，就会忽略该消息。

## 分区机制篇

### 说一下分区？

在Kafka中，主题Topic是一个逻辑上的概念，topic下细分为多个分区，某个分区只属于一个主题，同一主题下不同分区包含的消息是不同的。

在存储层面，分区可以看做一个可追加的日志文件，消息在追加到分区文件的时候，会分配一个特定的偏移量，作为消息在分区中的唯一标识，Kafka通过offset保证消息在分区中的顺序性。

### 分区的目的？

分区机制是Kafka实现高吞吐、水平扩展的机制，让数据消费更加均衡。

从逻辑组织来说，kafka有三层结构，kafka有多个主题，每个主题有多个分区，每个分区又有多条消息。以分区为单位进行数据读写，每个分区可以分布到不同的机器上，可以实现高伸缩性，以及负载均衡，动态调节的能力。

### 生产者分区策略？

分区策略就是决定生产者将消息发送到哪个分区的算法，在Kafka中分区策略包括：

	1. 轮询分区策略，按照分区编号依次将消息分配到不同的分区。
 	2. 哈希分区策略，将消息的key进行哈希计算，然后将哈希结果对分区数取余，得到消息所在的分区。
 	3. 范围分区策略，根据消息key的范围将消息分配到不同的分区。需要在创建主题时指定分区边界。
 	4. 粘性分区策略，将消息发送到同一个分区，直到该分区的消息数量超过阈值，才会将消息发送到下一个分区。这个策略可以用来保证消息的顺序性。
 	5. 自定义分区策略，用户可以根据自己的业务逻辑自定义分区策略，重写实现Partitioner类中的partition()方法。

### 消费者组分区策略？

在消费者组中，分配消费者消费哪些分区的算法有：

1. range范围分区策略

对同一个Topic里面的分区按照序号进行排序，并对消费者按照字母顺序进行排序。然后用Partitions分区的个数除以消费者线程的总数来决定每个消费者线程消费几个分区。

范围分区策略中，用partition数除以消费者线程的总数来决定每个消费者线程消费几个partition，如果除不尽，前面几个消费者将会多消费一个分区，多个topic的时候Range分区策略容易产生数据倾斜。

2. RoundRobin轮询策略

将消费组内所有消费者以及消费者所订阅的所有topic的partition按照字典序排序，通过轮询方式逐个将分区以此分配给每个消费者。

在轮询分区策略中，如果消费者订阅的topic列表是不同的，则分配结果不一定是尽量均衡的，因为某些消费者不参与一些Topic的分配。

3. 粘性分区策略

粘性分区策略的目的，一是分区的分配要尽可能的均匀，分配给消费者者的主题分区数最多相差一个；二是分区的分配尽可能的与上次分配的保持相同。

Kafka可以同时使用多个分区分配策略。

### 分区个数如何确定？

在`server.properties`包含默认主题分区数配置选项，默认情况下按照配置项数量进行配置。

也可以在创建topic时使用`-partitions`参数指定分区。

对于分区个数，分区越多，所需要消耗的资源就越多，并不是分区越多性能越好。确定分区个数的方式有：

1. 结合具体业务的处理速度和时间来估算。假如每秒钟需要从主题写入和读取1GB数据，而消费者1秒钟最多处理50MB的数据，那么这个时候就可以设置20-25个分区，当然还要结合具体的物理资源情况。
2. 基准测试来测试，创建不同分区的topic，逐步压测测出最终的结果。
3. 一般情况下，推荐确定分区数的方式就是broker机器数量的2~3倍。

## 多副本机制篇

### 说一下多副本？

在分区中又引入了多副本的概念，通过增加副本数量可以提高容灾能力。

同一分区的不同副本中保存的是相同的消息。副本之间是一主多从的关系，其中主副本负责读写，从副本只负责消息同步。副本处于不同的 broker 中，当主副本出现异常，便会在从副本中提升一个为主副本。

### 多副本的目的？



### 副本的分类？



### 副本分配策略？

副本分配策略为分配副本应该处于哪些broker上，在创建主题时 ：

- 如果使用了replica-assignment 参数，那么就按照指定的方案来进行分区副本的创建；
- 如果没有指定replica-assignment 参数，那么就按照Kafka内部逻辑来分配，内部逻辑按照机架信息分为两种策略：**无机架分配** 和 **有机架分配**。

其总体原则为：

1. 将副本平均分布在所有的 Broker 上;
2. partition 的多个副本应该分配在不同的 Broker 上;
3. 如果所有的 Broker 有机架信息的话, partition 的副本应该分配到不同的机架上。

在无机架分配中，随机选一个broker作为分区的第一个副本，随机生成副本间隔参数用以分配下一个副本；每经历一轮Broker List的遍历，间隔参数加1。

在有机架分配中，额外设置机架信息，按照交替机架的Broker顺序进行分配。

### 副本follower为什么不对外提供服务？

这个问题本质上是对性能和一致性的取舍。

如果副本Follower可以对外提供服务，性能虽然提升了，但可能出现数据不一致的问题，例如现在写入一条数据到kafka主题a，消费者b从主题a消费数据，却发现消费不到，因为消费者b去读取的那个分区副本中，最新消息还没写入。而这个时候，另一个消费者c却可以消费到最新那条数据，因为它消费了leader副本。

### 副本Leader选举策略？



### 副本leader选举时机？



### 副本间如何同步？







## 应用篇

### 如何基于Kafka实现优先队列

大致有以下方案

（一）consumer 各自拉取，使用优先级队列重新缓冲。

这种对内存要求很大，而且单纯靠内存，程序崩溃后难以找回未消费消息。

（二）先拉取高优先级topic的数据，只要有就一直消费，直到没有数据再消费低一级topic。消费低一级topic的过程中，如果发现有高一级topic消息到来，则转向消费高优先级消息。

该方案在高峰时段可能会导致低优先级消息完全失去消费机会，这种要看应用场景，比如在一些任务调度上，资源有限，高峰时段全部在高优先级任务上，也是符合设计的。

（三）实现相对的有序，先不考虑优先级，在高中低优先级consumer中循环拉取一批次，在该批次消费中，优先消费优先级高的。

该方案实现的是相对的有序，无法做到当高中低都有消息待消费时，集中全力先消费高优先级的消息。

```java
// 同时维护多个consumer
private Map<Integer, KafkaConsumer<K, V>> consumers;
public ConsumerRecords<K, V> poll(long pollTimeoutMs) {
    Map<TopicPartition, List<ConsumerRecord<K, V>>> consumerRecords = 
        new HashMap<TopicPartition, List<ConsumerRecord<K, V>>>();
    long start = System.currentTimeMillis();
    do {
        // 每一次整体“拉取”，都调用每个“子”consumer 拉取一次
        for (int i = maxPriority - 1; i >= 0; --i) {
            ConsumerRecords<K, V> records = consumers.get(i).poll(0);
            for (TopicPartition partition : records.partitions()) {
                consumerRecords.put(partition, records.records(partition));
            }
        }
    } while (consumerRecords.isEmpty() && System.currentTimeMillis() < (start + pollTimeoutMs));
    ...
}
```

### 如何保障消息可靠性/避免丢消息？

**生产者**

对于生产者，当生产者发送数据时，可以通过request.required.acks参数来设置数据可靠性的级别：

- acks=0： 表示producer不需要等待任何broker确认收到消息的回复，就可以继续发送下一条消息。

  性能最高，但是最容易丢消息。大数据统计报表场景，对性能要求很高，对数据丢失不敏感的情况可以用这种。

- acks=1： 至少要等待leader已经成功将数据写入本地log，但是不需要等待所有follower是否成功写入。

  这种情况下，如果follower没有成功备份数据，而此时leader又挂掉，则消息会丢失。

- acks=-1或all： 这意味着leader需要等待所有备份(min.insync.replicas配置的备份个数)都成功写入日志，这种策略会保证只要有一个备份存活就不会丢失数据。

  这是最强的数据保证。一般除非是金融级别，或跟钱打交道的场景才会使用这种配置。

**消费者**

对于消费者，如果消费这边配置的是自动提交，万一消费到数据还没处理完，就自动提交offset了，但是此时consumer直接宕机了，未处理完的数据丢失了，下次也消费不到了。

避免可以采用手动提交offset，确保消息成功消费之后再提交offset。

### 如何提高吞吐量？



### 如何保障消息的唯一性/避免重复消息和漏消费？





### Kafka如何保证消息有序性？

Kafka中是以分区作为单元进行消费的，同一个分区使用offset偏移量作为唯一标识，保证顺序性，但这只是保证分区内部的顺序性，而不能保证整个topic的有序性。

如果局部有序性不能满足需求，为了实现消息的全局有序，需要将所有消息发往同一个分区中才能保证消息顺序消费，那么可以：

- 如果是是全部消息都要全局有序，可以仅设置一个分区；
- 如果是部分消息要求全局有序，可以设置多个分区，在发送的时候指定 MessageKey，同一个key的消息会发到同一个分区中。

### 生产过程中何时会发生QueueFullExpection以及如何处理？

当生产者试图发送消息的速度快于Broker可以处理的速度时，通常会发生 `QueueFullException`

解决方案如下：

- 先进行判断生产者是否能够降低生产速率
- 如果生产者不能阻止这种情况，为了处理增加的负载，增加 Broker数量
- 或者选择生产阻塞，设置`Queue.enQueueTimeout.ms` 为 -1，通过这样处理，如果队列已满的情况，生产者将阻塞

> [!tip]`Queue.enQueueTimeout.ms` 字段说明：
>
> - 默认的 enqueueTimeout是0，如果producer内部的队列满了，数据(messages)会被丢弃，并抛出QueueFullExceptions异常
> - 阻塞模式的producer(queue.enqueueTimeout.ms=-1)，如果内部队列满了就会一直等待，从而有效的节制内置consumer的消费速度
