@autoHeader: 2.1.1.1.1.1

<p align="right">update time : {docsify-updated}</p>



> 一个事务是可以被看作一个单元的一系列SQL语句的集合。



## 事务基础

### 事务ACID特性

事务的 ACID 特性概念简单，但不是很好理解，主要是因为这几个特性不是一种平级关系：

- 只有满足一致性，事务的执行结果才是正确的。
- 在无并发的情况下，事务串行执行，隔离性一定能够满足。此时只要能满足原子性，就一定能满足一致性。
- 在并发的情况下，多个事务并行执行，事务不仅要满足原子性，还需要满足隔离性，才能满足一致性。
- 事务满足持久化是为了能应对系统崩溃的情况。

![image-20230826134018727](%E4%BA%8B%E5%8A%A1.assets/image-20230826134018727.png)

#### 原子性

**概念**

事务被视为不可分割的最小单元，事务的所有操作要么全部提交成功，要么全部失败回滚。

**实现**

回滚可以用回滚日志（Undo Log）来实现，回滚日志记录着事务所执行的修改操作，在回滚时反向执行这些修改操作即可。

#### 一致性

**概念**

数据库在事务执行前后都保持一致性状态。在一致性状态下，所有事务对同一个数据的读取结果都是相同的。

#### 隔离性

**概念**

一个事务所做的修改在最终提交以前，对其它事务是不可见的。

#### 持久性

**概念**

一旦事务提交，则其所做的修改将会永远保存到数据库中。即使系统发生崩溃，事务执行的结果也不能丢失

**实现**

系统发生崩溃可以用重做日志（Redo Log）进行恢复，从而实现持久性。与回滚日志记录数据的逻辑修改不同，重做日志记录的是数据页的物理修改。

### 事务的分类

#### 扁平事务

所有操作处于同一个层次中，从BEGIN WORK开始事务

所有操作完成之后 COMMIT WORK提交事务 事务执行成功

如果在操作中间出现了失败，则ROLLBACK WORK回滚所有已经执行的操作

扁平事务的主要限制在于不能提交或者回滚事务的一部分，它要么全部提交，要么全部回滚

但是某些事务可能在执行过程中出现的错误并不会导致所有的操作都无效，放弃整个事务似乎不大合理，开销也很大

当我们想回滚到之前某个已经完成的节点上就需要带有保存点

#### 带有保存点的扁平事务

除了支持扁平化支持的操作，还允许事务执行过程中回滚到同一事务中较早的一个状态

保存点使用SAVE WORK函数用来通知系统应该记住事务的当前状态，当出现问题时保存点可以作为内部的重启动点，根据应用逻辑决定返回哪一个保存点

需要注意的是，保存点在事务内部是递增的，ROLLBACK不会影响保存点的计数

举例：当前Savepoint5，ROLLBACK返回savepoint2之后，此时事务依然处于活跃状态，如果继续回滚ROLLBACK WORK回滚所有操作，那么事务就不再活跃，如果继续操作调用SAVE WORK保存保存点是Savepoint是依然递增savepoint6而非在2的基础上

带有保存点的扁平事务的缺陷：

保存点是易失的，而非持久的

**带有保存点的扁平事务，当发生系统崩溃时所有的保存点都会消失，当进行恢复时事务需要从开始处重新执行而非最近的一个保存点继续执行**

#### 链事务

链事务是对保存点模式的一种变种

链事务的思想在于释放不需要的数据对象，将必要的处理上下文传递给下一个要开始的事务

**提交事务和开始下一个事务操作合并成一个原子操作**，这就意味着下一个事务将看到上一个事务的结果

链事务和带有保存点的扁平事务不同的是：

链事务仅限制于回滚当前事务，只能恢复到最近的一个保存点

链事务在执行完当前事务的COMMIT操作之后即释放了当前事务所持有的锁

而带有保存点的扁平事务不会影响持有的锁

#### 嵌套事务

嵌套事务是一个层次结构框架，由一个顶层事务控制着各个层次的事务，顶层事务之下嵌套的事务叫做子事务

1. 每一个子事务可以是一个扁平化事务，也可以 是一个嵌套事务
2. 处于叶节点的事务是扁平事务，根节点的叫做顶层事务
3. 子事务可以提交也可以回滚，事务提交需要等到父事务提交之后才能真正提交，如此遍历一切事务的提交都要等到顶层事务的提交；子事务的回滚会引起这个事务的所有子事务的回滚
4. 子事务不具有D的特性

不同的子事务在数据库对象中持有不同的对象锁

如果想实现事务间的并行，需要支持嵌套事务

#### 分布式事务 [单独说明]

分布式事务是在一个分布式环境下运行的**扁平事务**，根据**数据库所在位置**访问网络中不同节点

(数据部署在每一个节点上，在不同节点上对一个数据库操作的情况)

访问网络中多个节点的数据库，而每个节点上数据库的执行操作都是扁平事务 

分布式事务同样满足ACID特性，要么都发生要么都失效

### 并发一致性问题

在并发环境下，事务的隔离性很难保证，因此会出现很多并发一致性问题。

> [!note]
>
> 数据库并发场景有三种：
>
> - **读-读**：不存在任何问题，也不需要并发控制
> - **读-写**：有线程安全问题，可能会造成事务隔离性问题，可能遇到脏读，幻读，不可重复读
> - **写-写**：有线程安全问题，可能会存在更新丢失问题，比如第一类更新丢失，第二类更新丢失

#### 修改丢失

丢失修改指一个事务的更新操作被另外一个事务的更新操作替换。

![image-20230827135342420](%E4%BA%8B%E5%8A%A1.assets/image-20230827135342420.png)

例如：T1 和 T2 两个事务都对一个数据进行修改，T1 先修改并提交生效，T2 随后修改，T2 的修改覆盖了 T1 的修改。

#### 脏读

读脏数据指在不同的事务下，当前事务可以读到另外事务未提交的数据。

![image-20230827135440224](%E4%BA%8B%E5%8A%A1.assets/image-20230827135440224.png)

例如：T1 修改一个数据但未提交，T2 随后读取这个数据。如果 T1 撤销了这次修改，那么 T2 读取的数据是脏数据。

#### 不可重复读

不可重复读指在一个事务内多次读取同一数据集合。在这一事务还未结束前，另一事务也访问了该同一数据集合并做了修改，由于第二个事务的修改，第一次事务的两次读取的数据可能不一致。

![image-20230827135536480](%E4%BA%8B%E5%8A%A1.assets/image-20230827135536480.png)

例如：T2 读取一个数据，T1 对该数据做了修改。如果 T2 再次读取这个数据，此时读取的结果和第一次读取的结果不同。

> 不可重复读和脏读区别在于，脏读读取的是其他事务**还未提交**的数据，不可重复读读取的是其他数据**提交之后**的数据

#### 幻读

幻读本质上也属于不可重复读的情况，T1 读取某个范围的数据，T2 在这个范围内插入新的数据，T1 再次读取这个范围的数据，此时读取的结果和和第一次读取的结果不同。

![image-20230827135655735](%E4%BA%8B%E5%8A%A1.assets/image-20230827135655735.png)

> 幻读，在一定程度上表现和不可重复读一样
>
> 都是另外一个事务同时操作导致，所读取的数据不再相同
>
> 但两者的侧重不同：不可重复读表现在update/delete，另外一个事务修改这一行数据；幻读表现在insert，插入一条新的消费记录，使得账户余额不同
>
> 不可重复读仅仅锁住那一行记录行即可；但是幻读需要锁住的是整张表

### 封锁协议

#### 一级封锁协议

![image-20230828135725879](%E4%BA%8B%E5%8A%A1.assets/image-20230828135725879.png)

事务 T 要修改数据 A 时必须加 X 锁，直到 T 结束才释放锁。

可以解决丢失修改问题，因为不能同时有两个事务对同一个数据进行修改，那么事务的修改就不会被覆盖。

#### 二级封锁协议

![image-20230828135800458](%E4%BA%8B%E5%8A%A1.assets/image-20230828135800458.png)

在一级的基础上，要求读取数据 A 时必须加 S 锁，读取完马上释放 S 锁。

可以解决读脏数据问题，因为如果一个事务在对数据 A 进行修改，根据 1 级封锁协议，会加 X 锁，那么就不能再加 S 锁了，也就是不会读入数据。

#### 三级封锁协议

![image-20230828135828166](%E4%BA%8B%E5%8A%A1.assets/image-20230828135828166.png)

在二级的基础上，要求读取数据 A 时必须加 S 锁，直到事务结束了才能释放 S 锁。

可以解决不可重复读的问题，因为读 A 时，其它事务不能对 A 加 X 锁，从而避免了在读的期间数据发生改变。

#### 两段锁协议

两段锁协议指事务必须分成两个阶段对数据进行加锁和解锁，在释放一个封锁以后，事务不在申请获得其它封锁。

1. 第一段是获得封锁，也称扩展阶段

事务可以获得任何数据项上任何类型的锁，但是不能释放锁

2. 第二段是释放封锁，也称收缩阶段

事务可以释放任何数据项上任何类型的锁，但是不能获得锁

```
lock-x(A)
...
lock-s(B)
...
lock-s(C)
...
unlock(A)
...
unlock(C)
...
unlock(B)
```

可串行化调度是指，通过并发控制，使得并发执行的事务结果与某个串行执行的事务结果相同。串行执行的事务互不干扰，不会出现并发一致性问题。

事务遵循两段锁协议是保证可串行化调度的充分不必要条件，满足两段锁协议是可串行调度，不满足两段锁协议也可能是可串行调度【如下，不满足两段锁协议，但也是可串行调度】

```
lock-x(A)
...
unlock(A)
...
lock-s(B)
...
unlock(B)
...
lock-s(C)
...unlock(C)
```

### 隔离级别

![image-20230827165744716](%E4%BA%8B%E5%8A%A1.assets/image-20230827165744716.png)

#### 读未提交

这是事务的最低级别，事务中的修改，即使没有提交，对其它事务也是可见的。

#### 读已提交

保证一个事务修改的数据提交后才能被另外一个事务读取，另外一个事务不能读取该事务未提交的数据。

换句话说，一个事务所做的修改在提交之前对其它事务是不可见的。

#### 可重复读

**这是MySQL的默认事务隔离级别**，它确保同一事务的多个实例在并发读取数据时，会看到同样的数据行。

#### 串行化

强制事务串行执行，这样多个事务互不干扰，不会出现并发一致性问题。

这是花费最高代价但是最可靠的事务隔离级别。事务被处理为顺序执行。



## 事务的使用

### InnoDB引擎

#### 开启一个事务

在InnoDB中分为自动开启自动提交，手动开启手动提交，自动开启手动提交三种情况：

| 提交机制 | 设置语句 | 说明 | SQL |
| --------------- | ------------------ | ------------------------------------------------------------ | ---------------------------------- |
| 自动 <br>开启自动提交 | set autocommit = 1 | 系统则默认用户对数据库的每一个SQL操作为一个孤立的事务，也就是说用户每进行一次操作系都会即时提交或者即时回滚。这种情况下用户的每一个SQL都是一个独立的事务 | SQL语句； COMMIT；                 |
| 手动开启手动提交 | set autocommit = 1 | 用户执行start transaction命令时一个事务开启，当用户执行commit命令时当前事务提交。从用户执行start transaction命令到用户执行commit命令之间的一系列操作为一个完整的事务周期。若不执行commit命令，系统则默认事务回滚。 | START TRANSACTION; SQL语句 COMMIT; |
| 自动开启手动提交 | set autocommit = 0 | 事务则在用户本次对数据进行操作时自动开启，在用户执行commit命令时提交，用户本次对数据库开始进行操作到用户执行commit命令之间的一系列操作为一个完整的事务周期。若不执行commit命令，系统则默认事务回滚。 | SQL语句                            |



## InnoDB引擎事务的实现

事务的持久性D通过数据库的redo log 实现；

事务的原子性A通过数据库的undo log实现；

事务隔离性I由锁和MVCC来完成。



### 持久性-redo log

#### redo log

redo log 【重做日志】是 InnoDB 引擎特有的日志， 是物理日志，记录的是“在某个数据页上做了什么修改”。

当事务提交时，必须先将事务的所有日志写入日志文件进行持久化，就是我们常说的WAL(write ahead log)机制，这样才能保证断电或宕机等情况发生后，已提交的事务不会丢失，这个能力称为 crash-safe。

#### redo log 写入流程

![image-20230827150435788](%E4%BA%8B%E5%8A%A1.assets/image-20230827150435788.png)

可以发现，更新操作的数据并没有直接写入磁盘，而且写入内存的buffer) pool ，**数据的持久化操作，是通过redo log 来完成的**。

Redo log包括两部分，重做日志缓冲(redo log buffer)和重做日志文件(redo log file)，前者是易失的缓存，后者是持久化的文件。

##### Redo log落盘

![img](%E4%BA%8B%E5%8A%A1.assets/5175b9c1e6939823a44a59c6eed27e1f.jpg)

在事务运行的过程中，MySQL 会先把日志写到 redolog buffer 中，等到事务真正提交的时候，再统一把 redolog buffer 中的数据写到 redolog 文件中。

从 redolog buffer 写到 redolog 文件中的操作，仅仅是把 redolog 写到了文件系统的 page cache系统缓存 上，最后还需要执行 fsync 才能够实现真正的落盘。

InnoDB 提供了 innodb_flush_log_at_trx_commit 参数，它有三种可能取值：

- innodb_flush_log_at_trx_commit = 0

每次事务提交的时候，都只是把 redolog 留在 redolog buffer 中，InnoDB 有一个后台线程，每隔 1 秒轮询一次，具体的操作是这样的：调用 write 将 redolog buffer 中的日志写到文件系统的 page cache，然后调用 fsync 持久化到磁盘。

当 `innodb_flush_log_at_trx_commit `的值为 0 时性能好，由后台 Master 线程每隔 1秒执行一次操作，可能会丢失 master thread 还没刷进磁盘的这一秒内的事务数据。

- innodb_flush_log_at_trx_commit = 1

每次事务提交的时候，都执行 fsync 将 redolog 直接持久化到磁盘。

当 `innodb_flush_log_at_trx_commit` 的值为1 时，这是最安全、性能最差的方式。

> [!tip]举个例子，假设事务 A 执行到一半，已经写了一些 redolog 到 redolog buffer 中，这时候有另外一个事务 B 提交，按照 innodb_flush_log_at_trx_commit = 1 的逻辑，事务 B 要把 redolog buffer 里的日志全部持久化到磁盘，这时候，就会带上事务 A 在 redolog buffer 里的日志一起持久化到磁盘

- innodb_flush_log_at_trx_commit = 2

每次事务提交的时候，都只执行 write 将 redolog 写到文件系统的 page cache 中，后台线程一秒执行一次刷盘操作。

如 DB 发生故障，期望且操作系统也出现了宕机，文件系统中没有及时写入磁盘的数据就会丢失1s的数据。

##### 二阶段提交

二阶段提交其实指的就是redo log在事务过程中，两个状态【prepare/commit】的变化阶段

**为什么一定需要二阶段提交？**

假如redo log不涉及状态的变化，提交之前的操作是 写入redo log 和binlog

那么无论维护两份日志的先后顺序是怎样的，都有可能在中间出现宕机的情况，重启后会出现binlog和实际数据不一致的情况，而我们并没有依据证明哪个日志是合理的。而如果有二阶段提交，redo log的两个状态会帮助我们去作出抉择：

1. binlog没日志，redo log状态为prepare，则事务进行回滚操作
2. binlog 有日志，redo log状态为prepare，则事务进行提交操作

#### 恢复原理

redo log是指在回放日志的时候把已经COMMIT的事务重做一遍，对于没有commit的事务按照abort处理，不进行任何操作。

#### binglog

##### binglog的作用

binlog【归档日志】是Mysql sever层维护的一种二进制日志，与innodb引擎中的redo/undo log是完全不同的日志；其主要是用来记录对mysql数据更新或潜在发生更新的SQL语句，并以"事务"的形式保存在磁盘中；

作用主要有：

- 复制：MySQL Replication在Master端开启binlog，Master把它的二进制日志传递给slaves并回放来达到master-slave数据一致的目的
- 数据恢复：通过mysqlbinlog工具恢复数据
- 增量备份

##### Redo log和bin log的不同

redo log是innodb的存储引擎产生的，而binlog是数据库的server层实现的。换句话说，如果你使用MySQL，换其他存储引擎，那么可能没有redo log，但是还是会有binlog。

- 日志记录的内容形式不同。

binlog是一种逻辑日志，记录对应的SQL语句，而redo log记录了物理日志，是针对每个数据页的修改。

- 日志写入时间不同。

binlog只有在事务提交后完成一次写入，对于一个事物而言，在binlog中只有一条记录。而redo log在事务进行中不断被写入，而且是并发写入的，不是顺序写入的。![跟面试官侃半小时MySQL事务，说完原子性、一致性、持久性的实现-开源基础软件社区](%E4%BA%8B%E5%8A%A1.assets/6892e87507b8f9ad70a0999adb9a861e00824c.png)

- 保存方式不同。

redo log 是循环写的，空间固定会用完;binlog 是可以追加写入的。“追加写”是指 binlog 文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。

##### 为什么有了redo log，还需要binlog

在事务提交之前，同时维护redo log以及binlog的状态，我们称之为二阶段提交。

mysql 主从使用的是binlog ，如果我们单纯维护redo log，是可以达到宕机恢复数据的目的，但是从机就会出现丢失变更的情况。

所以为了达到宕机恢复、主从同步的目的，需要同时维护两份日志

### 原子性-undo log

undo log 是一种用于撤销回退的日志。在事务没提交之前，MySQL 会先记录更新前的数据到 undo log 日志文件里面，当事务回滚时，可以利用 undo log 来进行回滚。

Undo log 主要用于记录数据被修改之前的日志，在表信息修改之前先会把数据拷贝到undo log 里，当事务进行回滚时可以通过undo log 里的日志进行数据还原。

**Undo log 的用途**

（1）保证事务进行rollback时的原子性，当事务进行回滚或者系统异常需要对数据进行回滚的的时候可以用undo log的日志进行数据重做。

（2）用于MVCC快照读的数据，在MVCC多版本控制中，通过读取undo log的历史版本数据可以实现不同事务版本号都拥有自己独立的快照数据版本。

#### Undo log格式

一条记录的每一次更新操作产生的 undo log 格式都有一个 roll_pointer 指针和一个 trx_id 事务id：

- 通过 trx_id 可以知道该记录是被哪个事务修改的；
- 通过 roll_pointer 指针可以将这些 undo log 串成一个链表，这个链表就被称为版本链；

![image-20230827172759782](%E4%BA%8B%E5%8A%A1.assets/image-20230827172759782.png)

#### 回滚原理

每当 InnoDB 引擎对一条记录进行操作（修改、删除、新增）时，要把回滚时需要的信息都记录到 undo log 里，比如：

- 在**插入**一条记录时，要把这条记录的主键值记下来，这样之后回滚时只需要把这个主键值对应的记录**删掉**就好了；
- 在**删除**一条记录时，要把这条记录中的内容都记下来，这样之后回滚时再把由这些内容组成的记录**插入**到表中就好了；
- 在**更新**一条记录时，要把被更新的列的旧值记下来，这样之后回滚时再把这些列**更新为旧值**就好了。

<font color=red>在发生回滚时，就读取 undo log 里的数据，然后做原先相反操作。</font>

比如当 delete 一条记录时，undo log 中会把记录中的内容都记下来，然后执行回滚操作的时候，就读取 undo log 里的数据，然后进行 insert 操作。

#### Relog vs undo log

这两种日志是属于 InnoDB 存储引擎的日志，它们的区别在于：

- redo log 记录了此次事务「**完成后**」的数据状态，记录的是更新**之后**的值；
- undo log 记录了此次事务「**开始前**」的数据状态，记录的是更新**之前**的值；

事务提交之前发生了崩溃，重启后会通过 undo log 回滚事务，事务提交之后发生了崩溃，重启后会通过 redo log 恢复事务。

### 一致性

一致性的保证是从2个方面来保证的。

从数据库层面来看，就像一开始在定义的时候介绍的，事务的ACID性质不是完全正交的，尤其是一致性，我们可以认为原子性、持久性和隔离性都是为了实现事务的一致性，数据库必须要实现AID三大特性，才有可能实现一致性。

但是，如果你在事务里故意写出违反约束的代码，一致性还是无法保证的。例如，你在转账的例子中，你的代码里故意不给B账户加钱，那一致性还是无法保证。因此，还必须从应用层角度考虑。从应用层面，通过代码判断数据库数据是否有效，然后决定回滚还是提交数据！

### 隔离性

MVCC是 MySQL 的 InnoDB 存储引擎实现隔离级别的一种具体方式，用于实现提交读和可重复读这两种隔离级别。

而未提交读隔离级别总是读取最新的数据行，要求很低，无需使用 MVCC。

可串行化隔离级别需要对所有读取的行都加锁，单纯使用 MVCC 无法实现。

#### MVCC

实现读已提交（RC）和可重复读（RR）这两种隔离级别。

多版本并发控制（MVCC）是一种用来解决读-写冲突的无锁并发控制，也就是为事务分配单向增长的时间戳，为每个修改保存一个版本，版本与事务时间戳关联，读操作只读该事务开始前的数据库的快照。

 所以MVCC可以在并发读写数据库时，可以做到在读操作时不用阻塞写操作，写操作也不用阻塞读操作，提高了数据库并发读写的性能，同时还可以解决脏读，幻读，不可重复读等事务隔离问题，但<font color=red>不能解决更新丢失问题。</font>

> [!tip]
>
> MVCC在MySQL InnoDB中的实现主要是为了提高数据库并发性能，用更好的方式去处理读-写冲突，做到即使有读写冲突时，也能做到不加锁，非阻塞并发读。
>
> MVCC针对的读-写冲突，并没有对写-写冲突做处理，因此避免了脏读、幻读、不可重复读等问题，但没有解决更新丢失。



##### 当前读和快照读

- **当前读**

像select lock in share mode(共享锁)、select for update 、 update、 insert 、delete(排他锁)这些操作都是一种当前读。

就是它读取的是记录的最新版本，读取时还要保证其他并发事务不能修改当前记录，会对读取的记录进行加锁。

**当前读实际上是一种加锁的操作，是悲观锁的实现**

- **快照读**

不加锁的select操作就是快照读，即不加锁的非阻塞读；

快照读的情况，是基于提高并发性能的考虑，快照读的实现是基于多版本并发控制，避免了加锁操作，降低了开销；既然是基于多版本，即快照读可能读到的并不一定是数据的最新版本，而有可能是之前的历史版本。

> [!ATTENTION]快照读的前提是隔离级别不是串行级别，串行级别下的快照读会退化成当前读；

##### 基本思想

MVCC 利用了多版本的思想，写操作更新最新的版本快照，而读操作去读旧版本快照，没有互斥关系。

在 MVCC 中事务的修改操作（DELETE、INSERT、UPDATE）会为数据行新增一个版本快照，用链式结构串联起来。

##### 隐式字段

每行记录除了我们自定义的字段外，还有数据库隐式定义的DB_TRX_ID,DB_ROLL_PTR,DB_ROW_ID等字段

- DB_ROW_ID： 6byte, 隐含的自增ID（隐藏主键），如果数据表没有主键，InnoDB会自动以DB_ROW_ID产生一个聚簇索引
- <font color=red>DB_TRX_ID ：6byte, 最近修改(修改/插入)事务ID：记录创建这条记录/最后一次修改该记录的事务ID</font>
- DB_ROLL_PTR ：7byte, 回滚指针，指向这条记录的上一个版本（存储于rollback segment里）
- DELETED_BIT： 1byte, 记录被更新或删除并不代表真的删除，而是删除flag变了

![image-20230827231135555](%E4%BA%8B%E5%8A%A1.assets/image-20230827231135555.png)

##### ReadView

Read View就是事务进行快照读操作的时候生产的读视图(Read View)，在该事务执行的快照读的那一刻，会生成数据库系统当前的一个快照，记录并维护系统当前活跃事务的ID。

当每个事务开启时，都会被分配一个ID, 这个ID是递增的，所以最新的事务，ID值越大。

**ReadView作用**

Read View主要是用来做可见性判断的，即当我们某个事务执行快照读的时候，对该记录创建一个Read View读视图，把它比作条件用来判断当前事务能够看到哪个版本的数据，即可能是当前最新的数据，也有可能是该行记录的undo log里面的某个版本的数据。

**可见性算法**

ReadView 结构，主要包含了当前系统未提交的事务列表 TRX_IDs {TRX_ID_1, TRX_ID_2, ...}，这个列表记录的就是当前其他活跃事务ID，该列表的最小值 TRX_ID_MIN【记录列表中事务ID最小的ID】 和 TRX_ID_MAX【记录列表中下一个事务ID，也就是目前已出现过的事务ID的最大值+1】。

![image-20230827230824612](%E4%BA%8B%E5%8A%A1.assets/image-20230827230824612.png)

在进行 SELECT 操作时，根据数据行快照的 DB_TRX_ID【记录中的隐式字段】 与 TRX_ID_MIN 和 TRX_ID_MAX 之间的关系，从而判断数据行快照是否可以使用：

- TRX_ID < TRX_ID_MIN，表示该数据行快照时在当前所有未提交事务之前进行更改的，因此可以使用。
- TRX_ID > TRX_ID_MAX，表示该数据行快照是在事务启动之后被更改的，因此不可使用。
- TRX_ID_MIN <= TRX_ID <= TRX_ID_MAX，再进行判断：
  - 如果 TRX_ID 在 TRX_IDs 列表中，表示该数据行快照对应的事务，在快照时还处于活跃状态，还未提交，则该快照不可使用。
  - TRX_ID不在TRX_IDs列表中，表示该数据行快照对应的事务，在快照时已经提交了，可以使用。

> 因为事务是并发开启和提交的，存在某个事务开启时间早、提交时间晚，中间已经有很多事务提交完成了，即TRX_ID_MIN和TRX_ID_MAX之间有已经提交完成的事务，所以需要三步校验。

在数据行快照不可使用的情况下，需要沿着 Undo Log 的回滚指针 ROLL_PTR 找到下一个快照，再进行上面的判断。

##### 实现流程

MVCC的实现流程主要是依赖记录中的 **4个隐式字段**，**undo日志** ，**Read View** 来实现的。

![image-20230827232513616](%E4%BA%8B%E5%8A%A1.assets/image-20230827232513616.png)

**模拟流程**

事务2对某行数据执行了快照读，数据库为该行数据生成一个Read View读视图。

假设当前事务ID为2，此时还有事务1和事务3在活跃中，事务4在事务2快照读前一刻提交更新了，所以Read View记录了系统当前活跃事务1、3的ID，维护在一个trx_list[1,3]的列表，TRX_ID_MIN =1；TRX_ID_MAX=4 + 1 = 5。

| 事务1    | 事务2    | 事务3    | 事务4        |
| -------- | -------- | -------- | ------------ |
| 事务开始 | 事务开始 | 事务开始 | 事务开始     |
| …        | …        | …        | 修改且已提交 |
| 进行中   | 快照读   | 进行中   |              |
| …        | …        | …        |              |

在例子中，只有事务4修改过该行记录，并在事务2执行快照读前，就提交了事务，所以当前该行当前数据的undo log为：

![img](%E4%BA%8B%E5%8A%A1.assets/db-mysql-mvcc-7.png)

1. 记录DB_TRX_ID字段记录的事务ID 4去跟Read View的的TRX_ID_MIN比较，看4是否小于TRX_ID_MIN (1)，所以不符合条件
2. 继续判断 4 是否大于等于 TRX_ID_MAX(5)，也不符合条件
3. 最后判断4是否处于trx_list[1,3]中的活跃事务, 最后发现事务ID为4的事务不在当前活跃事务列表中, 符合可见性条件

所以事务4修改后提交的最新结果对事务2快照读时是可见的，所以事务2能读到的最新数据记录是事务4所提交的版本，而事务4提交的版本也是全局角度上最新的版本。

##### 如何解决脏读和不可重复读

回顾一下，脏读和不可重复读是什么

脏读读取的是其他事务**还未提交**的数据，不可重复读读取的是其他数据**提交之后**的数据。

<font color=red>MVCC中Read View生成时机的不同，从而造成RC,RR级别下快照读的结果的不同。</font>

- **RC-解决脏读**

**在RC隔离级别下，每次快照读都会生成一个新的快照和Read View，同一个事务多次读取创建了不同的快照读，因此在RC级别下的事务中可以看到别的事务提交的更新**

比如说事务 A 用来查询，事务 B 用来更新，它俩都开启了事务，也都还没有提交，对应的事务 id 分别为 51 和 59：

1. 第一次A查询的Readview活动列表[51,59]，看不到事务B的修改
2. B提交事务后，事务59结束
3. A重新查询生成了一个ReadView，活动列表[51]，事务B不在活动列表中，可看到B的修改更新。

- **RR-解决不可重复读**

**在RR隔离级别下，则是同一个事务中的第一个快照读才会创建Read View, 之后的快照读获取的都是同一个Read View**

在RR级别下的某个事务的对某条记录的第一次快照读会创建一个快照及Read View, 将当前系统活跃的其他事务记录起来，此后在调用快照读的时候，还是使用的是同一个Read View，所以只要当前事务在其他事务提交更新之前使用过快照读，那么之后的快照读使用的都是同一个Read View，所以对之后的修改不可见。

##### RR级别和幻读

可重复读RR级别下，MVCC很大程度上解决了幻读现象：

比如 A 执行范围查询：select * from table where age > 10，查到了一条数据 X。然后事务 C 72 插入了一条数据，事务 A 再次查询时，可以查到两条数据 X 和 Y。但是 Y 的版本链上事务 id 等于 72，大于最大事务 id 60，说明是事务 A 发起查询后，当然是不可读到的了，所以事务 A 还是只能读到数据 X。

**但，没有完全解决！**

- 情况1：事务中更新了别的事务新插入的数据

以这张表作为例子：

![img](%E4%BA%8B%E5%8A%A1.assets/7f9df142b3594daeaaca495abb7133f5-20230309222119359.png)

事务 A 执行查询 id = 5 的记录，此时表中是没有该记录的，所以查询不出来。

```sql
# 事务 A
mysql> begin;
Query OK, 0 rows affected (0.00 sec)

mysql> select * from t_stu where id = 5;
Empty set (0.01 sec)
```

然后事务 B 插入一条 id = 5 的记录，并且提交了事务。

```sql
# 事务 B
mysql> begin;
Query OK, 0 rows affected (0.00 sec)

mysql> insert into t_stu values(5, '小美', 18);
Query OK, 1 row affected (0.00 sec)

mysql> commit;
Query OK, 0 rows affected (0.00 sec)
```

此时，**<font color=red>事务 A 更新 id = 5 这条记录，对没错，事务 A 看不到 id = 5 这条记录，但是他去更新了这条记录，这场景确实很违和，在这个时刻，这条新记录的 trx_id 隐藏列的值就变成了事务 A 的事务 id，之后事务 A 再使用普通 select 语句去查询这条记录时就可以看到这条记录了，于是就发生了幻读。</font>**

> 更新是完全OK的，因为MVCC做的只是读操作上的版本控制，对其他操作是没有限制的。

```sql
# 事务 A
mysql> update t_stu set name = '小林coding' where id = 5;
Query OK, 1 row affected (0.01 sec)
Rows matched: 1  Changed: 1  Warnings: 0

mysql> select * from t_stu where id = 5;
+----+--------------+------+
| id | name         | age  |
+----+--------------+------+
|  5 | 小林coding   |   18 |
+----+--------------+------+
1 row in set (0.00 sec)
```

整个发生幻读的时序图如下：

![img](%E4%BA%8B%E5%8A%A1.assets/%E5%B9%BB%E8%AF%BB%E5%8F%91%E7%94%9F.drawio.png)

- 事务中执行了“for update“当前读语句

T1 时刻：事务 A 先执行「快照读语句」：select * from t_test where id > 100 得到了 3 条记录。

T2 时刻：事务 B 往插入一个 id= 200 的记录并提交；

T3 时刻：事务 A 再执行「当前读语句」 select * from t_test where id > 100 for update 就会得到 4 条记录，此时也发生了幻读现象。

> **要避免这类特殊场景下发生幻读的现象的话，就是尽量在开启事务之后，马上执行 select ... for update 这类当前读的语句**，因为它会对记录加 next-key lock，从而避免其他事务插入一条新记录。

**结论：MySQL Innodb 中的 MVCC 并不能完全避免幻读现象**。

##### 总结 

MVCC是不满意只让数据库采用悲观锁这样性能不佳的形式去解决读-写冲突问题，而提出的解决方案，所以在数据库中，因为有了MVCC，所以可以形成两个组合：

- **MVCC + 悲观锁**： MVCC解决读-写冲突，悲观锁解决写-写冲突
- **MVCC + 乐观锁** ：MVCC解决读-写冲突，乐观锁解决写-写冲突

这种组合的方式就可以最大程度的提高数据库并发性能，并解决读写冲突，和写写冲突导致的问题。

> [!tip]注意MVCC和锁的关系
>
> MVCC是针对快照读的操作，加锁是针对当前读和写的操作。
>
> 上面说过”可以使用MVCC+next-key lock“的组合解决幻读，这个组合的逻辑关系是因为InnoDB MVCC和加锁的特性，选取的一个方案，是需要在事务中自己实现的，而非InnoDB自己自带的。
>
> 也就是说，InnoDB中的RR就是存在幻读的，只不过可以通过业务人员注意事务内的逻辑而解决这个问题。

**RR隔离级别下，针对快照读操作采用的策略是MVCC，解决了读写冲突中的脏读和不可重复读，解决了部分幻读，无法解决丢失更新问题**

#### 锁

##### 全局锁

要使用全局锁，则要执行这条命令：

```sql
flush tables with read lock
```

执行后，**整个数据库就处于只读状态了**，这时其他线程执行以下操作，都会被阻塞：

- 对数据的增删改操作，比如 insert、delete、update等语句；
- 对表结构的更改操作，比如 alter table、drop table 等语句。

如果要释放全局锁，则要执行这条命令：

```sql
unlock tables
```

当然，当会话断开了，全局锁会被自动释放。

**1 全局锁应用场景**

全局锁主要应用于做**全库逻辑备份**，这样在备份数据库期间，不会因为数据或表结构的更新，而出现备份文件的数据与预期的不一样。

> 在全库逻辑备份期间，假设不加全局锁的场景，看看会出现什么意外的情况。
>
> 如果在全库逻辑备份期间，有用户购买了一件商品，一般购买商品的业务逻辑是会涉及到多张数据库表的更新，比如在用户表更新该用户的余额，然后在商品表更新被购买的商品的库存。
>
> 那么，有可能出现这样的顺序：
>
> 1. 先备份了用户表的数据；
> 2. 然后有用户发起了购买商品的操作；
> 3. 接着再备份商品表的数据。
>
> 也就是在备份用户表和商品表之间，有用户购买了商品。
>
> 这种情况下，备份的结果是用户表中该用户的余额并没有扣除，反而商品表中该商品的库存被减少了，如果后面用这个备份文件恢复数据库数据的话，用户钱没少，而库存少了，等于用户白嫖了一件商品。
>
> 所以，在全库逻辑备份期间，加上全局锁，就不会出现上面这种情况了。

**2 全局锁的缺点**

加上全局锁，意味着整个数据库都是只读状态。

那么如果数据库里有很多数据，备份就会花费很多的时间，关键是备份期间，业务只能读数据，而不能更新数据，这样会造成业务停滞。

**3 既然备份数据库数据的时候，使用全局锁会影响业务，那有什么其他方式可以避免**

如果数据库的引擎支持的事务支持**可重复读的隔离级别**，那么在备份数据库之前先开启事务，会先创建 Read View，然后整个事务执行期间都在用这个 Read View，而且由于 MVCC 的支持，备份期间业务依然可以对数据进行更新操作。

> 因为在可重复读的隔离级别下，即使其他事务更新了表的数据，也不会影响备份数据库时的 Read View，这就是事务四大特性中的隔离性，这样备份期间备份的数据一直是在开启事务时的数据。
>
> 备份数据库的工具是 mysqldump，在使用 mysqldump 时加上 `–single-transaction` 参数的时候，就会在备份数据库之前先开启事务。这种方法只适用于支持「可重复读隔离级别的事务」的存储引擎。

InnoDB 存储引擎默认的事务隔离级别正是可重复读，因此可以采用这种方式来备份数据库。

但是，对于 MyISAM 这种不支持事务的引擎，在备份数据库时只能使用全局锁的方法。

##### 表锁

MySQL 里面表级别的锁有这几种：

- 表锁；
- 元数据锁（MDL）;
- 意向锁；
- AUTO-INC 锁

###### 表锁

对学生表（t_student）加表锁，可以使用下面的命令：

```sql
//表级别的共享锁，也就是读锁；
lock tables t_student read;

//表级别的独占锁，也就是写锁；
lock tables t_stuent write;
```

需要注意的是，表锁除了会限制别的线程的读写外，也会限制本线程接下来的读写操作。

也就是说如果本线程对学生表加了「共享表锁」，那么本线程接下来如果要对学生表执行写操作的语句，是会被阻塞的，当然其他线程对学生表进行写操作时也会被阻塞，直到锁被释放。

要释放表锁，可以使用下面这条命令，会释放当前会话的所有表锁：

```sql
unlock tables
```

另外，当会话退出后，也会释放所有表锁。

不过尽量避免在使用 InnoDB 引擎的表使用表锁，因为表锁的颗粒度太大，会影响并发性能，**InnoDB 牛逼的地方在于实现了颗粒度更细的行级锁**

###### 元数据锁(MDL)

元数据锁是为了保证当用户对表执行 CRUD 操作时，防止其他线程对这个表结构做了变更。

- **元数据锁调用**

元数据锁不需要显式调用，对数据库表进行操作时，会自动给这个表加上 MDL：

- 对一张表进行 CRUD 操作时，加的是 **MDL 读锁**；
- 对一张表做结构变更操作的时候，加的是 **MDL 写锁**；

当有线程在执行 select 语句（ 加 MDL 读锁）的期间，如果有其他线程要更改该表的结构（ 申请 MDL 写锁），那么将会被阻塞，直到执行完 select 语句（ 释放 MDL 读锁）。

反之，当有线程对表结构进行变更（ 加 MDL 写锁）的期间，如果有其他线程执行了 CRUD 操作（ 申请 MDL 读锁），那么就会被阻塞，直到表结构变更完成（ 释放 MDL 写锁）。

- **元数据锁释放**

MDL 是在事务提交后才会释放，这意味着**事务执行期间，MDL 是一直持有的**。

那如果数据库有一个长事务（所谓的长事务，就是开启了事务，但是一直还没提交），那在对表结构做变更操作的时候，可能会发生意想不到的事情，比如下面这个顺序的场景：

1. 首先，线程 A 先启用了事务（但是一直不提交），然后执行一条 select 语句，此时就先对该表加上 MDL 读锁；
2. 然后，线程 B 也执行了同样的 select 语句，此时并不会阻塞，因为「读读」并不冲突；
3. 接着，线程 C 修改了表字段，此时由于线程 A 的事务并没有提交，也就是 MDL 读锁还在占用着，这时线程 C 就无法申请到 MDL 写锁，就会被阻塞，

那么在线程 C 阻塞后，后续有对该表的 select 语句，就都会被阻塞，如果此时有大量该表的 select 语句的请求到来，就会有大量的线程被阻塞住，这时数据库的线程很快就会爆满了。

> 线程 C 因为申请不到 MDL 写锁，而导致后续的申请读锁的查询操作也会被阻塞。
>
> 这是因为申请 MDL 锁的操作会形成一个队列，队列中**写锁获取优先级高于读锁**，一旦出现 MDL 写锁等待，会阻塞后续该表的所有 CRUD 操作。
>
> 所以为了能安全的对表结构进行变更，在对表结构变更前，先要看看数据库中的长事务，是否有事务已经对表加上了 MDL 读锁，如果可以考虑 kill 掉这个长事务，然后再做表结构的变更。



###### 意向锁⚠️⚠️

对于MyISAM存储引擎都是表锁设计，InnoDB引擎中对锁做了细粒度设计。

**<font color=red>意向锁的目的是为了快速判断表里是否有记录被加锁</font>**

当 事务要对一行数据上锁时，需要先对这个表单上意向锁，再去具体的一行数据上上锁

- 在使用 InnoDB 引擎的表里对某些记录加上「共享锁」之前，需要先在表级别加上一个「意向共享锁」；
- 在使用 InnoDB 引擎的表里对某些纪录加上「独占锁」之前，需要先在表级别加上一个「意向独占锁」；

意向锁只会阻塞扫描全表的的请求

> 当前有一个事务对某一行数据读写，为表上了意向锁，有另外一个事务要对全表做一个update
>
> 如果没有意向锁，则需要扫描全表所有行来看有没有事务占据了行锁，十分占据资源
>
> 现在有了意向锁，如果发现当前表有意向锁，则全表的操作则会阻塞（这也是为什么要有意向锁）
>
> 而意向锁之间是没有冲突的，具体的冲突是两个事务获取同一行，加行锁的时候冲突；行锁上，只有共享锁和共享锁可以兼容，其他都会冲突

| 锁类型  | 说明                                   |
| ------- | -------------------------------------- |
| S Lock  | 行锁，共享锁，允许读取一行数据         |
| X Lock  | 行锁，排它锁，允许删除修改一行数据     |
| IS LOCK | 表锁，意向共享锁，允许获取几行数据     |
| IX LOCK | 表锁，意向排它锁，允许删除修改几行数据 |

**1 读写锁**

- 互斥锁（Exclusive），简写为 X 锁，又称写锁。
- 共享锁（Shared），简写为 S 锁，又称读锁。

有以下两个规定：

- 一个事务对数据对象 A 加了 X 锁，就可以对 A 进行读取和更新。加锁期间其它事务不能对 A 加任何锁。
- 一个事务对数据对象 A 加了 S 锁，可以对 A 进行读取操作，但是不能进行更新操作。加锁期间其它事务能对 A 加 S 锁，但是不能加 X 锁。

**2 意向锁**

使用意向锁（Intention Locks）可以更容易地支持多粒度封锁。

在存在行级锁和表级锁的情况下，事务 T 想要对表 A 加 X 锁，就需要先检测是否有其它事务对表 A 或者表 A 中的任意一行加了锁，那么就需要对表 A 的每一行都检测一次，这是非常耗时的。

意向锁在原来的 X/S 锁之上引入了 IX/IS，IX/IS 都是表锁，用来表示一个事务想要在表中的某个数据行上加 X 锁或 S 锁。有以下两个规定：

- 一个事务在获得某个数据行对象的 S 锁之前，必须先获得表的 IS 锁或者更强的锁；
- 一个事务在获得某个数据行对象的 X 锁之前，必须先获得表的 IX 锁。

通过引入意向锁，事务 T 想要对表 A 加 X 锁，只需要先检测是否有其它事务对表 A 加了 X/IX/S/IS 锁，如果加了就表示有其它事务正在使用这个表或者表中某一行的锁，因此事务 T 加 X 锁失败。

**3 锁之间的兼容关系**

![image-20230827144035358](%E4%BA%8B%E5%8A%A1.assets/image-20230827144035358.png)

- 任意 IS/IX 锁之间都是兼容的，因为它们只表示想要对表加锁，而不是真正加锁；
- 这里兼容关系针对的是表级锁，而表级的 IX 锁和行级的 X 锁兼容，两个事务可以对两个数据行加 X 锁。（事务 T1 想要对数据行 R1 加 X 锁，事务 T2 想要对同一个表的数据行 R2 加 X 锁，两个事务都需要对该表加 IX 锁，但是 IX 锁是兼容的，并且 IX 锁与行级的 X 锁也是兼容的，因此两个事务都能加锁成功，对同一个表中的两个数据行做修改。）

###### AUTO-INC 锁

表里的主键通常都会设置成自增的，这是通过对主键字段声明 `AUTO_INCREMENT` 属性实现的。

之后可以在插入数据时，可以不指定主键的值，数据库会自动给主键赋值递增的值，这主要是通过 **AUTO-INC 锁**实现的。

AUTO-INC 锁是特殊的表锁机制，锁**不是再一个事务提交后才释放，而是再执行完插入语句后就会立即释放**。

**在插入数据时，会加一个表级别的 AUTO-INC 锁**，然后为被 `AUTO_INCREMENT` 修饰的字段赋值递增的值，等插入语句执行完成后，才会把 AUTO-INC 锁释放掉。

那么，一个事务在持有 AUTO-INC 锁的过程中，其他事务的如果要向该表插入语句都会被阻塞，从而保证插入数据时，被 `AUTO_INCREMENT` 修饰的字段的值是连续递增的。

但是， AUTO-INC 锁再对大量数据进行插入的时候，会影响插入性能，因为另一个事务中的插入会被阻塞。

因此， 在 MySQL 5.1.22 版本开始，InnoDB 存储引擎提供了一种**轻量级的锁**来实现自增。

一样也是在插入数据的时候，会为被 `AUTO_INCREMENT` 修饰的字段加上轻量级锁，**然后给该字段赋值一个自增的值，就把这个轻量级锁释放了，而不需要等待整个插入语句执行完后才释放锁**。

InnoDB 存储引擎提供了个 innodb_autoinc_lock_mode 的系统变量，是用来控制选择用 AUTO-INC 锁，还是轻量级的锁。

- 当 innodb_autoinc_lock_mode = 0，就采用 AUTO-INC 锁，语句执行结束后才释放锁；
- 当 innodb_autoinc_lock_mode = 2，就采用轻量级锁，申请自增主键后就释放锁，并不需要等语句执行后才释放。
- 当 innodb_autoinc_lock_mode = 1：
  - 普通 insert 语句，自增锁在申请之后就马上释放；
  - 类似 insert … select 这样的批量插入数据的语句，自增锁还是要等语句结束后才被释放；

当 innodb_autoinc_lock_mode = 2 是性能最高的方式，但是当搭配 binlog 的日志格式是 statement 一起使用的时候，在「主从复制的场景」中会发生**数据不一致的问题**。

举个例子，考虑下面场景：

![img](%E4%BA%8B%E5%8A%A1.assets/innodb_autoinc_lock_mode=2.png)

session A 往表 t 中插入了 4 行数据，然后创建了一个相同结构的表 t2，然后**两个 session 同时执行向表 t2 中插入数据**。

如果 innodb_autoinc_lock_mode = 2，意味着「申请自增主键后就释放锁，不必等插入语句执行完」。那么就可能出现这样的情况：

- session B 先插入了两个记录，(1,1,1)、(2,2,2)；
- 然后，session A 来申请自增 id 得到 id=3，插入了（3,5,5)；
- 之后，session B 继续执行，插入两条记录 (4,3,3)、 (5,4,4)。

可以看到，**session B 的 insert 语句，生成的 id 不连续**。

当「主库」发生了这种情况，binlog 面对 t2 表的更新只会记录这两个 session 的 insert 语句，如果 binlog_format=statement，记录的语句就是原始语句。记录的顺序要么先记 session A 的 insert 语句，要么先记 session B 的 insert 语句。

但不论是哪一种，这个 binlog 拿去「从库」执行，这时从库是按「顺序」执行语句的，只有当执行完一条 SQL 语句后，才会执行下一条 SQL。因此，在**从库上「不会」发生像主库那样两个 session 「同时」执行向表 t2 中插入数据的场景。所以，在备库上执行了 session B 的 insert 语句，生成的结果里面，id 都是连续的。这时，主从库就发生了数据不一致**。

要解决这问题，binlog 日志格式要设置为 row，这样在 binlog 里面记录的是主库分配的自增值，到备库执行的时候，主库的自增值是什么，从库的自增值就是什么。

所以，**当 innodb_autoinc_lock_mode = 2 时，并且 binlog_format = row，既能提升并发性，又不会出现数据一致性问题**。

##### 行锁

###### 记录锁 Record Lock

锁定一个记录上的索引，而不是记录本身。

如果表没有设置索引，InnoDB 会自动在主键上创建隐藏的聚簇索引，因此 Record Locks 依然可以使用。

###### 间隙锁 Gap Lock

锁定索引之间的间隙，但是不包含索引本身。

例如当一个事务执行以下语句，其它事务就不能在 t.c 中插入 15：

```sql
SELECT c FROM t WHERE c BETWEEN 10 and 20 FOR UPDATE;
```

###### 临建锁 next-key lock

Next-Key Locks 是 MySQL 的 InnoDB 存储引擎的一种锁实现。

MVCC 不能解决幻读问题，Next-Key Locks 就是为了解决这个问题而存在的。在可重复读（REPEATABLE READ）隔离级别下，使用 MVCC + Next-Key Locks 可以解决幻读问题。

它是 Record Locks 和 Gap Locks 的结合，不仅锁定一个记录上的索引，也锁定索引之间的间隙。

它锁定一个**前开后闭**区间。

例如一个索引包含以下值：10, 11, 13, and 20，那么就需要锁定以下区间：

```
(-∞, 10]
(10, 11]
(11, 13]
(13, 20]
(20, +∞)
```

##### 不同SQL下的加锁

`SELECT ... FROM` ：一致性读，读取的是数据的快照（RR是读取事务开始的快照，而RC则是读取最新的快照）。

`SELECT ... LOCK IN SHARE MODE`：在任何行上设置共享锁。其他事务可以读取这些行，但在事务提交之前不能修改它。

`SELECT ... FOR UPDATE`：在任何行上设置排它锁。其他事务进不能加读锁（LOCK IN SHARE MODE）也不能加写锁（FOR UPDATE）。

`UPDATE ... WHERE ...`：在每条搜索记录上设置一个独占的 next-key lock。但是，对于使用唯一索引锁定行以搜索唯一行的语句，只需索引记录锁定。

`DELETE FROM ... WHERE ...` ：在每条搜索记录上设置一个独占的 next-key lock。但是，对于使用唯一索引锁定行以搜索唯一行的语句，只需索引记录锁定。

`INSERT`：在插入的行上设置排他锁。这个锁是索引记录锁，而不是 next-key lock(也就是说，没有间隙锁) ，并且不会阻止其他事务插入到插入的行之前的间隙中。

##### 隔离级别和加锁策略

注意的是，加锁针对的是当前读和写操作。

在读已提交隔离级别下，行级锁的种类只有记录锁，也就是仅仅把一条记录锁上。

在可重复读隔离级别下，行级锁的种类除了有记录锁，还有间隙锁（目的是为了避免幻读）

可串行读下，普通select语句加共享锁。

###### 读未提交

**在「读未提交」隔离级别下，读写操作可以同时进行，但写写操作无法同时进行。与此同时，该隔离级别下只会使用行级别的记录锁，并不会用间隙锁**

###### 读已提交

**在「读已提交」隔离级别下，只会使用行级别的记录锁，并不会用间隙锁**

###### 可重复读

**在「可重复读」隔离级别下，使用了记录锁、间隙锁、Next-Key 锁三种类型的锁。**

<font color=red>加锁的对象是索引，加锁的基本单位是 next-key lock</font>

但是，在能使用记录锁或者间隙锁就能避免幻读现象的场景下， next-key lock 就会退化成记录锁或间隙锁，具体根据场景而定。

**❗️❗️加锁场景规则**

1. 用唯一索引进行等值查询的时候，查询的记录存不存在，加锁的规则也会不同：
   1. 查询的记录是「存在」的，在索引树上定位到这一条记录后，将该记录的索引中的 next-key lock 会**退化成「记录锁」**
   2. 当查询的记录是「不存在」的，在索引树找到第一条大于该查询记录的记录后，将该记录的索引中的 next-key lock 会**退化成「间隙锁」**
2. 当唯一索引进行范围查询时，会对每一个扫描到的索引加 next-key 锁，然后如果遇到下面这些情况，会退化成记录锁或者间隙锁：
   1. 针对「大于等于」的范围查询，因为存在等值查询的条件，那么如果等值查询的记录是存在于表中，那么该记录的索引中的 next-key 锁会**退化成记录锁**
   2. 针对「小于或者小于等于」的范围查询，要看条件值的记录是否存在于表中:
      - 当条件值的记录不在表中，那么不管是「小于」还是「小于等于」条件的范围查询，**扫描到终止范围查询的记录时，该记录的索引的 next-key 锁会退化成间隙锁**，其他扫描到的记录，都是在这些记录的索引上加 next-key 锁
      - 当条件值的记录在表中，如果是「小于」条件的范围查询，**扫描到终止范围查询的记录时，该记录的索引的 next-key 锁会退化成间隙锁**，其他扫描到的记录，都是在这些记录的索引上加 next-key 锁；如果「小于等于」条件的范围查询，扫描到终止范围查询的记录时，该记录的索引 next-key 锁不会退化成间隙锁。其他扫描到的记录，都是在这些记录的索引上加 next-key 锁
3. 非唯一索引等值查询时，查询的记录存不存在，加锁的规则也会不同：
   1. 查询的记录「存在」时，由于不是唯一索引，所以肯定存在索引值相同的记录，于是**非唯一索引等值查询的过程是一个扫描的过程，直到扫描到第一个不符合条件的二级索引记录就停止扫描，然后在扫描的过程中，对扫描到的二级索引记录加的是 next-key 锁，而对于第一个不符合条件的二级索引记录，该二级索引的 next-key 锁会退化成间隙锁。同时，在符合查询条件的记录的主键索引上加记录锁**
   2. 查询的记录「不存在」时，**扫描到第一条不符合条件的二级索引记录，该二级索引的 next-key 锁会退化成间隙锁。因为不存在满足查询条件的记录，所以不会对主键索引加锁**
4. 非唯一索引进行范围查询时，对二级索引记录加锁都是加 next-key 锁
5. 没有索引的查询，或者查询语句没有走索引查询，导致扫描是全表扫描。那么，每一条记录的索引上都会加 next-key 锁，这样就相当于锁住的全表，这时如果其他事务对该表进行增、删、改操作的时候，都会被阻塞。

> **在线上在执行 update、delete、select ... for update 等具有加锁性质的语句，一定要检查语句是否走了索引，如果是全表扫描的话，会对每一个索引加 next-key 锁，相当于把整个表锁住了**，是挺严重的问题

值得一提的是，前面说过：**可重复读存在幻读的问题，但实际上在 MySQL 中，因为其使用了间隙锁，所以在「可重复读」隔离级别下，可以通过加锁解决幻读问题。因此，MySQL 将「可重复读」作为了其默认的隔离级别。**

> [!note]MySQL中的可重复读是存在幻读问题的，但通过在事务逻辑中添加当前读操作【Gap锁】解决，因此在RR级别下只要合适的事务逻辑，其实是可以不存在幻读问题的，相当于变相低成本实现。

> [!tip]如果合适事务逻辑就可以避免幻读，为什么还要串行化呢？
>
> 是因为可重复读中，读到的数据可能是历史数据，是不及时的数据，不是数据库当前的数据！这在一些对于数据的时效特别敏感的业务中，就很可能出问题。

###### 串行化

读加共享锁，写加排他锁【写操作加锁机制同可重复读】，读写互斥。使用的悲观锁的理论，实现简单，数据更加安全，但是并发能力非常差。

#### 总结

按照InnoDB中的实现方式进行总结，因为InnoDB本身实现了MVCC的特性，和原始事务基础上会略有不同：

| 隔离级别                   | 解决的问题                                                   | 存在的问题                                                   | InnoDB实现方式                                               |
| -------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 读未提交                   |                                                              | 事务中的修改，即使没有提交，对其它事务也是可见的             | 普通读：不加锁，直接读取当前数据库<br>加锁读：加行锁<br>写操作：只有记录锁，锁住行 |
| 读已提交                   | 脏读：通过快照读，活跃事务的数据不能读取，解决了读取到其他事务**还未提交**的数据的问题 | 不可重复读：可以读取的是其他数据**提交之后**的数据           | 普通读：MVCC机制，每个读操作生成一个新的ReadVIEW<br>加锁读：加行锁<br>写操作：只有记录锁，锁住行 |
| 可重复读【默认的隔离级别】 | 不可重复读：在事务中一直读取的是一个快照，在期间其他事务提交的数据就不会被读取到了 | 幻读：在同一个事务中快照读和加锁读\更新操作混合使用的事务中会引发幻读现象。<br>但是可以通过在事务逻辑中人为开始加netx-key而解决幻读问题。<br>但是这种解决方案中，读到的数据是历史数据，不适合在一些对于数据的时效特别敏感的业务中。 | 普通读：MVCC机制，同一个事务中的第一个快照读才会创建Read View, 之后的快照读获取的都是同一个Read View<br>加锁读：加行锁<br>写操作：行锁、gap锁、next-key根据执行情况而定 |
| 串行化                     | 幻读：通过锁读写互斥，每行记录在修改时，是不能被其他事务读取的，从而保证串行，解决脏读问题 | 一致性无问题，但性能较低                                     | 读操作：所有读操作加行锁<br>写操作：加排他锁，行锁、gap锁、next-key根据执行情况而定<br>读写互斥 |

**行级锁的加锁规则如下[RR和串行化含义gap锁的级别]**

唯一索引等值查询：

- 当查询的记录是「存在」的，在索引树上定位到这一条记录后，将该记录的索引中的 next-key lock 会**退化成「记录锁」**。
- 当查询的记录是「不存在」的，在索引树找到第一条大于该查询记录的记录后，将该记录的索引中的 next-key lock 会**退化成「间隙锁」**。

非唯一索引等值查询：

- 当查询的记录「存在」时，由于不是唯一索引，所以肯定存在索引值相同的记录，于是非唯一索引等值查询的过程是一个扫描的过程，直到扫描到第一个不符合条件的二级索引记录就停止扫描，然后**在扫描的过程中，对扫描到的二级索引记录加的是 next-key 锁，而对于第一个不符合条件的二级索引记录，该二级索引的 next-key 锁会退化成间隙锁。同时，在符合查询条件的记录的主键索引上加记录锁**。
- 当查询的记录「不存在」时，**扫描到第一条不符合条件的二级索引记录，该二级索引的 next-key 锁会退化成间隙锁。因为不存在满足查询条件的记录，所以不会对主键索引加锁**。

没有索引的查询，或者查询语句没有走索引查询：

- 导致全表扫描，每一条记录的索引上都会加 next-key 锁，锁住全表。

  

其中，非唯一索引和主键索引的范围查询的加锁规则不同之处在于：

- 唯一索引在满足一些条件的时候，索引的 next-key lock 退化为间隙锁或者记录锁。
- 非唯一索引范围查询，索引的 next-key lock 不会退化为间隙锁和记录锁。