@autoHeader: 2.1.1.1.1.1

<p align="right">update time : {docsify-updated}</p>

## 基础篇

### MySQL中都有哪些数据类型？

分为五种大类型：

- 针对整型，TINYINT, SMALLINT, MEDIUMINT, INT, BIGINT 分别使用 8, 16, 24, 32, 64 位存储空间。
- 针对浮点数类型，FLOAT 和 DOUBLE 为浮点类型，DECIMAL 为高精度小数类型。
- 针对字符串，有CHAR 和 VARCHAR 两种类型，前者是定长的，后者是变长的。
- 针对日期类型，有datetime和timestamp类型。
- 针对大文件，有text和blob类型。

### BLOB和TEXT有什么区别？

BLOB 是一个二进制对象，可以容纳可变数量的数据。

TEXT 是一个不区分大小写的 BLOB。

BLOB 和 TEXT 类型之间的唯一区别在于对 BLOB 值进行排序和比较时，区分大小写，对 TEXT 值不区分大小写。

### Char和Varchar的区别？

- char 表示定长字符串，长度是固定的；vachar表示可变字符串，长度是变化的。
- 如果插入数据的长度小于 char 的固定长度时，则用空格填充；在varchar中，插入的数据多长就按照多长来存储。
- Varchar因为长度固定，所以存取速度要比 varchar 快；但varchar不会占据多余空间
-  char 最多能存放的字符个数为 255；varchar最多能存放的字符为2的16次方-1。

### DateTime和TimeStamp的区别？

两个数据类型都是存储时间的类型，均为 `YYYY-MM-DD HH:MM:SS`

两种的不同的在于：

- 日期范围不同。DATETIME 的日期范围是 `1000-01-01 00:00:00.000000` 到 `9999-12-31 23:59:59.999999`；TIMESTAMP 的时间范围是`1970-01-01 00:00:01.000000` UTC `到 ``2038-01-09 03:14:07.999999` UTC。
- 存储空间不同。DATETIME 的存储空间为 8 字节；TIMESTAMP 的存储空间为 4 字节。
- 时区不同。DATETIME 存储时间与时区无关；TIMESTAMP 存储时间与时区有关，显示的值也依赖于时区。
- 默认值不同。DATETIME 的默认值为 null；TIMESTAMP 的字段默认不为空(not null)，默认值为当前时间。

### 记录货币用什么字段类型比较好？

货币在数据库中 MySQL可以用 Decimal，高精度浮点小数。

之所以不使用 float 或者 double 的原因：因为 float 和 double 是以二进制存储的，有一定的误差；而DECIMAL 和 NUMERIC 值作为字符串存储，可以有效保存那些值的小数精度。

###表连接的方式有哪几种？

1. 内关联：查出两表关联字段等值的数据。从数学的角度讲就是求两个表的交集，从笛卡尔积的角度讲就是从笛卡尔积中挑出ON子句条件成立的记录。
2. 左关联：以左表为中心，查出左表的全部数据，关联字段值不相等则右表查出的数据显示为空；从笛卡尔积的角度讲，就是先从笛卡尔积中挑出ON子句条件成立的记录，然后加上左表中剩余的记录。
3. 右关联：以右表为中心，查出右表的全部数据，关联字段值不相等则左表查出的数据显示为空；从笛卡尔积的角度描述，右连接就是从笛卡尔积中挑出ON子句条件成立的记录，然后加上右表中剩余的记录。
4. 全外关联：产生A和B的并集。对于没有匹配的记录，则以null做为值。MySQL中没全外连接，用左外连接和右外连接在union(union连接的是两个查询不是两张表)起来。

### 表与表之间的连接方式和对性能的影响

在性能上的区别是：

**左右关联的方式比内关联方式更慢**。

第一个原因是，外连接多返回了一部分左表没有返回的数据。

第二个原因是MySQL中支持的是嵌套循环算法，外表中的每一条记录与内表中的记录进行判断，假设外表的记录数为R，内表的记录数位S，外表记录越少，性能越高，所以尽可能小表驱动大表。`inner join`在连接的时候，mysql会自动选择较小的表来作为驱动表，从而达到减少循环次数的目的。我们在使用`left join`表的时候，默认是使用左表作为驱动表，那么此时左表的大小是我们来控制的，如果控制不当，左表比较大，那么自然循环次数也会变多，效率会下降。

### 什么是SQL注入，如何防范？

SQL注入是通过把SQL命令插入到表单提交或页面请求的查询字符串中，最终到达服务器执行恶意的SQL命令。

防范：

1. 不要相信用户的输入，对用户输入进行校验
2. 不要动态拼接SQL，使用参数化的SQL进行数据查询
3. 敏感信息要单独加密存放
4. 为每个应用赋予单独的权限

### 存储过程和函数区别？

存储过程和函数都是存储在数据库中的SQL集合，可以被用户直接或者间接调用，本质上，存储过程和函数没有什么区别，只是在使用下有些区别：

1. 标志符不同，函数标志符为FUNCTION，存储过程标志符为PROCEDURE。
2. 两者返回值不同：函数必须有返回值，且只能有一个；存储过程可以无或者有多个返回值。
3. 两者调用方式不同：存储过程没有返回值类型，需要利用call函数调用作为一个独立部分执行，不能直接赋值给变量；函数有返回值类型，除了可以赋值给变量还可以直接在select子句中使用。
4. 总体来讲，存储过程的限制相对就比较少 ，可实现的功能复杂一些。

### 存储过程和触发器不同？

存储过程是为了完成特定功能的SQL语句集，经编译创建并保存在数据库中，用户可通过指定存储过程的名字并给定参数(需要时)来调用执行。

触发器trigger是与表事件相关的特殊的存储过程，它的执行是由事件来触发，比如当对一个表进行操作（insert，delete， update）时就会激活它执行。

两种的区别在于：

1. 存储过程是由用户或者应用程序显式调用的，触发器是由一个事件触发自动隐式运行
2. 存储过程可以接收返回参数，触发器不能接收参数

## 日志篇

### MySQL有哪些日志文件？

MySQL 日志文件有很多，包括 ：

- 错误日志，错误日志文件对 MySQL 的启动、运行、关闭过程进行了记录，能帮助定位 MySQL 问题。
- 慢查询日志：慢查询日志是用来记录执行时间超过query_time 这个变量定义的时长的查询语句。通过慢查询日志，可以查找出哪些查询语句的执行效率很低，以便进行优化。
- 一般查询日志：一般查询日志记录了所有对 MySQL 数据库请求的信息，无论请求是否正确执行。
- 二进制日志：关于二进制日志，它记录了数据库所有执行的语句（除了数据查询语句 select、show 等），以事件形式记录并保存在二进制文件中。

还有两个 InnoDB 存储引擎特有的日志文件：

- 重做日志：重做日志中记录的是在某个数据页上做了什么修改，当事务提交时，必须先将事务的所有日志写入日志文件，保证断电或宕机等情况发生后，已提交的事务不会丢失。
- 回滚日志：回滚日志的作用就是对数据进行回滚，用于记录数据被修改之前的日志，记录要回滚时需要的数据和信息，当事务发生回滚时，就读取 undo log 里的数据，做原先相反操作。

### binlog 和 redo log 有什么区别？

- 支持的引擎不同。bin log 会记录所有与数据库有关的日志记录，包括 InnoDB、MyISAM 等存储引擎的日志，而 redo log 只记 InnoDB 存储引擎的日志。
- 记录的内容不同。bin log 记录的是具体操作内容，是逻辑日志。而 redo log 记录的是关于每个页的物理情况。
- 写入的时间不同。bin log 仅在事务提交前进行提交，也就是只写磁盘一次。而redo log是在在事务进行的过程中，不断写入的。
- 写入的方式也不相同。redo log 是循环写入和擦除，bin log 是追加写入，不会覆盖已经写的文件。

## 事务篇

### 说一下事务？

事务就是一组原子性的SQL集合，或者说一个独立的工作单元，事务内的语句，要么全部执行成功，要么全部执行失败。

事务满足ACID四个特性：

- 原子性：事务被视为不可分割的最小单元，事务的所有操作要么全部提交成功，要么全部失败回滚。
- 隔离性：一个事务所做的修改在最终提交以前，对其它事务是不可见的。
- 持久性：一旦事务提交，则其所做的修改将会永远保存到数据库中。即使系统发生崩溃，事务执行的结果也不能丢失
- 一致性：事务开始之前和事务结束以后，数据一致性不会被破坏。

###  事务还没提交的时候，redo log 能不能被持久化到磁盘？

事务还没有提交的时候，redo log 是有可能被持久化到磁盘的。

redolog 的具体落盘操作是这样的：在事务运行的过程中，MySQL 会先把日志写到 redolog buffer 中，等到事务真正提交的时候，再统一把 redolog buffer 中的数据写到 redolog 文件中。不过这个从 redolog buffer 写到 redolog 文件中的操作也就是 write 并不就是落盘操作了，这里仅仅是把 redolog 写到了文件系统的 page cache 上，最后还需要执行 fsync 才能够实现真正的落盘。

也就是说，redolog 其实存在三种状态：

1. 事务执行过程中，存在 MySQL 的进程内存中的 redolog buffer 中
2. 事务提交，执行 write 操作存在文件系统的 page cache 中，但是没有执行 fsync 操作持久化到磁盘
3. 事务提交，执行 fsync 操作持久化到磁盘

relog的刷盘时机有三种情况：

第一种情况：InnoDB 有一个后台线程，每隔 1 秒轮询一次，具体的操作是这样的：调用 write 将 redolog buffer 中的日志写到文件系统的 page cache，然后调用 fsync 持久化到磁盘。而在事务执行中间过程的 redolog 都是直接写在 redolog buffer 中的，也就是说，一个没有提交的事务的 redolog，也是有可能会被后台线程一起持久化到磁盘的。

第二种情况：innodb_flush_log_at_trx_commit 设置是 1时，每次事务提交的时候，都执行 fsync 将 redolog 直接持久化到磁盘，假设事务 A 执行到一半，已经写了一些 redolog 到 redolog buffer 中，这时候有另外一个事务 B 提交，事务 B 要把 redolog buffer 里的日志全部持久化到磁盘，这时候，就会带上事务 A 在 redolog buffer 里的日志一起持久化到磁盘。

第三种情况：redo log buffer 占用的空间达到 redolo buffer 大小(由参数 innodb_log_buffer_size 控制，默认是 8MB)一半的时候，后台线程会主动写盘。不过由于这个事务并没有提交，所以这个写盘动作只是 write 到了文件系统的 page cache，仍然是在内存中，并没有调用 fsync ，此时并不会落盘。

### 说一下MVCC？

多版本并发控制（MVCC）是一种用来解决读-写冲突的并发控制，简单来说就是通过维护数据历史版本，从而解决并发访问情况下的读一致性问题。

在MySQL中，将读操作分为了两种，普通的select读操作叫做快照读，读取的都是快照数据；类似`select lock in share mode、select for update`等读操作成为当前读，需要加锁读取当前数据。而MVCC机制主要针对的就是快照读操作。

MVCC的原理分为几部分：

- 第一，为事务分配单向增长的事务id，在 InnoDB中每一行记录都有个隐藏列存储事务id，每次行记录被修改时则将修改该行的事务id赋值给隐藏字段。
- 第二，MVCC进行快照读操作时会创建一个读视图ReadView，在这个ReadView会记录本次快照生成时，有哪些活跃的事务id，把列表记录下来。
- 第三，通过比较某条记录存储的事务id和读视图中的活跃事务id列表，判读当前版本的快照是否可对当前事务可见，若不可见，则顺着版本链找到下一个版本的数据继续判断。如果最后一个版本也不可见的话，那么就意味着该条记录对该事务完全不可见，查询结果就不包含该记录。

在InnodDB中，通过MVCC实现了读已提交和可重复读两个隔离级别，他们非常大的区别就是它们生成 ReadView 的时机不同：

- 在读已提交隔离级别下，MVCC的机制是，每次快照读操作都会生成一个新的ReadView，同一个事务多次读取创建了不同的快照读，每次读取的快照版本不一致，引发的问题是在读已提交级别下的事务中可以看到别的事务提交的更新。
- 在可重复读隔离级别下，MVCC机制快照的创建时机为，同一个事务中的第一个快照读才会创建Read View, 之后的快照读获取的都是同一个快照，由此解决了不可重复读问题。

### 事务都有哪些隔离级别，都会产生什么问题？

事务的四个隔离级别：

- 读未提交：这是事务的最低级别，事务中的修改，即使没有提交，对其它事务也是可见的，产生脏读问题：当前事务可以读到另外事务未提交的数据。
- 读已提交：保证一个事务修改的数据提交后才能被另外一个事务读取，但会产生不可重复读问题，即在一个事务内多次读取同一数据集合。在这一事务还未结束前，另一事务也访问了该同一数据集合并做了修改，由于第二个事务的修改，第一次事务的两次读取的数据可能不一致。
- 可重复读：这是MySQL的默认事务隔离级别，它确保同一事务的多个实例在并发读取数据时，会看到同样的数据行。但会产生幻读问题：事务1读取某个范围的数据，事务2在这个范围内插入新的数据，事务1 再次读取这个范围的数据，此时读取的结果和和第一次读取的结果不同。
- 串行化：强制事务串行执行，这样多个事务互不干扰，不会出现并发一致性问题。这是花费最高代价但是最可靠的事务隔离级别，事务会被处理为顺序执行。

### InnoDB是怎么实现这些隔离级别的？

在InnoDB引擎中：

- 对于读未提交隔离级别，读操作不加锁，写操作加记录锁，读写操作可以同时进行，但写写操作无法同时进行。
- 对于不可重复读隔离级别，普通读操作采用MVCC，写操作加行记录锁，每次快照读操作都会生成一个新的ReadView，同一个事务多次读取创建了不同的快照读，每次读取的快照版本不一致，引发的问题是在读已提交级别下的事务中可以看到别的事务提交的更新。
- 对于可重复读隔离级别，普通读操作采用MVCC，但是同一个事务中的第一个快照读才会创建Read View, 之后的快照读获取的都是同一个快照，解决了不可重复读问题。对于写操作，加锁的对象是索引，加的锁是next-key lock，但在某些场景下next-key lock会退化成记录锁或者间隙锁。
- 对于串行化隔离级别，读加共享锁，写加排他锁，读写互斥。

### InnoDB是如何实现ACID的？

- 对于原子性，借助的是“undo log”回滚日日志。回滚日志主要用于记录数据被修改之前的日志，记录要回滚时需要的数据和信息，当事务发生回滚时，就读取 undo log 里的数据，做原先相反操作，例如：在更新一条记录时，要把被更新的列的旧值记下来，这样之后回滚时再把这些列更新为旧值
- 对于持久性，借助的是“redo log”重做日志，日志中记录的是在某个数据页上做了什么修改，当事务提交时，必须先将事务的所有日志写入日志文件，保证断电或宕机等情况发生后，已提交的事务不会丢失。
- 对于隔离性，MySQL中InnoDB引擎借助了MVCC多版本控制和锁机制实现多个隔离级别。
- 对于一致性，从数据库层面来看，可以认为原子性、持久性和隔离性都是为了实现事务的一致性，数据库必须要实现AID三大特性，才有可能实现一致性。

### 说说InnoDB中的锁？

MySQL中有多种类型的锁

如果按锁粒度划分，可以分为

- 全局锁：加全局锁之后，整个数据库处于只读状态，主要应用于做全库逻辑备份，这样在备份数据库期间，不会因为数据或表结构的更新，而出现备份文件的数据与预期的不一样。
- 表级别锁：在表粒度级别下，有表锁、元数据锁、意向锁。
  - 表锁除了会限制其他的事务的读写操作；
  - 元数据锁是为了保证当用户对表执行操作时，防止其他线程对这个表结构做了变更；
  - 对于意向锁，当事务要对一行数据上锁时，需要先对这个表单上意向锁，再去具体的一行数据上上锁，意向锁的目的是为了快速判断表里是否有记录被加锁，意向锁只会阻塞扫描全表的的请求；
- 行级别锁，在行粒度级别下，有记录锁、间隙锁、next-key临键锁：
  - 记录锁锁定一行记录上的索引，如果没有设置索引，InnoDB 会自动在主键上创建隐藏的聚簇索引
  - 间隙锁锁定索引之间的间隙
  - next-key锁是间隙锁和记录锁的组合，不仅锁定一个记录上的索引，也锁定索引之间的间隙，锁定一个前开后闭的区间

如果按照兼容性区分，有两种：

- 共享锁：也称为读锁，读锁和读锁之间相互不阻塞。
- 排他锁：也称为写锁，排它锁是阻塞的，在一定时间内，只有一个请求能执行写入，并阻止其它锁读取正在写入的数据。

### InnoDB中行锁的加锁规则？

在「读已提交」隔离级别下，只会使用行级别的记录锁，并不会用间隙锁。

在「可重复读」隔离级别下，默认下，加锁的对象是索引，加锁的基本单位是 next-key lock，但在能使用记录锁或者间隙锁就能避免幻读现象的场景下，next-key lock会退化成记录锁或者间隙锁，比如：

- 当唯一性等值查询时，查询的记录存在，由于是唯一性索引，不会插入相同值的记录了，只要锁定该行即可，则会退化成记录锁。
- 当唯一性等值查询时，查询的记录不存在，在索引树找到第一条大于该查询记录的记录，退化成间隙锁，这是由于右边界的记录已经存在，不可能再插入一条相同的记录，因此可以不锁定右边界。
- 当唯一性索引进行大于等于范围查询时，如果等值的记录存在，因为是大于等于查询，小于该值的记录不满足条件，没有必要锁定，那么该记录会退化成记录锁。
- 当唯一性索引进行小于等于范围查询时，如果条件值的记录不存在表中，那扫描到第一个不满足条件的记录，由于该记录已经不满足条件了，没有必要锁定这行，此时会退化成间隙锁。
- 当使用非唯一性索引进行等值查询时，扫描到的第一个不符合条件的记录，会退化成间隙锁。

等等，其基本思想就是放开没有必要锁住的行记录，能使用记录锁或者间隙锁就能满足的场景下进行退化。

### 乐观锁和悲观锁了解吗？

悲观锁认为被它保护的数据是极其不安全的，每时每刻都有可能被改动，一个事务拿到悲观锁后，其他任何事务都不能对该数据进行修改，只能等待锁被释放才可以执行。数据库中的行锁，表锁，读锁，写锁均为悲观锁。

乐观锁认为数据的变动不会太频繁，一个事务拿到乐观锁后，不会阻塞其他事务的操作，乐观锁通常是通过在表中增加一个版本或时间戳来实现：

- 事务在从数据库中取数据时，会将该数据的版本也取出来(v1)，当事务对数据变动完毕想要将其更新到表中时，会将之前取出的版本 v1 与数据中最新的版本 v2 相对比
- 如果 v1=v2，那么说明在数据变动期间，没有其他事务对数据进行修改，此时，就允许事务对表中的数据进行修改，并且修改时 version 会加 1，以此来表明数据已被变动。
- 如果，v1 不等于 v2，那么说明数据变动期间，数据被其他事务改动了，此时不允许数据更新到表中，一般的处理办法是通知用户让其重新操作

### 意向锁是什么知道吗？

意向锁是一个表级锁，当事务要对一行数据上锁时，需要先对这个表单上意向锁，再去具体的一行数据上上锁，意向锁的目的是为了快速判断表里是否有记录被加锁，意向锁只会阻塞扫描全表的的请求。

当我们需要给一个表加表锁的时候，我们需要根据去判断表中有没有数据行被锁定，以确定是否能加成功，假如没有意向锁，那么我们就得遍历表中所有数据行来判断有没有行锁；有了意向锁这个表级锁之后，则我们直接判断一次就知道表中是否有数据行被锁定了。

## 索引篇

### InnoDB中有哪些索引？

按照多个角度来分类索引:

- 按「物理存储」分类：
  - 聚簇索引（主键索引）:是一种对磁盘实际数据重新组织并排序的索引结构，它的索引指向实际的数据页面，规定了数据在表中的物理存储顺序。
  - 二级索引（辅助索引）：指定了表中数据的逻辑顺序，索引的叶子节点记录的是主键值。
- 按「字段特性」分类：
  - 主键索引：建立在主键字段上的索引。
  - 唯一索引：索引值必须唯一，可以允许有空值。
  - 普通索引：既不要求字段为主键，也不要求字段唯一。
  - 前缀索引：针对字符类型的字段，取前几个字符建立的索引。
- 按「字段个数」分类：
  - 单列索引：建立在单列上的索引称为单列索引，比如主键索引。
  - 联合索引：建立在多列上的索引称为联合索引。

### 为什么使用索引会加快查询？

传统的查询方法，是按照表的顺序遍历的，不论查询几条数据，MySQL 需要将表的数据从头到尾遍历一遍。

添加完索引之后，MySQL 会生成一个索引文件，在查询数据库时，找到索引文件进行遍历，在比较小的索引数据里查找，然后映射到对应的数据，能大幅提升查找的效率。

### 说下MySQL回表？

一般我们自己建的索引不管是单列索引还是联合索引，都是二类索引，索引B+ 树的节点仅仅包含了索引里的几个字段的值以及主键值。

根据索引树按照条件找到了需要的数据，仅仅是索引里的几个字段的值和主键值，还需要很多其他的字段，就得走一个回表操作，根据主键再到主键的聚簇索引里去找，聚簇索引的叶子节点是数据页，找到数据页里才能把一行数据的所有字段值提取出来。

### 覆盖索引是什么？

在辅助索引里面，不管是单列索引还是联合索引，如果 select 的数据列只用辅助索引中就能够取得，不用去查主键索引，这时候使用的索引就叫做覆盖索引，避免了回表。

### 什么是索引下推？

索引下推用于优化数据查询。

对于联合索引（a, b），在执行 `select * from table where a > 1 and b = 2` 语句的时候，只有 a 字段能用到索引，在没有索引下推的时候，联合索引找到满足索引条件的主键值，之后需要一个个回表查询，再判断其他条件是否满足。

MySQL引入的索引下推优化， 可以在联合索引遍历过程中，先对联合索引中包含的字段做判断，直接过滤掉不满足条件的记录，只有满足条件的才进行回表，减少回表次数。

当查询语句的执行计划里，出现了 Extra 为 `Using index condition`，那么说明使用了索引下推的优化。

### 创建索引应该注意什么？

索引虽然是 sql 性能优化的利器，但是索引的维护也是需要成本的，所以创建索引，也要注意：

1. 索引应该建在查询应用频繁的字段。在用于 where 判断字段上创建索引。
2. 索引的个数应该适量。索引需要占用空间，更新时候也需要维护。
3. 对于区分度低的字段不要建索引。例如性别，这种字段离散度太低，即便建立了索引扫描的行数依然很多。
4. 经常使用多个条件查询时更适合使用组合索引。
5. 建立组合索引时，要区值分度高的列放在前面。这样可以满足最左前缀匹配原则。
6. 频繁更新的值，不要作为主键或者索引。会导致维护索引的成本很高。
7. 针对比较长的字符类型的话，如果要建立索引，使用前缀索引。减少索引占用的存储空间，提升查询效率
8. 不建议对用无序的值建立索引。例如身份证、UUID，索引具有不确定性，会造成叶子节点频繁分裂。

### 索引失效的有哪些情况？

- 模糊匹配的时候，也就是 `like %xx` 或者 `like %xx%`这两种方式都会造成索引失效；
- 查询条件中对索引列使用函数，就会导致索引失效。
- 查询条件中对索引列进行表达式计算，也是无法走索引的。
- 如果列类型是字符串，那一定要在条件中将数据使用引号引用起来,否则会导致数据库向字符串的隐式强制转换，从而不使用索引。这是因为不加括号的话，会自动把字符串隐式转换转为数字，等同于对索引列使用了函数，导致索引失效。
- 联合索引要能正确使用需要遵循最左匹配原则，也就是按照最左优先的方式进行索引的匹配，否则就会导致索引失效。
- 在 WHERE 子句中，如果在 OR 前的条件列是索引列，而在 OR 后的条件列不是索引列，那么索引会失效。
- 对于多列复合索引，如果查询条件不是索引的第一部分，不会使用索引。

### 索引不适合哪些场景呢？

- 数据量比较少的表不适合加索引
- 更新比较频繁的字段也不适合加索引
- 离散低的字段不适合加索引（如性别）

### 索引是不是建的越多越好呢？

当然不是。

- 索引会占据磁盘空间
- 索引虽然会提高查询效率，但是会降低更新表的效率。比如每次对表进行增删改操作，MySQL 不仅要保存数据，还有保存或者更新对应的索引文件。

### InnoDB中索引用的什么数据结构？

默认采用的是 B+树结构的索引。

B+树的结构是：

- 只有叶子节点才会存储数据，非叶子节点只存储键值。
- 叶子节点之间使用双向指针连接，最底层的叶子节点形成了一个双向有序链表

B+树相对的优点：

- B+Tree 永远是在叶子节点拿到数据，所以 IO 次数是稳定的
- 因为叶子节点上有下一个数据区的指针，数据形成了链表，排序能力更强
- 在面临扫表时，只需要遍历叶子节点就可以 了，不需要遍历整棵 B+Tree 拿到所有的数据
- 和二叉树相比，每个父节点的儿子个数更多，所以相同数据下，B+树更低，一次数据查询操作经历的磁盘IO更少。
- 相比较B树，B+Tree 由于中间节点不存指针，同样大小的磁盘页可以容纳更多的节点元素，单一节点存储的元素更多，使得查询的IO次数更少。

### Hash 索引和 B+ 树索引区别是什么？

- B+ 树可以进行范围查询，Hash 索引不能。
- B+ 树支持联合索引的最左侧原则，Hash 索引不支持。
- B+ 树支持 order by 排序，Hash 索引不支持。
- Hash 索引在等值查询上比 B+ 树效率更高。
- B+ 树使用 like 进行模糊查询的时候，like 后面（比如 % 开头）的话可以起到优化的作用，Hash 索引根本无法进行模糊查询。

### 聚簇索引与非聚簇索引的区别？

- 一个表中只能拥有一个聚簇索引，而非聚簇索引一个表可以存在多个。
- 聚簇索引，索引中键值的逻辑顺序决定了表中相应行的物理顺序；而非聚集索引，索引中索引的逻辑顺序与磁盘上行的物理存储顺序不同。
- 聚簇索引的索引和数据存储在一棵树上，树的叶子节点就是数据，非聚簇索引索引和数据不在一棵树上，叶节点指向的是主键值。

### 什么是最左前缀原则？

在 InnoDB 的联合索引中，查询的时候只有匹配了前一个左边的值之后，才能匹配下一个。

如果不遵循「最左匹配原则」，联合索引会失效，这样就无法利用到索引快速查询的特性了。

## 调优篇

### JOIN表外连接优化？

1. left join选择小表作为驱动表（这部分基本是大家的共识）
2. 如果左表比较大，并且业务要求驱动表必须是左表，那么我们可以通过where条件语句，使得左表被过滤的小一些，主要原理和第一条类似
3. 关联字段给索引，因为在mysql的嵌套循环算法中，是通过关联字段进行关联，并查询的，所以给关联字段索引很必要
4. 如果sql里面有排序，请给排序字段加上索引，不然会造成排序使用全表扫描
5. 如果where条件中含有右表的非空条件（除开is null），则left join语句等同于join语句，可直接改写成join语句。 
6. 根据文档，MySQL能更高效地在声明具有相同类型和尺寸的列上使用索引。所以把表与表之间的关联字段给上encoding和collation（决定字符比较的规则）全部改成统一的类型
7. 右表的条件列一定要加上索引（主键、唯一索引、前缀索引等），最好能够使type达到range及以上（ref,eq_ref,const,system） 

### 如何对数据库进行优化？

数据库优化可以从多个方面入手：

- 在服务器端：
  - 可以选择用限流策略、分流策略负载均衡来提高并发量。
  - 利用缓存机制，使用缓存中间件，对经常频繁查询的结果建立缓存，减少磁盘IO操作次数。

- 在数据库架构方面：
  - 分库分表策略，把一个数据库切分成多个部分，放到不同的数据库上，从而缓解单一数据库的性能问题。
  - 使用读写分离策略，业务线大部分读写写少，用读写分离是用来解决数据库的读性能瓶颈。
  - 使用分区策略，当表中的数据量不断增大，查询数据的速度就会变慢，使用分区策略，逻辑上表仍然是一张完整的表，只是将表中的数据在物理上存放到多个物理文件上，这样查询数据时，可只查询对应分区的数据。
- 在表单结构方面：
  - 创建索引，对频繁查询的属性创建索引来优化查询速度。
  - 对表单结构进行优化，数据类型尽可能简单，数据长度尽可能小。
- 在SQL语句方面：
  - 减少请求的数据量，只返回必要的列。
  - 切分大查询，一个大查询如果一次性执行的话，可能一次锁住很多数据，将一个查询分解，多个小查询，然后在应用程序中进行关联；如果数据量很大，查询时可以考虑分页。
  - 如果有慢查询现象，使用慢查询日志功能，查询出比较慢的 SQL 语句，然后再通过 explain 来查询 SQL 语句的执行计划，定位优化对应的SQL。
- 在系统硬件方面，通过升级磁盘、网络、内存提高数据库性能。

### 说一下数据库读写分离？

读写分离的基本原理是将数据库读写操作分散到不同的节点上：

- 数据库主机负责读写操作，从机只负责读操作。
- 数据库主机通过复制将数据同步到从机，每台数据库服务器都存储了所有的业务数据。
- 业务服务器将写操作发给数据库主机，将读操作发给数据库从机。

### 读写分离分配是如何实现的？

将读写操作区分开来，然后访问不同的数据库服务器，一般有两种方式：程序代码封装和中间件封装：

- 程序代码封装，指在代码中抽象一个数据访问层，实现读写操作分离和数据库服务器连接的管理。
- 中间件封装，使用数据库中间件，比如Mysql-proxy，中间件对业务服务器提供 SQL 兼容的协议，业务服务器无须自己进行读写分离。对于业务服务器来说，访问中间件和访问数据库没有区别，事实上在业务服务器看来，中间件就是一个数据库服务器。

### 分表的策略有哪些？

分表有垂直切分和水平切分两种：

- 水平切分。当一个表中的数据量过大时，我们可以把该表的数据按照某种规则，进行划分，然后存储到多个结构相同的表，和不同的库上。
- 垂直切分。垂直切分是将一张表按列切分成多个表，通常是按照列的关系密集程度进行切分，也可以利用垂直切分将经常被使用的列和不经常被使用的列切分到不同的表中。

在业务中：

- 如果数据库是因为表太多而造成海量数据，并且项目的各项业务逻辑划分清晰、低耦合，则首选垂直切分；
- 而如果数据库中的表并不多，但单表的数据量很大、或数据热度很高，这种情况之下就应该选择水平切分。
- 如果这两种情况兼而有之，这就需要做出权衡，有时既需要垂直切分，又需要水平切分，比如先去数据库进行垂直切分，然后再针对一部分表，通常是用户表，进行水平切分。

### 水平分表有哪几种路由方式？

路由指的是数据应该分到哪一张表，水平分表主要有三种路由方式：

- 范围路由：选取有序的数据列 （例如，整形、时间戳等） 作为路由的条件，不同分段分散到不同的数据库表中。范围路由的优点是新增数据很方便，只需要增加新的表就可以了，原有的数据不需要动。而缺点是分布不均匀。
- 哈希路由：选取某个列或者某几个列组合的值进行 Hash 运算，然后根据 Hash 结果分散到不同的数据库表中。哈希路由的优点是分布比较均匀，但是扩充新的表很麻烦，所有数据都要重分布。
- 配置路由：配置路由就是路由表，用一张独立的表来记录路由信息。配置路由设计简单，使用起来非常灵活，尤其是在扩充表的时候，只需要迁移指定的数据，然后修改路由表就可以了。但是缺点是因为要查询一次路由表，所以次数多了一次，影响性能；而且路由表本身如果太大，路由表的性能可能会变成瓶颈。

### 分库分表会带来什么问题？

1. ID问题，因为将数据切分到了不同的表和库中，MySQL 本身的自增 id 就不能保证唯一性了，这时候需要其他方案来保证，比如还是自增，只不过自增步长设置一下。比如现在有三张表，步长设置为 3，三张表 ID 初始值分别是 1、2、3。这样第一张表的 ID 增长是 1、4、7。第二张表是 2、5、8。第三张表是 3、6、9，这样就不会重复了。或者是UUID、雪花算法等分布式ID。
2. 事务问题。在执行分库分表之后，由于数据存储到了不同的库上，数据库事务管理出现了困难。
3. 跨库跨表的join问题。分库分表后，表的关联操作将受到限制，我们无法join位于不同分库的表，可以通过冗余数据的方式来减少和避免 join 的情况，或者通过业务逻辑来进行join 操作而不是数据库 join。
4. 跨节点的 count,order by,group by 以及聚合函数问题。只能由业务代码来实现或者用中间件将各表中的数据汇总后返回，不过这也会造成额外的数据管理负担。

### 主从复制的原理？

主库和从库的同步是通过线程和Bin log二进制日志实现的：

- 主库将数据的改变记录二进制binlog日志，当主库上的数据发生改变时，则将其改变写入二进制日志中；
- 从库服务器会在一定时间间隔内对主库的二进制日志进行探测其是否发生改变，如果发生改变，则生成一个I/O线程请求主库二进制日志，并将得到的binlog写到本地的中继日志文件中；

- 此时，主库会生成一个线程，用来给从库I/O线程传送二进制日志
- 从库数据库会生成一个SQL线程，会读取中继日志，并解析成sql语句逐一执行

### 主从复制模式有哪些？

MySQL 有三种同步模式，分别是异步复制、同步复制、半同步复制。

- 异步复制：MySQL 默认的复制即是异步的，主库在执行完客户端提交的事务后会立即将结果返给客户端，并不关心从库是否已经接收并处理。这样就会有一个问题，一旦主库宕机，此时主库上已经提交的事务可能因为网络原因并没有传到从库上，如果此时执行故障转移，强行将从提升为主，可能导致新主上的数据不完整。

- 全同步复制：指当主库执行完一个事务，并且所有的从库都执行了该事务，主库才提交事务并返回结果给客户端。因为需要等待所有从库执行完该事务才能返回，所以全同步复制的性能必然会收到严重的影响。

- 半同步复制：是介于全同步复制与全异步复制之间的一种，主库只需要等待至少一个从库接收到并写到 Relay Log 文件即可，主库不需要等待所有从库给主库返回 ACK。主库收到这个 ACK 以后，才能给客户端返回 “事务完成” 的确认。

### 主从同步延迟怎么处理？

主从同步延迟的原因是：从库读取bing log的线程仅有一个，当日志文件很大、或者有网络延迟导致读取bing log延迟大；或者因为从库读操作压力大、某个SQL执行时间较长、或者因为锁冲突等多种原因，导致中继日志中的SQL未在从库执行，都会造成主从延迟。

缓解主从复制延迟有几种常见的方法:

1. 提升配置，比如网络IO、从库的CPU、硬盘等资源，提高IO能力。
2. 增加从库数量，如果从库承担了大量查询请求，那么从库上的查询操作将耗费大量的 CPU 资源，从而影响了同步速度，造成主从延迟，通过多接几个从库，让这些从库来共同分担读的压力。
3. 将MySQL变为半同步复制，主库只需要等待至少一个从库接收到并写到中继日志中，才可返回客户端，减少了主从延迟的概率，由于不用等其完全执行且提交，还是有一定程度的延迟。
4. 在业务层面，如果业务场景允许，执行更新操作，等待一小段时间后再查询。
5. 在SQL层面，优化SQL，避免慢SQL，减少批量操作。

以上方案都是减缓主从复制延迟的概率，如果要需求是强一致性的话：

- 将MySQL变为全同步复制，主库执行完一个事务，并且所有的从库都执行了该事务，主库才提交事务并返回结果给客户端，因为需要等待所有从库执行完该事务才能返回，所以全同步复制的性能必然会收到严重的影响。
- 采用缓存中间件和双写策略，写入时写入主库和缓存中，查询时查询缓存，从库作为容灾和备份。分布式缓存也有一些限制，比如不能完全支持事务处理，如果业务并发压力大但不要求支持事务的话，可以考虑缓存。
- 针对关键业务读写操作显式读主库，非关键业务采用读写分离。如果某些操作对数据的实时性要求比较苛刻，需要反映实时最新的数据，则从主库读取；可接受延迟的业务从从库读取。

## 场景篇

### 如果当前数据库查询CPU占用高，该如何定位问题？

排查：

1. 首先使用 top 命令观察，确定是MySQL进程导致还是其他原因。

2. 如果确定是MySQL进程占用较高，查看data目录里面的*.err文件，查询数据库是否运行正常

3. 使用`show processlist`，查看确定是不是有消耗资源的 sql 在运行，也有可能是每个 sql 消耗资源并不多，但是突然之间，有大量的 session 连进来导致 cpu 飙升，这种情况就需要跟应用一起来分析为何连接数会激增，再做出相应的调整，比如说限制连接数等。

   > 对于查询时间长、运行状态（State 列）是“Sending data”、“Copying to tmp table”、“Copying to tmp table on disk”、“Sorting result”、“Using filesort”等都可能是有性能问题的查询（SQL）。

4. 如果确实有消耗高的 sql，使用`explain`看看执行计划是否准确， 索引是否缺失，数据量是否太大，定位SQL语句的性能问题。

5. 一些比较复杂的SQL语句可以一个一个优化，把每个查询条件单独拆分分析，找到那个语句比较慢，再对应地优化。

处理：

1. kill 掉这些线程 (同时观察 cpu 使用率是否下降)，
2. 进行相应的调整 (比如说加索引、改 sql、改内存参数)
3. 重新跑这些 SQL

### MySQL表很大，进行分页时limit 100000加载很慢，如何解决？

limitm，n其实去扫描m+n条数据，然后过滤掉前面的m条数据，当m越大，那么需要扫描的数据也就越多，性能也会越来越慢。针对这种情况，有以下几种方案可以进行一定的优化：

1、如果id是趋势递增的，那么每次查询都可以返回这次查询最大的ID。下次查询时加上大于上次最大id的条件，这样会通过主键索引去扫描，扫描数量会少很多很多。

2、先limit出来主键ID，然后用主表跟查询出来的ID进行innerjoin内连接，因为减少了回表，查询ID只需要走聚集索引就行。

3、如果mysql级别优化不了了。我们也可以对分页数据进行缓存。

4、看业务层面能否做一些让步，比如不做后面几百页的数据。

### 慢SQL如何定位？

- 使用慢查询日志定位：开启 MySQL 的慢查询日志，再通过一些工具比如 mysql-dump-slow 去分析对应的慢查询日志。
- 使用show processlist定位：可以查询定位当前正在执行的慢查询。

### 如何优化SQL？

 SQL语句的优化可以注意以下方面：

- 避免不必要的列。SQL 查询的时候，应该只查询需要的列，而不要包含额外的列。
- 分页优化。在数据量比较大，考虑分页的优化。
- 索引优化。合理的设计和使用索引。
- 如果需要表的联合查询的话，尽可能用小表驱动大表，避免join太多的表，适当的增加冗余字段减少join查询。

### 大表如何增加字段？

当线上的数据库数据量到达几百万、上千万的时候，加一个字段就没那么简单，因为可能会长时间锁表。

通常的做法包括：

- 通过中间表转换：创建一个临时的新表，把旧表的结构完全复制过去，添加字段，再把旧表数据复制过去，删除旧表，新表命名为旧表的名称，这种方式可能回丢掉一些数据。
- 先在从库添加 再进行主从切换：如果一张表数据量大且是热表，读写特别频繁，则可以考虑先在从库添加，再进行主从切换，切换后再将其他几个节点上添加字段。

### 百万级别的数据如何删除？

MySQL中删除数据的速度和创建的索引数量是成正比的，索引文件是单独存在的文件,所以当我们对数据的增加,修改,删除,都会产生额外的对索引文件的操作,这些操作需要消耗额外的 IO,会降低增/改/删的执行效率。

因此，删除大量数据时，首先要先删除索引，之后再删除数据，删除完成之后重新创建索引。

### MySQL 遇到过死锁问题吗，你是如何解决的？

排查死锁的一般步骤是这样的：

1. 查看死锁日志`show engine innodb status;`
2. 找出死锁 sql
3. 分析 sql 加锁情况
4. 模拟死锁案发
5. 分析死锁日志
6. 分析死锁结果

### 不停机，如何实现迁移？

- **第一阶段：在线双写，查询走老库**

1. 建立好新的库表结构，数据写入旧库的同时，也写入拆分的新库
2. 数据迁移，使用数据迁移程序，将旧库中的历史数据迁移到新库
3. 使用定时任务，新旧库的数据对比，把差异补齐

- **第二阶段：在线双写，查询走新库**

1. 完成了历史数据的同步和校验
2. 把对数据的读切换到新库

- **第三阶段：旧库下线**

1. 旧库不再写入新的数据
2. 经过一段时间，确定旧库没有请求之后，就可以下线老库

